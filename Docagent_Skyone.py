#!/usr/bin/env python3
"""
DocAgent LangGraph - Sistema de Documenta√ß√£o Autom√°tica de Reposit√≥rios
=======================================================================

Sistema avan√ßado baseado em LangGraph para an√°lise e documenta√ß√£o completa
de reposit√≥rios GitHub, com suporte para OpenAI e Ollama.

Caracter√≠sticas:
- Arquitetura baseada em LangGraph com fluxo de estados
- Agentes especializados para an√°lise e documenta√ß√£o
- Suporte para OpenAI GPT-4 e modelos Ollama locais
- Interface web moderna com autentica√ß√£o
- Relat√≥rios an√¥nimos e documenta√ß√£o t√©cnica completa
- Sistema de tools avan√ßadas para an√°lise de c√≥digo
- Arquitetura C4 Model para documenta√ß√£o arquitetural

Autor: DocAgent Skyone v3.0 LangGraph
"""

import os
import sys
import json
import subprocess
import tempfile
import shutil
import time
import logging
import traceback
import hashlib
import re
import fnmatch
import zipfile
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any, Union, TypedDict, Annotated
from dataclasses import dataclass, asdict
from concurrent.futures import ThreadPoolExecutor
import asyncio

# Importar configura√ß√µes
try:
    from config import config
    CONFIG_AVAILABLE = True
    print("‚úÖ Configura√ß√µes carregadas")
except ImportError:
    CONFIG_AVAILABLE = False
    print("‚ö†Ô∏è Arquivo de configura√ß√£o n√£o encontrado - usando padr√µes")

# LangGraph e LangChain imports
try:
    from langgraph.graph import StateGraph, END
    from langgraph.checkpoint.memory import MemorySaver
    from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
    from langchain_core.tools import tool
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_openai import ChatOpenAI
    from langchain_community.llms import Ollama
    from langchain_core.runnables import RunnableConfig
    
    # Tentar importar ToolNode da vers√£o mais recente
    try:
        from langgraph.prebuilt import ToolNode
    except ImportError:
        ToolNode = None
        print("‚ö†Ô∏è ToolNode n√£o dispon√≠vel")
    
    # Importa√ß√µes para Mermaid nativo do LangGraph
    try:
        from IPython.display import Image, display
        MERMAID_NATIVE_AVAILABLE = True
        print("‚úÖ Mermaid nativo dispon√≠vel")
    except ImportError:
        MERMAID_NATIVE_AVAILABLE = False
        print("‚ö†Ô∏è Mermaid nativo n√£o dispon√≠vel")
    
    # Importa√ß√µes para gera√ß√£o PNG com Playwright
    try:
        from playwright.sync_api import sync_playwright
        PLAYWRIGHT_AVAILABLE = True
        print("‚úÖ Playwright dispon√≠vel para PNG")
    except ImportError:
        PLAYWRIGHT_AVAILABLE = False
        print("‚ö†Ô∏è Playwright n√£o dispon√≠vel")
    
    LANGGRAPH_AVAILABLE = True
    print("‚úÖ LangGraph e LangChain dispon√≠veis")
except ImportError as e:
    LANGGRAPH_AVAILABLE = False
    MERMAID_NATIVE_AVAILABLE = False
    print(f"‚ùå LangGraph/LangChain n√£o dispon√≠vel: {e}")
    print("Execute: pip install langgraph langchain langchain-openai langchain-community")

# FastAPI e depend√™ncias web
try:
    from fastapi import FastAPI, Request, HTTPException, BackgroundTasks
    from fastapi.responses import HTMLResponse, JSONResponse, FileResponse
    from fastapi.staticfiles import StaticFiles
    from fastapi.templating import Jinja2Templates
    from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
    from fastapi.middleware.cors import CORSMiddleware
    import uvicorn
    WEB_AVAILABLE = True
    print("‚úÖ FastAPI dispon√≠vel")
except ImportError as e:
    WEB_AVAILABLE = False
    print(f"‚ùå FastAPI n√£o dispon√≠vel: {e}")

# Pydantic
try:
    from pydantic import BaseModel, Field, ConfigDict
    PYDANTIC_V2 = True
    print("‚úÖ Pydantic V2 detectado")
except ImportError:
    try:
        from pydantic import BaseModel, Field
        PYDANTIC_V2 = False
        print("‚ö†Ô∏è Pydantic V1 em uso")
    except ImportError as e:
        print(f"‚ùå Pydantic n√£o dispon√≠vel: {e}")
        exit(1)

# Configurar logging
if CONFIG_AVAILABLE:
    # Criar diret√≥rio de logs
    config.LOGS_DIR.mkdir(exist_ok=True)
    
    logging.basicConfig(
        level=getattr(logging, config.LOG_LEVEL),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(config.LOG_FILE),
            logging.StreamHandler(sys.stdout)
        ]
    )
else:
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

logger = logging.getLogger(__name__)

# =============================================================================
# ESTADO DO LANGGRAPH - DEFINI√á√ïES PRINCIPAIS
# =============================================================================

class DocumentationState(TypedDict):
    """Estado principal do fluxo LangGraph para documenta√ß√£o"""
    # Entrada
    repo_url: str
    model_provider: str  # "openai" ou "ollama"
    model_name: str
    anonymous: bool
    max_files: int
    deep_analysis: bool
    
    # Estado do processamento
    repo_path: Optional[str]
    current_phase: str
    progress: int
    logs: List[str]
    
    # An√°lise
    file_structure: Optional[Dict[str, Any]]
    code_analysis: Optional[Dict[str, Any]]
    architecture_analysis: Optional[Dict[str, Any]]
    
    # Documenta√ß√£o
    documentation_plan: Optional[Dict[str, Any]]
    generated_docs: List[str]
    
    # Metadata
    metadata: Dict[str, Any]
    error_count: int

# =============================================================================
# MODELOS DE DADOS
# =============================================================================

@dataclass
class RepositoryInfo:
    """Informa√ß√µes de um reposit√≥rio GitHub"""
    nome: str
    nome_completo: str
    descricao: str
    url: str
    linguagem_principal: str
    estrelas: int
    forks: int
    tamanho_kb: int
    atualizado_em: str
    topicos: List[str]
    privado: bool

@dataclass
class FileAnalysis:
    """An√°lise detalhada de um arquivo"""
    name: str
    path: str
    language: str
    size: int
    lines: int
    functions: List[str]
    classes: List[str]
    imports: List[str]
    purpose: str
    summary: str
    complexity: str

class AnalysisRequest(BaseModel):
    """Requisi√ß√£o de an√°lise"""
    repo_url: str
    model_provider: str = "ollama"  # "openai" ou "ollama"
    model_name: str = "qwen2.5:7b"
    max_files: int = 50
    deep_analysis: bool = True
    anonymous: bool = True
    local_directory: Optional[str] = None  # Para an√°lise de diret√≥rio local

class AnalysisStatus(BaseModel):
    """Status da an√°lise"""
    status: str
    phase: str
    progress: int
    message: str
    logs: List[str] = []
    current_step: str = ""

class SearchRequest(BaseModel):
    """Requisi√ß√£o de busca de reposit√≥rios"""
    usuario: str
    incluir_forks: bool = False

class ModelConfig(BaseModel):
    """Configura√ß√£o de modelos"""
    provider: str  # "openai" ou "ollama"
    model_name: str
    api_key: Optional[str] = None
    base_url: Optional[str] = None
    temperature: float = 0.1
    max_tokens: int = 8192

# =============================================================================
# SISTEMA DE ANONIMIZA√á√ÉO
# =============================================================================

class AnonymizationSystem:
    """Sistema para anonimizar informa√ß√µes pessoais"""
    
    def __init__(self):
        self.user_mapping = {}
        self.repo_mapping = {}
        self.counter = 1
        print("üîí Sistema de anonimiza√ß√£o inicializado")
    
    def anonymize_repo_url(self, url: str) -> str:
        """Anonimiza URL do reposit√≥rio ou diret√≥rio local"""
        try:
            # Anonimizar diret√≥rio local
            if url.startswith("file://"):
                return "file:///projeto_local_anonimo"
            
            # Anonimizar URL GitHub
            match = re.search(r'github\.com/([^/]+)/([^/]+)', url)
            if match:
                user, repo = match.groups()
                
                if user not in self.user_mapping:
                    self.user_mapping[user] = f"usuario_anonimo_{self.counter}"
                    self.counter += 1
                
                if repo not in self.repo_mapping:
                    self.repo_mapping[repo] = f"projeto_anonimo_{len(self.repo_mapping) + 1}"
                
                anon_user = self.user_mapping[user]
                anon_repo = self.repo_mapping[repo]
                
                return f"https://github.com/{anon_user}/{anon_repo}"
            
            return "https://github.com/usuario_anonimo/projeto_anonimo"
            
        except Exception as e:
            logger.warning(f"Erro na anonimiza√ß√£o: {e}")
            return "https://github.com/usuario_anonimo/projeto_anonimo"
    
    def anonymize_content(self, content: str, anonymous: bool = True) -> str:
        """Anonimiza conte√∫do textual se necess√°rio"""
        if not anonymous:
            return content
        
        try:
            # Anonimizar caminhos de arquivo
            content = re.sub(r'/home/[^/]+/', '/home/usuario_anonimo/', content)
            content = re.sub(r'/Users/[^/]+/', '/Users/usuario_anonimo/', content)
            content = re.sub(r'C:\\Users\\[^\\]+\\', 'C:\\Users\\usuario_anonimo\\', content)
            
            # Anonimizar nomes de usu√°rio em caminhos
            content = re.sub(r'[/\\]([a-zA-Z][a-zA-Z0-9_-]{2,})[/\\]', r'/usuario_anonimo/', content)
            
            return content
        except Exception as e:
            logger.warning(f"Erro na anonimiza√ß√£o de conte√∫do: {e}")
            return content

# =============================================================================
# SISTEMA DE BUSCA GITHUB
# =============================================================================

class GitHubRepositoryFetcher:
    """Sistema para buscar reposit√≥rios do GitHub"""
    
    def __init__(self):
        self.session_cache = {}
        self.rate_limit_info = {}
        self.last_request_time = 0
        self.min_request_interval = 1.0
        print("üîç Sistema de busca GitHub inicializado")
    
    def _rate_limit_wait(self):
        """Implementa rate limiting b√°sico"""
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        
        if time_since_last < self.min_request_interval:
            wait_time = self.min_request_interval - time_since_last
            time.sleep(wait_time)
        
        self.last_request_time = time.time()
    
    def search_repositories(self, user_or_org: str, include_forks: bool = False) -> List[RepositoryInfo]:
        """Busca reposit√≥rios de um usu√°rio ou organiza√ß√£o"""
        try:
            clean_user = self._extract_user_from_input(user_or_org)
            logger.info(f"Buscando reposit√≥rios de: {clean_user}")
            
            if not self._verify_user_exists(clean_user):
                logger.error(f"Usu√°rio/organiza√ß√£o n√£o encontrado: {clean_user}")
                return []
            
            repositories = []
            page = 1
            
            while len(repositories) < 50 and page <= 5:
                repos_api_url = f"https://api.github.com/users/{clean_user}/repos?per_page=30&sort=updated&page={page}"
                
                try:
                    self._rate_limit_wait()
                    repos_data = self._make_github_request(repos_api_url)
                    
                    if not repos_data:
                        break
                    
                    for repo_data in repos_data:
                        if not include_forks and repo_data.get('fork', False):
                            continue
                        
                        if repo_data.get('private', False) and not os.environ.get('GITHUB_TOKEN'):
                            continue
                        
                        repo_info = self._process_repository_data(repo_data)
                        if repo_info:
                            repositories.append(repo_info)
                    
                    if len(repos_data) < 30:
                        break
                    
                    page += 1
                    
                except Exception as e:
                    logger.warning(f"Erro na p√°gina {page}: {e}")
                    break
            
            logger.info(f"Encontrados {len(repositories)} reposit√≥rios")
            return sorted(repositories, key=lambda x: x.estrelas, reverse=True)
            
        except Exception as e:
            logger.error(f"Erro ao buscar reposit√≥rios: {e}")
            return []
    
    def _extract_user_from_input(self, input_str: str) -> str:
        """Extrai nome de usu√°rio de diferentes formatos"""
        input_str = input_str.strip()
        
        if 'github.com' in input_str:
            match = re.search(r'github\.com/([^/]+)', input_str)
            if match:
                return match.group(1)
        
        return re.sub(r'[^a-zA-Z0-9\-_]', '', input_str)
    
    def _verify_user_exists(self, user: str) -> bool:
        """Verifica se usu√°rio existe"""
        try:
            import urllib.request
            url = f"https://api.github.com/users/{user}"
            self._rate_limit_wait()
            response = self._make_github_request(url)
            return response is not None
        except Exception as e:
            logger.warning(f"Erro ao verificar usu√°rio: {e}")
            return False
    
    def _make_github_request(self, url: str) -> Optional[Dict]:
        """Faz requisi√ß√£o para API do GitHub"""
        try:
            import urllib.request
            import urllib.error
            
            request = urllib.request.Request(url)
            request.add_header('User-Agent', 'Mozilla/5.0 (compatible; DocAgent-LangGraph/3.0)')
            request.add_header('Accept', 'application/vnd.github.v3+json')
            
            github_token = os.environ.get('GITHUB_TOKEN')
            if github_token:
                request.add_header('Authorization', f'token {github_token}')
            
            with urllib.request.urlopen(request, timeout=30) as response:
                if response.getcode() == 200:
                    return json.loads(response.read().decode('utf-8'))
                else:
                    logger.warning(f"Resposta HTTP {response.getcode()}")
                    return None
                    
        except urllib.error.HTTPError as e:
            if e.code == 404:
                logger.error(f"Recurso n√£o encontrado (404): {url}")
            elif e.code == 403:
                logger.error("403: Rate limit ou permiss√£o insuficiente")
            elif e.code == 401:
                logger.error("401: Token inv√°lido ou expirado")
            else:
                logger.error(f"Erro HTTP {e.code}: {e.reason}")
            return None
        except Exception as e:
            logger.error(f"Erro na requisi√ß√£o: {e}")
            return None
    
    def _process_repository_data(self, repo_data: Dict) -> Optional[RepositoryInfo]:
        """Processa dados do reposit√≥rio"""
        try:
            return RepositoryInfo(
                nome=repo_data.get('name', ''),
                nome_completo=repo_data.get('full_name', ''),
                descricao=(repo_data.get('description') or 'Sem descri√ß√£o')[:200],
                url=repo_data.get('html_url', ''),
                linguagem_principal=repo_data.get('language') or 'Desconhecida',
                estrelas=repo_data.get('stargazers_count', 0),
                forks=repo_data.get('forks_count', 0),
                tamanho_kb=repo_data.get('size', 0),
                atualizado_em=repo_data.get('updated_at', ''),
                topicos=repo_data.get('topics', []),
                privado=repo_data.get('private', False)
            )
        except Exception as e:
            logger.warning(f"Erro ao processar reposit√≥rio: {e}")
            return None

# =============================================================================
# SISTEMA DE GERA√á√ÉO MERMAID NATIVO
# =============================================================================

class MermaidGenerator:
    """Gerador de diagramas Mermaid usando LangGraph nativo + Playwright"""
    
    def __init__(self, workflow_graph=None):
        self.workflow_graph = workflow_graph
        self.docs_dir = Path("docs")
        self.docs_dir.mkdir(exist_ok=True)
        logger.info("Gerador Mermaid inicializado")
    
    def generate_workflow_diagram(self) -> str:
        """Gera diagrama Mermaid do workflow LangGraph"""
        try:
            if not self.workflow_graph:
                return "Workflow n√£o dispon√≠vel"
            
            # Usar fun√ß√£o nativa do LangGraph
            if MERMAID_NATIVE_AVAILABLE:
                try:
                    mermaid_code = self.workflow_graph.get_graph().draw_mermaid()
                    return mermaid_code
                except Exception as e:
                    logger.warning(f"Erro ao usar Mermaid nativo: {e}")
                    return self._generate_fallback_workflow()
            else:
                return self._generate_fallback_workflow()
                
        except Exception as e:
            logger.error(f"Erro na gera√ß√£o do diagrama workflow: {e}")
            return self._generate_fallback_workflow()
    
    def _generate_fallback_workflow(self) -> str:
        """Gera diagrama workflow de fallback"""
        return """
```mermaid
flowchart TD
    A[In√≠cio] --> B[Clone/Local Directory]
    B --> C[Analyze Structure]
    C --> D[Generate Plan]
    D --> E[Generate C4 Context]
    E --> F[Generate C4 Container]
    F --> G[Generate C4 Component]
    G --> H[Generate C4 Code]
    H --> I[Generate Detailed Analysis]
    I --> J[Generate Structure Report]
    J --> K[Generate Implementation Guide]
    K --> L[Generate Flowcharts]
    L --> M[Conclu√≠do]
    
    style A fill:#e1f5fe
    style M fill:#c8e6c9
    style E fill:#f3e5f5
    style F fill:#f3e5f5
    style G fill:#f3e5f5
    style H fill:#f3e5f5
    style I fill:#e8f5e8
    style J fill:#e8f5e8
    style K fill:#e8f5e8
    style L fill:#e8f5e8
```
"""
    
    def save_workflow_diagram(self, filename: str = "skyone_workflow_diagram.md") -> str:
        """Salva diagrama do workflow em arquivo"""
        try:
            mermaid_content = f"""# Skyone DocAgent - Workflow Diagram

## üîÑ Fluxo de Processamento LangGraph

Este diagrama mostra o fluxo completo de processamento do Skyone DocAgent.

{self.generate_workflow_diagram()}

## üìã Descri√ß√£o das Etapas

### Fase 1: Prepara√ß√£o
- **Clone/Local Directory**: Prepara√ß√£o do reposit√≥rio ou diret√≥rio local
- **Analyze Structure**: An√°lise da estrutura de arquivos e c√≥digo

### Fase 2: Planejamento
- **Generate Plan**: Cria√ß√£o do plano de documenta√ß√£o

### Fase 3: Documenta√ß√£o C4
- **Generate C4 Context**: Diagrama de contexto
- **Generate C4 Container**: Diagrama de cont√™ineres
- **Generate C4 Component**: Diagrama de componentes
- **Generate C4 Code**: An√°lise de c√≥digo C4

### Fase 4: An√°lise Detalhada
- **Generate Detailed Analysis**: An√°lise t√©cnica profunda
- **Generate Structure Report**: Relat√≥rio estrutural
- **Generate Implementation Guide**: Guia de implementa√ß√£o
- **Generate Flowcharts**: Fluxogramas detalhados

---
*Gerado pelo Skyone DocAgent v3.0 ‚Ä¢ LangGraph Native*
"""
            
            file_path = self.docs_dir / filename
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(mermaid_content)
            
            logger.info(f"Diagrama workflow salvo: {filename}")
            return filename
            
        except Exception as e:
            logger.error(f"Erro ao salvar diagrama workflow: {e}")
            return ""
    
    def generate_mermaid_png(self, mermaid_code: str, filename: str = None) -> str:
        """Gera PNG do diagrama Mermaid usando Playwright"""
        try:
            if not PLAYWRIGHT_AVAILABLE:
                logger.warning("Playwright n√£o dispon√≠vel para gera√ß√£o PNG")
                return ""
            
            if not filename:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"skyone_mermaid_{timestamp}.png"
            
            png_path = self.docs_dir / filename
            
            # HTML template para renderizar Mermaid
            html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <style>
        body {{ margin: 0; padding: 20px; background: white; }}
        .mermaid {{ text-align: center; }}
    </style>
</head>
<body>
    <div class="mermaid">
{mermaid_code}
    </div>
    <script>
        mermaid.initialize({{ startOnLoad: true, theme: 'default' }});
    </script>
</body>
</html>
"""
            
            # Gerar PNG com Playwright
            with sync_playwright() as p:
                browser = p.chromium.launch(headless=True)
                page = browser.new_page()
                page.set_content(html_content)
                page.wait_for_timeout(2000)  # Aguardar renderiza√ß√£o
                page.screenshot(path=str(png_path), full_page=True)
                browser.close()
            
            logger.info(f"PNG Mermaid gerado: {filename}")
            return filename
            
        except Exception as e:
            logger.error(f"Erro ao gerar PNG Mermaid: {e}")
            return ""

# =============================================================================
# SISTEMA DE TOOLS PARA AN√ÅLISE DE REPOSIT√ìRIO
# =============================================================================

class RepositoryAnalysisTools:
    """Tools especializadas para an√°lise de reposit√≥rio"""
    
    def __init__(self, repo_path: Union[str, Path]):
        self.repo_path = Path(repo_path)
        self.file_cache = {}
        self.analysis_cache = {}
        logger.info(f"Inicializando tools de an√°lise para: {self.repo_path}")
    
    def get_file_structure(self) -> Dict[str, Any]:
        """Analisa estrutura de arquivos do reposit√≥rio"""
        try:
            structure = {
                "total_files": 0,
                "code_files": 0,
                "languages": {},
                "directories": [],
                "important_files": [],
                "config_files": []
            }
            
            code_extensions = {
                '.py': 'Python', '.js': 'JavaScript', '.ts': 'TypeScript',
                '.java': 'Java', '.cpp': 'C++', '.c': 'C', '.go': 'Go',
                '.rs': 'Rust', '.php': 'PHP', '.rb': 'Ruby', '.swift': 'Swift'
            }
            
            for root, dirs, files in os.walk(self.repo_path):
                # Filtrar diret√≥rios irrelevantes
                dirs[:] = [d for d in dirs if not d.startswith('.') 
                          and d not in ['node_modules', '__pycache__', 'target', 'build', 'dist']]
                
                # Adicionar diret√≥rios importantes
                for dir_name in dirs:
                    if dir_name in ['src', 'lib', 'app', 'components', 'services', 'models']:
                        structure["directories"].append(str(Path(root) / dir_name))
                
                for file in files:
                    if file.startswith('.'):
                        continue
                    
                    structure["total_files"] += 1
                    file_path = Path(root) / file
                    ext = file_path.suffix.lower()
                    
                    # Arquivos de c√≥digo
                    if ext in code_extensions:
                        structure["code_files"] += 1
                        lang = code_extensions[ext]
                        structure["languages"][lang] = structure["languages"].get(lang, 0) + 1
                    
                    # Arquivos importantes
                    if (file.lower() in ['readme.md', 'package.json', 'requirements.txt', 'dockerfile'] or
                        'main' in file.lower() or 'index' in file.lower() or 'app' in file.lower()):
                        structure["important_files"].append(str(file_path.relative_to(self.repo_path)))
                    
                    # Arquivos de configura√ß√£o
                    if ext in ['.json', '.yml', '.yaml', '.toml', '.ini', '.cfg']:
                        structure["config_files"].append(str(file_path.relative_to(self.repo_path)))
            
            return structure
            
        except Exception as e:
            logger.error(f"Erro na an√°lise de estrutura: {e}")
            return {"error": str(e)}
    
    def analyze_code_files(self, max_files: int = 50) -> List[FileAnalysis]:
        """Analisa arquivos de c√≥digo em detalhes"""
        try:
            analyses = []
            
            # Padr√µes de arquivos importantes (expandido)
            important_patterns = [
                'main.py', 'app.py', 'index.js', 'server.py', 'api.py',
                'models.py', 'views.py', 'controllers.py', 'routes.py',
                'utils.py', 'helpers.js', 'config.py', 'settings.py',
                'service.py', 'handler.py', 'manager.py', 'client.py',
                'database.py', 'db.py', 'auth.py', 'middleware.py',
                'component.js', 'module.py', 'processor.py', 'worker.py',
                'scheduler.py', 'task.py', 'job.py', 'queue.py'
            ]
            
            for root, dirs, files in os.walk(self.repo_path):
                dirs[:] = [d for d in dirs if not d.startswith('.')]
                
                for file in files:
                    if len(analyses) >= max_files:
                        break
                    
                    file_path = Path(root) / file
                    
                    # Priorizar arquivos importantes
                    is_important = any(pattern in file.lower() for pattern in important_patterns)
                    is_code = file_path.suffix.lower() in ['.py', '.js', '.ts', '.java', '.go', '.rs']
                    
                    if not (is_important or is_code):
                        continue
                    
                    try:
                        if file_path.stat().st_size > 500 * 1024:  # Skip files > 500KB
                            continue
                        
                        content = file_path.read_text(encoding='utf-8', errors='ignore')
                        language = self._get_language(file_path.suffix.lower())
                        
                        analysis = self._analyze_file_content(file_path, content, language)
                        analyses.append(analysis)
                        
                    except Exception as e:
                        logger.warning(f"Erro ao analisar {file}: {e}")
                        continue
                
                if len(analyses) >= max_files:
                    break
            
            logger.info(f"Analisados {len(analyses)} arquivos de c√≥digo")
            return analyses
            
        except Exception as e:
            logger.error(f"Erro na an√°lise de arquivos: {e}")
            return []
    
    def _analyze_file_content(self, file_path: Path, content: str, language: str) -> FileAnalysis:
        """Analisa conte√∫do de um arquivo"""
        try:
            lines = [line for line in content.split('\n') if line.strip()]
            
            # Extrair fun√ß√µes, classes e imports
            functions = self._extract_functions(content, language)
            classes = self._extract_classes(content, language)
            imports = self._extract_imports(content, language)
            
            # Determinar prop√≥sito
            purpose = self._determine_file_purpose(file_path, content, language)
            
            # Gerar resumo
            summary = self._generate_file_summary(file_path, content, functions, classes)
            
            # Calcular complexidade
            complexity = self._calculate_complexity(content, functions, classes)
            
            return FileAnalysis(
                name=file_path.name,
                path=str(file_path.relative_to(self.repo_path)),
                language=language,
                size=len(content.encode('utf-8')),
                lines=len(lines),
                functions=functions[:10],
                classes=classes[:10],
                imports=imports[:15],
                purpose=purpose,
                summary=summary,
                complexity=complexity
            )
            
        except Exception as e:
            logger.warning(f"Erro ao analisar arquivo {file_path}: {e}")
            return FileAnalysis(
                name=file_path.name,
                path=str(file_path),
                language=language,
                size=0,
                lines=0,
                functions=[],
                classes=[],
                imports=[],
                purpose="Arquivo de c√≥digo",
                summary=f"Arquivo {language}",
                complexity="Baixa"
            )
    
    def _get_language(self, ext: str) -> str:
        """Identifica linguagem pela extens√£o"""
        language_map = {
            '.py': 'Python', '.js': 'JavaScript', '.ts': 'TypeScript',
            '.java': 'Java', '.cpp': 'C++', '.c': 'C', '.go': 'Go',
            '.rs': 'Rust', '.php': 'PHP', '.rb': 'Ruby', '.swift': 'Swift',
            '.html': 'HTML', '.css': 'CSS', '.sql': 'SQL', '.sh': 'Shell'
        }
        return language_map.get(ext, 'Unknown')
    
    def _extract_functions(self, content: str, language: str) -> List[str]:
        """Extrai fun√ß√µes do c√≥digo com mais detalhes"""
        functions = []
        try:
            if language == 'Python':
                # Capturar fun√ß√µes normais e async
                pattern = r'(?:async\s+)?def\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\('
                # Tamb√©m capturar m√©todos de classe
                class_method_pattern = r'^\s+(?:async\s+)?def\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\('
                
                matches = re.findall(pattern, content, re.MULTILINE)
                class_matches = re.findall(class_method_pattern, content, re.MULTILINE)
                functions.extend(matches)
                functions.extend([f"method_{m}" for m in class_matches])
                
            elif language in ['JavaScript', 'TypeScript']:
                # Fun√ß√µes normais, arrow functions, m√©todos
                patterns = [
                    r'function\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\(',
                    r'const\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*=\s*\(',
                    r'([a-zA-Z_][a-zA-Z0-9_]*)\s*:\s*function\s*\(',
                    r'([a-zA-Z_][a-zA-Z0-9_]*)\s*\([^)]*\)\s*=>'
                ]
                for pattern in patterns:
                    matches = re.findall(pattern, content, re.MULTILINE)
                    functions.extend(matches)
                    
            elif language == 'Java':
                pattern = r'(?:public|private|protected)?\s*(?:static)?\s*\w+\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\('
                matches = re.findall(pattern, content, re.MULTILINE)
                functions.extend(matches)
            else:
                return []
            
            functions = list(set(functions)) if functions else []
        except Exception:
            pass
        
        return functions[:20]  # Limitar a 20 fun√ß√µes mais importantes
    
    def _extract_classes(self, content: str, language: str) -> List[str]:
        """Extrai classes do c√≥digo"""
        classes = []
        try:
            if language in ['Python', 'Java', 'JavaScript', 'TypeScript']:
                pattern = r'class\s+([a-zA-Z_][a-zA-Z0-9_]*)'
                matches = re.findall(pattern, content, re.MULTILINE)
                classes = list(set(matches)) if matches else []
        except Exception:
            pass
        
        return classes
    
    def _extract_imports(self, content: str, language: str) -> List[str]:
        """Extrai imports do c√≥digo"""
        imports = []
        try:
            if language == 'Python':
                pattern = r'(?:from\s+[\w.]+\s+)?import\s+([\w\s,.*]+)'
            elif language in ['JavaScript', 'TypeScript']:
                pattern = r'import\s+.*?from\s+[\'"]([^\'"]+)[\'"]'
            elif language == 'Java':
                pattern = r'import\s+([\w.]+)'
            else:
                return []
            
            matches = re.findall(pattern, content, re.MULTILINE)
            for match in matches:
                if isinstance(match, str):
                    import_name = match.strip().split(',')[0].strip()
                    if import_name and import_name not in imports:
                        imports.append(import_name)
        except Exception:
            pass
        
        return imports
    
    def _determine_file_purpose(self, file_path: Path, content: str, language: str) -> str:
        """Determina o prop√≥sito do arquivo"""
        filename = file_path.name.lower()
        
        if 'test' in filename:
            return "Arquivo de testes"
        elif filename in ['main.py', 'app.py', 'index.js']:
            return "Ponto de entrada da aplica√ß√£o"
        elif filename in ['config.py', 'settings.py']:
            return "Arquivo de configura√ß√£o"
        elif 'api' in filename or 'controller' in filename:
            return "Controlador de API"
        elif 'model' in filename:
            return "Modelo de dados"
        elif 'view' in filename or 'component' in filename:
            return "Componente de interface"
        elif filename.endswith('.md'):
            return "Documenta√ß√£o"
        else:
            return f"Arquivo {language} do projeto"
    
    def _generate_file_summary(self, file_path: Path, content: str, functions: List[str], classes: List[str]) -> str:
        """Gera resumo do arquivo"""
        lines_count = len([l for l in content.split('\n') if l.strip()])
        summary_parts = [f"Arquivo com {lines_count} linhas"]
        
        if classes:
            summary_parts.append(f"{len(classes)} classe(s)")
        if functions:
            summary_parts.append(f"{len(functions)} fun√ß√£o(√µes)")
        
        return ", ".join(summary_parts)
    
    def _calculate_complexity(self, content: str, functions: List[str], classes: List[str]) -> str:
        """Calcula complexidade do arquivo"""
        lines = len([l for l in content.split('\n') if l.strip()])
        complexity_score = 0
        
        if lines > 200:
            complexity_score += 2
        elif lines > 50:
            complexity_score += 1
        
        complexity_score += len(functions) + len(classes)
        
        control_structures = len(re.findall(r'\b(if|for|while|try|catch)\b', content))
        if control_structures > 20:
            complexity_score += 2
        elif control_structures > 10:
            complexity_score += 1
        
        if complexity_score >= 5:
            return "Alta"
        elif complexity_score >= 3:
            return "M√©dia"
        else:
            return "Baixa"

# =============================================================================
# TOOLS LANGGRAPH PARA AN√ÅLISE
# =============================================================================

# Definir tools apenas se LangGraph estiver dispon√≠vel
if LANGGRAPH_AVAILABLE:
    @tool
    def analyze_repository_structure(repo_path: str) -> str:
        """Analisa a estrutura completa do reposit√≥rio"""
        try:
            tools = RepositoryAnalysisTools(repo_path)
            structure = tools.get_file_structure()
            
            if "error" in structure:
                return f"Erro na an√°lise: {structure['error']}"
            
            result = f"""## üìÅ Estrutura do Reposit√≥rio

### üìä Estat√≠sticas Gerais:
- **Total de arquivos:** {structure['total_files']:,}
- **Arquivos de c√≥digo:** {structure['code_files']:,}
- **Linguagens detectadas:** {len(structure['languages'])}

### üíª Distribui√ß√£o por Linguagem:
"""
            for lang, count in sorted(structure['languages'].items(), key=lambda x: x[1], reverse=True):
                percentage = (count / structure['code_files']) * 100 if structure['code_files'] > 0 else 0
                result += f"- **{lang}:** {count} arquivos ({percentage:.1f}%)\n"
            
            result += "\n### üìÅ Diret√≥rios Importantes:\n"
            for directory in structure['directories'][:10]:
                result += f"- {directory}\n"
            
            result += "\n### üéØ Arquivos Importantes:\n"
            for file in structure['important_files'][:15]:
                result += f"- {file}\n"
            
            return result
            
        except Exception as e:
            return f"Erro na an√°lise de estrutura: {str(e)}"

    @tool
    def analyze_code_files(repo_path: str, max_files: int = 20) -> str:
        """Analisa arquivos de c√≥digo em detalhes"""
        try:
            tools = RepositoryAnalysisTools(repo_path)
            analyses = tools.analyze_code_files(max_files)
            
            if not analyses:
                return "Nenhum arquivo de c√≥digo encontrado para an√°lise"
            
            result = f"## üî¨ An√°lise Detalhada de Arquivos ({len(analyses)} arquivos)\n\n"
            
            for i, analysis in enumerate(analyses[:15], 1):
                result += f"### {i}. {analysis.name} ({analysis.language})\n"
                result += f"**Localiza√ß√£o:** `{analysis.path}`\n"
                result += f"**Tamanho:** {analysis.size:,} bytes | **Linhas:** {analysis.lines:,} | **Complexidade:** {analysis.complexity}\n"
                result += f"**Prop√≥sito:** {analysis.purpose}\n"
                result += f"**Resumo:** {analysis.summary}\n"
                
                if analysis.functions:
                    result += f"**Fun√ß√µes:** {', '.join(analysis.functions[:5])}"
                    if len(analysis.functions) > 5:
                        result += f" e mais {len(analysis.functions) - 5}"
                    result += "\n"
                
                if analysis.classes:
                    result += f"**Classes:** {', '.join(analysis.classes[:3])}"
                    if len(analysis.classes) > 3:
                        result += f" e mais {len(analysis.classes) - 3}"
                    result += "\n"
                
                if analysis.imports:
                    result += f"**Principais imports:** {', '.join(analysis.imports[:5])}\n"
                
                result += "\n---\n\n"
            
            return result
            
        except Exception as e:
            return f"Erro na an√°lise de arquivos: {str(e)}"

    @tool
    def read_file_content(repo_path: str, file_path: str) -> str:
        """L√™ conte√∫do de um arquivo espec√≠fico"""
        try:
            full_path = Path(repo_path) / file_path
            
            if not full_path.exists():
                return f"Arquivo n√£o encontrado: {file_path}"
            
            if full_path.stat().st_size > 100 * 1024:  # 100KB limit
                return f"Arquivo muito grande: {file_path}"
            
            content = full_path.read_text(encoding='utf-8', errors='ignore')
            
            return f"""## üìÑ Arquivo: {file_path}

**Tamanho:** {full_path.stat().st_size:,} bytes
**Linhas:** {len(content.split(chr(10)))}

### Conte√∫do:
```{full_path.suffix[1:] if full_path.suffix else 'text'}
{content[:2000]}{'...' if len(content) > 2000 else ''}
```
"""
            
        except Exception as e:
            return f"Erro ao ler arquivo {file_path}: {str(e)}"

    @tool
    def find_dependencies(repo_path: str) -> str:
        """Encontra e analisa arquivos de depend√™ncias"""
        try:
            dependency_files = {
                'package.json': 'Node.js',
                'requirements.txt': 'Python',
                'Pipfile': 'Python (Pipenv)',
                'pyproject.toml': 'Python (Poetry)',
                'pom.xml': 'Java (Maven)',
                'build.gradle': 'Java (Gradle)',
                'Cargo.toml': 'Rust',
                'go.mod': 'Go',
                'composer.json': 'PHP'
            }
            
            found_deps = []
            repo_path = Path(repo_path)
            
            for dep_file, tech in dependency_files.items():
                file_path = repo_path / dep_file
                if file_path.exists():
                    try:
                        content = file_path.read_text(encoding='utf-8', errors='ignore')
                        size = file_path.stat().st_size
                        
                        found_deps.append({
                            'file': dep_file,
                            'technology': tech,
                            'size': size,
                            'content_preview': content[:500]
                        })
                    except Exception as e:
                        logger.warning(f"Erro ao ler {dep_file}: {e}")
            
            if not found_deps:
                return "Nenhum arquivo de depend√™ncias encontrado"
            
            result = "## üì¶ Arquivos de Depend√™ncias Encontrados\n\n"
            
            for dep in found_deps:
                result += f"### {dep['file']} ({dep['technology']})\n"
                result += f"**Tamanho:** {dep['size']:,} bytes\n\n"
                
                if dep['file'] == 'package.json':
                    try:
                        pkg_data = json.loads(dep['content_preview'])
                        if 'dependencies' in pkg_data:
                            result += "**Depend√™ncias principais:**\n"
                            for pkg, version in list(pkg_data['dependencies'].items())[:10]:
                                result += f"- {pkg}: {version}\n"
                    except:
                        pass
                elif dep['file'] == 'requirements.txt':
                    lines = dep['content_preview'].split('\n')[:15]
                    result += "**Depend√™ncias:**\n"
                    for line in lines:
                        if line.strip() and not line.startswith('#'):
                            result += f"- {line.strip()}\n"
                
                result += "\n---\n\n"
            
            return result
            
        except Exception as e:
            return f"Erro na an√°lise de depend√™ncias: {str(e)}"

else:
    # Definir tools vazias se LangGraph n√£o estiver dispon√≠vel
    def analyze_repository_structure(repo_path: str) -> str:
        return "LangGraph n√£o dispon√≠vel"
    
    def analyze_code_files(repo_path: str, max_files: int = 20) -> str:
        return "LangGraph n√£o dispon√≠vel"
    
    def read_file_content(repo_path: str, file_path: str) -> str:
        return "LangGraph n√£o dispon√≠vel"
    
    def find_dependencies(repo_path: str) -> str:
        return "LangGraph n√£o dispon√≠vel"

# =============================================================================
# SISTEMA DE MODELOS LLM
# =============================================================================

class LLMManager:
    """Gerenciador de modelos LLM (OpenAI e Ollama)"""
    
    def __init__(self):
        self.current_config = None
        self.available_models = {
            "openai": ["gpt-4o", "gpt-4o-mini", "gpt-3.5-turbo"],
            "ollama": []
        }
        self._check_ollama_models()
        logger.info("LLM Manager inicializado")
    
    def _check_ollama_models(self):
        """Verifica modelos Ollama dispon√≠veis"""
        try:
            result = subprocess.run(["ollama", "list"], capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                models = []
                for line in result.stdout.strip().split('\n')[1:]:
                    if line.strip():
                        parts = line.split()
                        if parts:
                            model_name = parts[0]
                            # Adicionar informa√ß√µes extras se dispon√≠veis
                            size_info = parts[1] if len(parts) > 1 else ""
                            models.append({
                                "name": model_name,
                                "size": size_info,
                                "display_name": f"{model_name} ({size_info})" if size_info else model_name
                            })
                self.available_models["ollama"] = models
                logger.info(f"Modelos Ollama encontrados: {[m['name'] for m in models]}")
            else:
                logger.warning("Ollama n√£o est√° rodando")
                self.available_models["ollama"] = []
        except Exception as e:
            logger.warning(f"Erro ao verificar Ollama: {e}")
            self.available_models["ollama"] = []
    
    def get_ollama_models_detailed(self):
        """Retorna modelos Ollama com detalhes"""
        self._check_ollama_models()
        return self.available_models["ollama"]
    
    def configure_model(self, config: ModelConfig):
        """Configura modelo LLM"""
        try:
            self.current_config = config
            
            if config.provider == "openai":
                if not config.api_key:
                    config.api_key = os.environ.get("OPENAI_API_KEY")
                
                if not config.api_key:
                    raise ValueError("OPENAI_API_KEY n√£o configurada")
                
                self.llm = ChatOpenAI(
                    model=config.model_name,
                    temperature=config.temperature,
                    max_tokens=config.max_tokens,
                    api_key=config.api_key
                )
                
            elif config.provider == "ollama":
                self.llm = Ollama(
                    model=config.model_name,
                    temperature=config.temperature,
                    base_url=config.base_url or "http://localhost:11434"
                )
            
            else:
                raise ValueError(f"Provider n√£o suportado: {config.provider}")
            
            logger.info(f"Modelo configurado: {config.provider}/{config.model_name}")
            return True
            
        except Exception as e:
            logger.error(f"Erro ao configurar modelo: {e}")
            return False
    
    def get_llm(self):
        """Retorna inst√¢ncia do LLM configurado"""
        if not hasattr(self, 'llm'):
            # Configura√ß√£o padr√£o
            default_config = ModelConfig(
                provider="ollama",
                model_name="qwen2.5:7b"
            )
            self.configure_model(default_config)
        
        return self.llm
    
    def list_available_models(self) -> Dict[str, List[str]]:
        """Lista modelos dispon√≠veis"""
        self._check_ollama_models()  # Atualizar lista Ollama
        return self.available_models.copy()

# =============================================================================
# N√ìS DO LANGGRAPH - AGENTES ESPECIALIZADOS
# =============================================================================

class DocumentationAgents:
    """Agentes especializados para documenta√ß√£o usando LangGraph"""
    
    def __init__(self, llm_manager: LLMManager):
        self.llm_manager = llm_manager
        self.anonymizer = AnonymizationSystem()
        logger.info("Agentes de documenta√ß√£o inicializados")
    
    async def clone_repository_node(self, state: DocumentationState) -> DocumentationState:
        """N√≥ para clonar reposit√≥rio ou usar diret√≥rio local"""
        try:
            repo_url = state["repo_url"]
            logger.info(f"Processando: {repo_url}")
            
            # Verificar se √© um diret√≥rio local
            if repo_url.startswith("file://"):
                local_path = repo_url.replace("file://", "")
                logger.info(f"Usando diret√≥rio local: {local_path}")
                
                if not Path(local_path).exists():
                    state["logs"].append(f"‚ùå Diret√≥rio n√£o encontrado: {local_path}")
                    state["error_count"] += 1
                    return state
                
                if not Path(local_path).is_dir():
                    state["logs"].append(f"‚ùå Caminho n√£o √© um diret√≥rio: {local_path}")
                    state["error_count"] += 1
                    return state
                
                state["repo_path"] = local_path
                state["current_phase"] = "local_ready"
                state["progress"] = 20
                state["logs"].append("‚úÖ Diret√≥rio local configurado")
                logger.info(f"Diret√≥rio local pronto: {local_path}")
                return state
            
            # Validar URL GitHub
            if not self._validate_github_url(repo_url):
                state["logs"].append("‚ùå URL inv√°lida")
                state["error_count"] += 1
                return state
            
            # Preparar diret√≥rio para clone
            repo_name = repo_url.split("/")[-1].replace(".git", "")
            workdir = Path("workdir").resolve()
            workdir.mkdir(exist_ok=True)
            repo_path = workdir / repo_name
            
            # Remover se existir
            if repo_path.exists():
                shutil.rmtree(repo_path, ignore_errors=True)
            
            # Clone
            cmd = ["git", "clone", "--depth", "1", repo_url, str(repo_path)]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0 and repo_path.exists():
                state["repo_path"] = str(repo_path)
                state["current_phase"] = "cloned"
                state["progress"] = 20
                state["logs"].append("‚úÖ Reposit√≥rio clonado com sucesso")
                logger.info(f"Clone conclu√≠do: {repo_path}")
            else:
                state["logs"].append(f"‚ùå Falha no clone: {result.stderr}")
                state["error_count"] += 1
            
            return state
            
        except Exception as e:
            logger.error(f"Erro no processamento: {e}")
            state["logs"].append(f"‚ùå Erro no processamento: {str(e)}")
            state["error_count"] += 1
            return state
    
    async def analyze_structure_node(self, state: DocumentationState) -> DocumentationState:
        """N√≥ para an√°lise de estrutura"""
        try:
            repo_path = state.get("repo_path")
            if not repo_path:
                state["logs"].append("‚ùå Caminho do reposit√≥rio n√£o encontrado")
                state["error_count"] += 1
                return state
            
            logger.info("Analisando estrutura do reposit√≥rio")
            
            # Usar tool de an√°lise
            structure_result = analyze_repository_structure.invoke({"repo_path": repo_path})
            
            # Analisar arquivos de c√≥digo
            code_result = analyze_code_files.invoke({
                "repo_path": repo_path, 
                "max_files": state.get("max_files", 20)
            })
            
            # Encontrar depend√™ncias
            deps_result = find_dependencies.invoke({"repo_path": repo_path})
            
            state["file_structure"] = {
                "structure_analysis": structure_result,
                "code_analysis": code_result,
                "dependencies": deps_result
            }
            
            state["current_phase"] = "analyzed"
            state["progress"] = 40
            state["logs"].append("‚úÖ Estrutura analisada")
            
            return state
            
        except Exception as e:
            logger.error(f"Erro na an√°lise de estrutura: {e}")
            state["logs"].append(f"‚ùå Erro na an√°lise: {str(e)}")
            state["error_count"] += 1
            return state
    
    async def generate_documentation_plan_node(self, state: DocumentationState) -> DocumentationState:
        """N√≥ para gerar plano de documenta√ß√£o"""
        try:
            logger.info("Gerando plano de documenta√ß√£o")
            
            llm = self.llm_manager.get_llm()
            
            # Preparar contexto da an√°lise
            structure_info = state.get("file_structure", {})
            
            # Prompt para planejamento com C4
            planning_prompt = ChatPromptTemplate.from_template("""
Voc√™ √© um especialista em documenta√ß√£o t√©cnica e arquitetura C4. Baseado na an√°lise do reposit√≥rio abaixo, 
crie um plano detalhado para documenta√ß√£o completa com arquitetura C4 em formato JSON.

AN√ÅLISE DO REPOSIT√ìRIO:
{structure_analysis}

{code_analysis}

{dependencies}

Crie um plano JSON com 8 se√ß√µes seguindo o modelo C4 + An√°lise Detalhada:
1. "C4 Context Diagram" - vis√£o geral do sistema e intera√ß√µes externas
2. "C4 Container Diagram" - cont√™ineres e tecnologias principais
3. "C4 Component Diagram" - componentes internos e suas responsabilidades
4. "C4 Code Analysis" - an√°lise detalhada do c√≥digo e estrutura
5. "Detailed Code Analysis" - an√°lise t√©cnica profunda linha por linha
6. "Code Structure Report" - relat√≥rio estrutural detalhado
7. "Technical Implementation Guide" - guia t√©cnico de implementa√ß√£o
8. "Mermaid Flowcharts" - fluxogramas detalhados dos componentes

Formato JSON obrigat√≥rio:
{{
  "overview": "Documenta√ß√£o completa C4 + An√°lise Detalhada do projeto Skyone",
  "sections": [
    {{
      "title": "C4 Context Diagram",
      "description": "Vis√£o contextual do sistema e suas intera√ß√µes externas",
      "content_type": "c4_context"
    }},
    {{
      "title": "C4 Container Diagram", 
      "description": "Cont√™ineres, tecnologias e comunica√ß√£o entre componentes",
      "content_type": "c4_container"
    }},
    {{
      "title": "C4 Component Diagram",
      "description": "Componentes internos, interfaces e responsabilidades",
      "content_type": "c4_component"
    }},
    {{
      "title": "C4 Code Analysis",
      "description": "An√°lise detalhada do c√≥digo, classes e implementa√ß√£o",
      "content_type": "c4_code"
    }},
    {{
      "title": "Detailed Code Analysis",
      "description": "An√°lise t√©cnica profunda linha por linha do c√≥digo",
      "content_type": "detailed_code_analysis"
    }},
    {{
      "title": "Code Structure Report",
      "description": "Relat√≥rio estrutural detalhado dos arquivos e m√≥dulos",
      "content_type": "code_structure_report"
    }},
    {{
      "title": "Technical Implementation Guide",
      "description": "Guia t√©cnico de implementa√ß√£o e padr√µes utilizados",
      "content_type": "technical_implementation"
    }},
    {{
      "title": "Mermaid Flowcharts",
      "description": "Fluxogramas detalhados dos componentes e processos",
      "content_type": "mermaid_flowcharts"
    }}
  ]
}}

Responda APENAS com o JSON v√°lido.
""")
            
            # Executar planejamento
            chain = planning_prompt | llm
            
            planning_result = await chain.ainvoke({
                "structure_analysis": structure_info.get("structure_analysis", ""),
                "code_analysis": structure_info.get("code_analysis", ""),
                "dependencies": structure_info.get("dependencies", "")
            })
            
            # Extrair JSON do resultado
            try:
                if hasattr(planning_result, 'content'):
                    plan_text = planning_result.content
                else:
                    plan_text = str(planning_result)
                
                # Extrair JSON
                json_match = re.search(r'\{.*\}', plan_text, re.DOTALL)
                if json_match:
                    plan_data = json.loads(json_match.group())
                    state["documentation_plan"] = plan_data
                    state["logs"].append("‚úÖ Plano de documenta√ß√£o criado")
                else:
                    raise ValueError("JSON n√£o encontrado na resposta")
                    
            except Exception as e:
                logger.warning(f"Erro ao extrair plano JSON: {e}")
                # Plano padr√£o C4 com an√°lise detalhada de c√≥digo
                state["documentation_plan"] = {
                    "overview": "Documenta√ß√£o completa C4 + An√°lise Detalhada do projeto Skyone",
                    "sections": [
                        {"title": "C4 Context Diagram", "description": "Vis√£o contextual do sistema", "content_type": "c4_context"},
                        {"title": "C4 Container Diagram", "description": "Cont√™ineres e tecnologias", "content_type": "c4_container"},
                        {"title": "C4 Component Diagram", "description": "Componentes internos", "content_type": "c4_component"},
                        {"title": "C4 Code Analysis", "description": "An√°lise detalhada do c√≥digo", "content_type": "c4_code"},
                        {"title": "Detailed Code Analysis", "description": "An√°lise t√©cnica profunda do c√≥digo", "content_type": "detailed_code_analysis"},
                        {"title": "Code Structure Report", "description": "Relat√≥rio estrutural detalhado", "content_type": "code_structure_report"},
                        {"title": "Technical Implementation Guide", "description": "Guia t√©cnico de implementa√ß√£o", "content_type": "technical_implementation"},
                        {"title": "Mermaid Flowcharts", "description": "Fluxogramas detalhados dos componentes", "content_type": "mermaid_flowcharts"}
                    ]
                }
                state["logs"].append("‚ö†Ô∏è Usando plano padr√£o")
            
            state["current_phase"] = "planned"
            state["progress"] = 60
            
            return state
            
        except Exception as e:
            logger.error(f"Erro no planejamento: {e}")
            state["logs"].append(f"‚ùå Erro no planejamento: {str(e)}")
            state["error_count"] += 1
            return state
    
    async def generate_documentation_node(self, state: DocumentationState) -> DocumentationState:
        """N√≥ para gerar documenta√ß√£o"""
        try:
            logger.info("Gerando documenta√ß√£o")
            
            plan = state.get("documentation_plan", {})
            sections = plan.get("sections", [])
            
            if not sections:
                state["logs"].append("‚ùå Plano de documenta√ß√£o n√£o encontrado")
                state["error_count"] += 1
                return state
            
            llm = self.llm_manager.get_llm()
            docs_dir = Path("docs")
            docs_dir.mkdir(exist_ok=True)
            
            generated_files = []
            
            for i, section in enumerate(sections):
                try:
                    logger.info(f"Gerando se√ß√£o: {section['title']}")
                    
                    # Prompt espec√≠fico por tipo de se√ß√£o
                    doc_content = await self._generate_section_content(
                        llm, section, state, i + 1
                    )
                    
                    # Salvar arquivo
                    filename = self._get_section_filename(section['title'], i, state.get("anonymous", True))
                    file_path = docs_dir / filename
                    
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(doc_content)
                    
                    generated_files.append(filename)
                    state["logs"].append(f"‚úÖ Se√ß√£o criada: {section['title']}")
                    
                except Exception as e:
                    logger.error(f"Erro na se√ß√£o {section['title']}: {e}")
                    state["logs"].append(f"‚ùå Erro na se√ß√£o {section['title']}: {str(e)}")
            
            # Gerar diagrama de workflow usando LangGraph nativo
            try:
                # Criar gerador Mermaid para esta inst√¢ncia
                temp_generator = MermaidGenerator()
                workflow_file = temp_generator.save_workflow_diagram()
                if workflow_file:
                    generated_files.append(workflow_file)
                    state["logs"].append("‚úÖ Diagrama de workflow LangGraph criado")
            except Exception as e:
                logger.warning(f"Erro ao gerar diagrama de workflow: {e}")
            
            state["generated_docs"] = generated_files
            state["current_phase"] = "completed"
            state["progress"] = 100
            state["logs"].append(f"üéâ Documenta√ß√£o completa: {len(generated_files)} arquivos")
            
            return state
            
        except Exception as e:
            logger.error(f"Erro na gera√ß√£o de documenta√ß√£o: {e}")
            state["logs"].append(f"‚ùå Erro na documenta√ß√£o: {str(e)}")
            state["error_count"] += 1
            return state
    
    def _validate_github_url(self, url: str) -> bool:
        """Valida URL do GitHub"""
        pattern = r"^https://github\.com/[\w\-\.]+/[\w\-\.]+/?$"
        return bool(re.match(pattern, url.strip()))
    
    def _limit_context_size(self, structure_info: Dict[str, Any], max_chars: int = 8000) -> Dict[str, Any]:
        """Limita o tamanho do contexto para evitar 'Chunk too big'"""
        limited_info = {}
        
        for key, value in structure_info.items():
            if isinstance(value, str):
                if len(value) > max_chars:
                    # Truncar mantendo informa√ß√µes importantes
                    limited_info[key] = value[:max_chars] + "\n\n[... An√°lise truncada para evitar limite de tokens ...]"
                else:
                    limited_info[key] = value
            else:
                limited_info[key] = value
        
        return limited_info
    
    async def _generate_section_content(self, llm, section: Dict, state: DocumentationState, section_num: int) -> str:
        """Gera conte√∫do de uma se√ß√£o espec√≠fica"""
        try:
            content_type = section.get("content_type", "general")
            repo_url = state["repo_url"]
            anonymous = state.get("anonymous", True)
            
            # Anonimizar URL se necess√°rio
            final_url = self.anonymizer.anonymize_repo_url(repo_url) if anonymous else repo_url
            
            # Limitar tamanho do contexto para evitar "Chunk too big"
            structure_info = state.get("file_structure", {})
            limited_structure_info = self._limit_context_size(structure_info)
            
            if content_type == "c4_context":
                prompt = self._create_c4_context_prompt(section, limited_structure_info, final_url)
            elif content_type == "c4_container":
                prompt = self._create_c4_container_prompt(section, limited_structure_info, final_url)
            elif content_type == "c4_component":
                prompt = self._create_c4_component_prompt(section, limited_structure_info, final_url)
            elif content_type == "c4_code":
                prompt = self._create_c4_code_prompt(section, limited_structure_info, final_url)
            elif content_type == "mermaid_flowcharts":
                prompt = self._create_mermaid_flowcharts_prompt(section, limited_structure_info, final_url)
            elif content_type == "detailed_code_analysis":
                prompt = self._create_detailed_code_analysis_prompt(section, limited_structure_info, final_url)
            elif content_type == "code_structure_report":
                prompt = self._create_code_structure_report_prompt(section, limited_structure_info, final_url)
            elif content_type == "technical_implementation":
                prompt = self._create_technical_implementation_prompt(section, limited_structure_info, final_url)
            elif content_type == "overview":
                prompt = self._create_overview_prompt(section, state, final_url)
            elif content_type == "installation":
                prompt = self._create_installation_prompt(section, state, final_url)
            elif content_type == "technical":
                prompt = self._create_technical_prompt(section, state, final_url)
            else:
                prompt = self._create_general_prompt(section, state, final_url)
            
            # Gerar conte√∫do
            result = await llm.ainvoke([HumanMessage(content=prompt)])
            
            if hasattr(result, 'content'):
                content = result.content
            else:
                content = str(result)
            
            # Aplicar anonimiza√ß√£o no conte√∫do se necess√°rio
            anonymous = state.get("anonymous", True)
            content = self.anonymizer.anonymize_content(content, anonymous)
            
            return content
                
        except Exception as e:
            logger.error(f"Erro ao gerar se√ß√£o {section.get('title', 'unknown')}: {e}")
            return self._create_fallback_content(section, state)
    
    def _create_overview_prompt(self, section: Dict, state: DocumentationState, final_url: str) -> str:
        """Cria prompt para vis√£o geral"""
        structure_info = state.get("file_structure", {})
        
        return f"""
Crie uma documenta√ß√£o completa de VIS√ÉO GERAL DO PROJETO baseada na an√°lise real:

T√çTULO: {section['title']}
REPOSIT√ìRIO: {final_url}

AN√ÅLISE ESTRUTURAL:
{structure_info.get('structure_analysis', 'An√°lise n√£o dispon√≠vel')}

AN√ÅLISE DE C√ìDIGO:
{structure_info.get('code_analysis', 'An√°lise de c√≥digo n√£o dispon√≠vel')}

DEPEND√äNCIAS:
{structure_info.get('dependencies', 'Depend√™ncias n√£o identificadas')}

Crie documenta√ß√£o em Markdown com:
# {section['title']}

## üéØ Prop√≥sito do Projeto
[Baseado na an√°lise real dos arquivos]

## üõ†Ô∏è Stack Tecnol√≥gico
[Tecnologias identificadas na an√°lise]

## üèóÔ∏è Arquitetura
[Estrutura e padr√µes identificados]

## üìä Estat√≠sticas
[Dados quantitativos da an√°lise]

Use APENAS informa√ß√µes da an√°lise real fornecida.
"""
    
    def _create_installation_prompt(self, section: Dict, state: DocumentationState, final_url: str) -> str:
        """Cria prompt para instala√ß√£o"""
        structure_info = state.get("file_structure", {})
        
        return f"""
Crie um GUIA DE INSTALA√á√ÉO baseado na an√°lise das depend√™ncias:

T√çTULO: {section['title']}

DEPEND√äNCIAS ENCONTRADAS:
{structure_info.get('dependencies', 'Nenhuma depend√™ncia identificada')}

ESTRUTURA DO PROJETO:
{structure_info.get('structure_analysis', 'Estrutura n√£o analisada')}

Crie documenta√ß√£o em Markdown com:
# {section['title']}

## üìã Pr√©-requisitos
[Baseado nas tecnologias identificadas]

## üöÄ Instala√ß√£o
[Passos baseados nos arquivos de depend√™ncia encontrados]

## ‚öôÔ∏è Configura√ß√£o
[Configura√ß√µes necess√°rias]

## ‚ñ∂Ô∏è Execu√ß√£o
[Como executar o projeto]

Use APENAS informa√ß√µes das depend√™ncias e estrutura analisadas.
"""
    
    def _create_technical_prompt(self, section: Dict, state: DocumentationState, final_url: str) -> str:
        """Cria prompt para relat√≥rio t√©cnico"""
        structure_info = state.get("file_structure", {})
        
        return f"""
Crie um RELAT√ìRIO T√âCNICO DETALHADO baseado na an√°lise de c√≥digo:

T√çTULO: {section['title']}

AN√ÅLISE DE ARQUIVOS:
{structure_info.get('code_analysis', 'An√°lise de c√≥digo n√£o dispon√≠vel')}

ESTRUTURA:
{structure_info.get('structure_analysis', 'Estrutura n√£o analisada')}

Crie documenta√ß√£o t√©cnica em Markdown com:
# {section['title']}

## üìÅ Estrutura do Projeto
[Organiza√ß√£o identificada]

## üîß Arquivos Principais
[Para cada arquivo analisado:]
### [Nome do Arquivo]
- **Prop√≥sito:** [identificado na an√°lise]
- **Linguagem:** [detectada]
- **Fun√ß√µes:** [listadas na an√°lise]
- **Classes:** [encontradas]
- **Complexidade:** [calculada]

## üèóÔ∏è Arquitetura
[Padr√µes identificados]

Use APENAS dados da an√°lise real dos arquivos.
"""
    
    def _create_c4_context_prompt(self, section: Dict, structure_info: Dict[str, Any], final_url: str) -> str:
        """Cria prompt para C4 Context Diagram"""
        
        return f"""
Crie uma documenta√ß√£o C4 CONTEXT DIAGRAM baseada na an√°lise real:

T√çTULO: {section['title']}
PROJETO: {final_url}

AN√ÅLISE ESTRUTURAL:
{structure_info.get('structure_analysis', 'An√°lise n√£o dispon√≠vel')}

DEPEND√äNCIAS:
{structure_info.get('dependencies', 'Depend√™ncias n√£o identificadas')}

Crie documenta√ß√£o em Markdown seguindo o modelo C4 Context:

# {section['title']}

## üéØ Vis√£o Contextual do Sistema

### Sistema Principal
[Nome e prop√≥sito do sistema baseado na an√°lise]

### Usu√°rios e Atores
[Identifique os tipos de usu√°rios que interagem com o sistema]

### Sistemas Externos
[Sistemas, APIs e servi√ßos externos identificados nas depend√™ncias]

### Intera√ß√µes Principais
[Como o sistema se comunica com o mundo externo]

## üìä Diagrama de Contexto C4

```mermaid
C4Context
    title Diagrama de Contexto - [Nome do Sistema]
    
    Person(user, "Usu√°rio", "Descri√ß√£o do usu√°rio principal")
    System(system, "[Nome do Sistema]", "Descri√ß√£o do sistema")
    System_Ext(external, "Sistema Externo", "Descri√ß√£o")
    
    Rel(user, system, "Usa")
    Rel(system, external, "Consome API")
```

## üîó Integra√ß√µes Identificadas
[Liste as integra√ß√µes encontradas na an√°lise]

Use APENAS informa√ß√µes da an√°lise real fornecida.
"""

    def _create_c4_container_prompt(self, section: Dict, structure_info: Dict[str, Any], final_url: str) -> str:
        """Cria prompt para C4 Container Diagram"""
        
        return f"""
Voc√™ √© um especialista em arquitetura C4. Crie uma documenta√ß√£o C4 CONTAINER DIAGRAM baseada EXCLUSIVAMENTE na an√°lise real:

T√çTULO: {section['title']}

AN√ÅLISE DE C√ìDIGO:
{structure_info.get('code_analysis', 'An√°lise de c√≥digo n√£o dispon√≠vel')}

DEPEND√äNCIAS E TECNOLOGIAS REAIS:
{structure_info.get('dependencies', 'Depend√™ncias n√£o identificadas')}

ESTRUTURA REAL:
{structure_info.get('structure_analysis', 'Estrutura n√£o analisada')}

INSTRU√á√ïES CR√çTICAS:
1. Identifique APENAS tecnologias REAIS encontradas nas depend√™ncias
2. Use APENAS linguagens de programa√ß√£o REAIS detectadas na an√°lise
3. Identifique cont√™ineres REAIS baseados na estrutura de diret√≥rios
4. N√ÉO invente bancos de dados ou APIs se n√£o foram identificados
5. Base-se APENAS nos arquivos e tecnologias encontrados

# {section['title']}

## üèóÔ∏è Arquitetura de Cont√™ineres Reais

### Cont√™ineres Identificados na An√°lise
[Baseado na estrutura de diret√≥rios REAL: frontend/, backend/, api/, etc.]

### Stack Tecnol√≥gico Real
[APENAS as tecnologias REAIS das depend√™ncias:]
- **Linguagens:** [Linguagens REAIS detectadas]
- **Frameworks:** [Frameworks REAIS dos arquivos de depend√™ncia]
- **Bibliotecas:** [Bibliotecas REAIS identificadas]

### Comunica√ß√£o e Protocolos
[Baseado nos imports e configura√ß√µes REAIS encontrados]

## üì¶ Diagrama de Cont√™ineres C4 (Dados Reais)

```mermaid
C4Container
    title Diagrama de Cont√™ineres - [Nome Real do Projeto]
    
    Person(user, "Usu√°rio", "Usu√°rio do sistema")
    
    Container_Boundary(system, "[Nome Real do Sistema]") {{
        [Para cada cont√™iner REAL identificado na estrutura:]
        [Exemplo: Container(app_real, "NomeAplicacaoReal", "TecnologiaReal", "Fun√ß√£o real")]
        [APENAS se houver banco de dados identificado: ContainerDb(db_real, "BancoDadosReal", "TipoReal", "Fun√ß√£o real")]
    }}
    
    [APENAS se houver APIs externas REAIS nas depend√™ncias:]
    [System_Ext(api_real, "NomeAPIReal", "Fun√ß√£o real")]
    
    [Relacionamentos REAIS baseados na an√°lise:]
    [Rel(user, app_real, "Interage", "ProtocoloReal")]
    [Rel(app_real, db_real, "Acessa", "ProtocoloReal") - APENAS se DB foi identificado]
```

## üîß Detalhes T√©cnicos dos Cont√™ineres Reais
[Para cada cont√™iner REAL identificado:]

### [Nome Real do Cont√™iner]
- **Tecnologia:** [Tecnologia REAL detectada]
- **Localiza√ß√£o:** [Diret√≥rio REAL na estrutura]
- **Responsabilidades:** [Baseadas nos arquivos REAIS encontrados]
- **Depend√™ncias:** [Depend√™ncias REAIS identificadas]
- **Configura√ß√£o:** [Arquivos de config REAIS encontrados]

## üåê Integra√ß√µes Externas Reais
[APENAS se identificadas nas depend√™ncias ou imports:]

IMPORTANTE: Use SOMENTE dados REAIS da an√°lise. N√ÉO invente cont√™ineres, bancos de dados ou APIs.
"""

    def _create_c4_component_prompt(self, section: Dict, structure_info: Dict[str, Any], final_url: str) -> str:
        """Cria prompt para C4 Component Diagram"""
        
        return f"""
Voc√™ √© um especialista em arquitetura de software e documenta√ß√£o C4. Crie uma documenta√ß√£o C4 COMPONENT DIAGRAM baseada EXCLUSIVAMENTE na an√°lise detalhada real fornecida.

T√çTULO: {section['title']}

AN√ÅLISE DETALHADA DE ARQUIVOS:
{structure_info.get('code_analysis', 'An√°lise de c√≥digo n√£o dispon√≠vel')}

ESTRUTURA DO PROJETO:
{structure_info.get('structure_analysis', 'Estrutura n√£o analisada')}

DEPEND√äNCIAS IDENTIFICADAS:
{structure_info.get('dependencies', 'Depend√™ncias n√£o identificadas')}

INSTRU√á√ïES CR√çTICAS:
1. Use APENAS os arquivos, classes, fun√ß√µes e componentes REAIS identificados na an√°lise
2. N√ÉO invente ou use componentes gen√©ricos como "Controller", "Service", "Repository"
3. Use os NOMES REAIS dos arquivos e classes encontrados na an√°lise
4. Base as responsabilidades nas FUN√á√ïES REAIS identificadas
5. Use as TECNOLOGIAS REAIS encontradas nas depend√™ncias

Crie documenta√ß√£o em Markdown seguindo o modelo C4 Component:

# {section['title']}

## üß© Componentes Reais Identificados

### Arquivos e M√≥dulos Principais
[Liste APENAS os arquivos reais da an√°lise com suas fun√ß√µes espec√≠ficas]

### Classes e Interfaces Reais
[Liste APENAS as classes reais encontradas na an√°lise de c√≥digo]

### Fun√ß√µes e M√©todos Principais
[Liste APENAS as fun√ß√µes reais identificadas na an√°lise]

## üîó Diagrama de Componentes C4 (Baseado na An√°lise Real)

```mermaid
C4Component
    title Diagrama de Componentes - [Nome Real do Sistema]
    
    Container_Boundary(main_container, "[Nome Real da Aplica√ß√£o]") {{
        [Para cada arquivo/classe REAL da an√°lise, crie um Component com nome, tecnologia e prop√≥sito REAIS]
        [Exemplo: Component(arquivo_real, "NomeArquivoReal.py", "Python", "Fun√ß√£o real identificada")]
    }}
    
    [Adicione sistemas externos REAIS encontrados nas depend√™ncias]
    [Adicione bancos de dados REAIS se identificados]
    
    [Crie relacionamentos REAIS baseados nos imports e depend√™ncias da an√°lise]
```

## üìã Detalhes dos Componentes Reais
[Para cada arquivo/classe REAL da an√°lise:]

### [Nome Real do Arquivo/Classe]
- **Localiza√ß√£o:** [Caminho real do arquivo]
- **Linguagem:** [Linguagem real detectada]
- **Prop√≥sito:** [Prop√≥sito real identificado na an√°lise]
- **Fun√ß√µes Principais:** [Fun√ß√µes reais listadas]
- **Depend√™ncias:** [Imports reais identificados]
- **Complexidade:** [Complexidade real calculada]

## üîÑ Fluxo de Dados Real
[Baseado nos imports e depend√™ncias REAIS, descreva como os dados fluem entre os componentes REAIS]

## üèóÔ∏è Padr√µes Arquiteturais Identificados
[Identifique padr√µes REAIS baseados na estrutura e organiza√ß√£o dos arquivos analisados]

IMPORTANTE: Use SOMENTE informa√ß√µes REAIS da an√°lise fornecida. N√ÉO invente componentes gen√©ricos.
"""

    def _create_c4_code_prompt(self, section: Dict, structure_info: Dict[str, Any], final_url: str) -> str:
        """Cria prompt para C4 Code Analysis"""
        
        return f"""
Crie uma documenta√ß√£o C4 CODE ANALYSIS baseada na an√°lise detalhada do c√≥digo:

T√çTULO: {section['title']}

AN√ÅLISE COMPLETA DOS ARQUIVOS:
{structure_info.get('code_analysis', 'An√°lise de c√≥digo n√£o dispon√≠vel')}

ESTRUTURA DETALHADA:
{structure_info.get('structure_analysis', 'Estrutura n√£o analisada')}

Crie documenta√ß√£o em Markdown seguindo o modelo C4 Code:

# {section['title']}

## üíª An√°lise Detalhada do C√≥digo

### Estrutura de Classes e Fun√ß√µes
[Baseado na an√°lise real dos arquivos]

### Padr√µes de C√≥digo Identificados
[Padr√µes arquiteturais encontrados na an√°lise]

### Depend√™ncias Internas
[Como as classes e m√≥dulos se relacionam]

## üèóÔ∏è Estrutura de C√≥digo

### Arquivos Principais Analisados
[Para cada arquivo analisado:]

#### [Nome do Arquivo]
- **Linguagem:** [Detectada na an√°lise]
- **Prop√≥sito:** [Identificado na an√°lise]
- **Classes:** [Listadas na an√°lise]
- **Fun√ß√µes:** [Listadas na an√°lise]
- **Complexidade:** [Calculada na an√°lise]
- **Imports:** [Depend√™ncias identificadas]

## üîç M√©tricas de C√≥digo
[Estat√≠sticas extra√≠das da an√°lise]

## üèõÔ∏è Arquitetura do C√≥digo
[Padr√µes arquiteturais identificados]

## üìà Qualidade e Complexidade
[Avalia√ß√£o baseada na an√°lise realizada]

## üîó Diagrama de Classes (se aplic√°vel)

```mermaid
classDiagram
    [Baseado nas classes identificadas na an√°lise]
```

Use APENAS dados reais da an√°lise dos arquivos fornecida.
"""

    def _create_mermaid_flowcharts_prompt(self, section: Dict, structure_info: Dict[str, Any], final_url: str) -> str:
        """Cria prompt para fluxogramas Mermaid detalhados"""
        
        return f"""
Voc√™ √© um especialista em fluxogramas e diagramas Mermaid. Crie fluxogramas detalhados baseados EXCLUSIVAMENTE na an√°lise real do c√≥digo.

T√çTULO: {section['title']}

AN√ÅLISE COMPLETA DOS ARQUIVOS:
{structure_info.get('code_analysis', 'An√°lise de c√≥digo n√£o dispon√≠vel')}

ESTRUTURA DETALHADA:
{structure_info.get('structure_analysis', 'Estrutura n√£o analisada')}

DEPEND√äNCIAS IDENTIFICADAS:
{structure_info.get('dependencies', 'Depend√™ncias n√£o identificadas')}

INSTRU√á√ïES CR√çTICAS:
1. Use APENAS arquivos, fun√ß√µes e fluxos REAIS identificados na an√°lise
2. Crie fluxogramas para os processos REAIS encontrados no c√≥digo
3. Use nomes REAIS das fun√ß√µes e classes
4. Base os fluxos nas chamadas de fun√ß√£o REAIS identificadas
5. N√ÉO invente processos gen√©ricos

# {section['title']}

## üîÑ Fluxogramas dos Componentes Reais

### Fluxograma Principal do Sistema
[Baseado no arquivo principal identificado na an√°lise]

```mermaid
flowchart TD
    Start([Inicio do Sistema]) --> Init[Inicializacao]
    Init --> Config[Carregar Configuracao]
    Config --> Main[Funcao Principal]
    Main --> Process[Processar Dados]
    Process --> Output[Gerar Saida]
    Output --> End([Fim])
    
    style Start fill:#e1f5fe
    style End fill:#c8e6c9
    style Main fill:#f3e5f5
    style Process fill:#fff3e0
```

### Fluxograma de Processamento de Dados
[APENAS se identificado processamento de dados na an√°lise]

```mermaid
flowchart LR
    Input[Entrada de Dados] --> Validate[Validar Dados]
    Validate --> Transform[Transformar]
    Transform --> Store[Armazenar]
    Store --> Output[Sa√≠da]
    
    %% Substitua pelos processos REAIS identificados na an√°lise
    %% Use nomes REAIS das fun√ß√µes que manipulam dados
    
    style Input fill:#e3f2fd
    style Output fill:#e8f5e8
```

### Fluxograma de Intera√ß√£o entre M√≥dulos
[Baseado nos imports REAIS identificados]

```mermaid
flowchart TB
    subgraph "M√≥dulo Principal"
        MainFunc[Fun√ß√£o Principal]
        Helper[Fun√ß√£o Auxiliar]
    end
    
    subgraph "M√≥dulo Secund√°rio"
        SecFunc[Fun√ß√£o Secund√°ria]
        Utils[Utilit√°rios]
    end
    
    %% Conecte baseado nos imports REAIS da an√°lise
    MainFunc --> SecFunc
    Helper --> Utils
    
    style MainFunc fill:#f3e5f5
    style SecFunc fill:#e8f5e8
```

### Fluxograma de Tratamento de Erros
[APENAS se identificado tratamento de erro na an√°lise]

```mermaid
flowchart TD
    Try[Executar Operacao] --> Success{{Sucesso}}
    Success -->|Sim| Continue[Continuar]
    Success -->|Nao| Catch[Capturar Erro]
    Catch --> Log[Registrar Erro]
    Log --> Fallback[Acao de Fallback]
    Fallback --> End[Fim]
    Continue --> End
    
    style Try fill:#e3f2fd
    style Catch fill:#ffebee
    style End fill:#e8f5e8
```

### Fluxograma de Configura√ß√£o e Inicializa√ß√£o
[APENAS se identificados arquivos de config na an√°lise]

```mermaid
flowchart TD
    Start([Inicio]) --> LoadEnv[Carregar Variaveis de Ambiente]
    LoadEnv --> ReadConfig[Ler Arquivos de Configuracao]
    ReadConfig --> Validate[Validar Configuracoes]
    Validate --> Setup[Configurar Sistema]
    Setup --> Ready[Sistema Pronto]
    
    style Start fill:#e1f5fe
    style Ready fill:#c8e6c9
    style Setup fill:#f3e5f5
```

## üìã Descri√ß√£o dos Fluxogramas

### [Nome do Fluxograma Real]
- **Baseado em:** [Arquivo/fun√ß√£o REAL da an√°lise]
- **Entrada:** [Par√¢metros REAIS identificados]
- **Processamento:** [L√≥gica REAL encontrada no c√≥digo]
- **Sa√≠da:** [Retorno REAL da fun√ß√£o]
- **Depend√™ncias:** [Chamadas REAIS para outras fun√ß√µes]

## üîß Detalhes de Implementa√ß√£o
[Para cada fluxo REAL identificado:]

### Processo: [Nome Real do Processo]
- **Arquivo:** [Localiza√ß√£o REAL]
- **Fun√ß√£o Principal:** [Nome REAL da fun√ß√£o]
- **Complexidade:** [Complexidade REAL calculada]
- **Chamadas:** [Fun√ß√µes REAIS que chama]

IMPORTANTE: Crie APENAS fluxogramas baseados em c√≥digo REAL analisado. N√ÉO invente processos gen√©ricos.
"""

    def _create_detailed_code_analysis_prompt(self, section: Dict, structure_info: Dict[str, Any], final_url: str) -> str:
        """Cria prompt para an√°lise detalhada linha por linha do c√≥digo"""
        
        return f"""
Voc√™ √© um especialista em an√°lise de c√≥digo e engenharia de software. Crie uma AN√ÅLISE T√âCNICA PROFUNDA linha por linha baseada EXCLUSIVAMENTE na an√°lise real do c√≥digo.

T√çTULO: {section['title']}

AN√ÅLISE COMPLETA DOS ARQUIVOS:
{structure_info.get('code_analysis', 'An√°lise de c√≥digo n√£o dispon√≠vel')}

ESTRUTURA DETALHADA:
{structure_info.get('structure_analysis', 'Estrutura n√£o analisada')}

DEPEND√äNCIAS IDENTIFICADAS:
{structure_info.get('dependencies', 'Depend√™ncias n√£o identificadas')}

INSTRU√á√ïES CR√çTICAS:
1. Analise CADA arquivo identificado na an√°lise com detalhes t√©cnicos profundos
2. Examine imports, depend√™ncias, padr√µes de c√≥digo e estruturas de dados REAIS
3. Identifique vulnerabilidades, otimiza√ß√µes e melhorias poss√≠veis
4. Use APENAS dados da an√°lise fornecida - N√ÉO invente c√≥digo ou estruturas
5. Foque em aspectos t√©cnicos: performance, seguran√ßa, manutenibilidade

# {section['title']}

## üî¨ An√°lise T√©cnica Profunda por Arquivo

### Metodologia de An√°lise
- **Escopo:** An√°lise linha por linha dos arquivos principais
- **Crit√©rios:** Performance, Seguran√ßa, Manutenibilidade, Padr√µes
- **Ferramentas:** An√°lise est√°tica baseada na estrutura identificada

### Arquivos Analisados em Detalhes

[Para cada arquivo REAL da an√°lise:]

#### [Nome Real do Arquivo] - An√°lise T√©cnica

**üìç Localiza√ß√£o:** `[Caminho REAL do arquivo]`
**üî§ Linguagem:** [Linguagem REAL detectada]
**üìè M√©tricas:** [Linhas, tamanho, complexidade REAIS]

##### Estrutura do C√≥digo
- **Imports/Depend√™ncias:**
  [Liste os imports REAIS identificados na an√°lise]
  - An√°lise de cada import: prop√≥sito, vers√£o, seguran√ßa
  
- **Classes Identificadas:**
  [Para cada classe REAL encontrada:]
  - `[NomeClasseReal]`: [Prop√≥sito baseado na an√°lise]
    - M√©todos: [M√©todos REAIS identificados]
    - Atributos: [Baseados na an√°lise do c√≥digo]
    - Padr√µes aplicados: [Padr√µes REAIS identificados]

- **Fun√ß√µes Principais:**
  [Para cada fun√ß√£o REAL encontrada:]
  - `[NomeFuncaoReal]()`: [Prop√≥sito baseado na an√°lise]
    - Par√¢metros: [Baseados na an√°lise]
    - L√≥gica: [Resumo da l√≥gica identificada]
    - Complexidade: [Complexidade REAL calculada]

##### An√°lise de Qualidade
- **Performance:**
  - Pontos de otimiza√ß√£o identificados
  - Estruturas de dados utilizadas
  - Algoritmos e complexidade
  
- **Seguran√ßa:**
  - Valida√ß√£o de inputs
  - Tratamento de erros
  - Exposi√ß√£o de dados sens√≠veis
  
- **Manutenibilidade:**
  - Legibilidade do c√≥digo
  - Documenta√ß√£o interna
  - Padr√µes de nomenclatura

##### Padr√µes e Arquitetura
- **Padr√µes de Design:** [Padr√µes REAIS identificados]
- **Arquitetura:** [Estrutura arquitetural identificada]
- **Acoplamento:** [An√°lise de depend√™ncias REAIS]
- **Coes√£o:** [An√°lise da organiza√ß√£o do c√≥digo]

##### Recomenda√ß√µes T√©cnicas
- **Melhorias de Performance:** [Baseadas na an√°lise real]
- **Refatora√ß√µes Sugeridas:** [Baseadas no c√≥digo analisado]
- **Corre√ß√µes de Seguran√ßa:** [Se identificadas vulnerabilidades]
- **Otimiza√ß√µes:** [Espec√≠ficas para o c√≥digo analisado]

---

## üìä Resumo da An√°lise T√©cnica

### M√©tricas Gerais
[Baseadas na an√°lise real:]
- **Total de Arquivos Analisados:** [N√∫mero REAL]
- **Linhas de C√≥digo:** [Total REAL]
- **Complexidade M√©dia:** [Calculada na an√°lise]
- **Linguagens Principais:** [Identificadas na an√°lise]

### Pontos Cr√≠ticos Identificados
[APENAS se identificados na an√°lise real:]
1. **Performance:** [Problemas espec√≠ficos encontrados]
2. **Seguran√ßa:** [Vulnerabilidades espec√≠ficas]
3. **Manutenibilidade:** [Problemas de c√≥digo espec√≠ficos]

### Padr√µes Arquiteturais Detectados
[Baseados na estrutura REAL do c√≥digo:]
- [Padr√£o1]: [Onde foi identificado]
- [Padr√£o2]: [Como est√° implementado]

### Tecnologias e Frameworks
[APENAS os identificados nas depend√™ncias:]
- [Framework1]: [Vers√£o e uso identificado]
- [Biblioteca1]: [Prop√≥sito no projeto]

IMPORTANTE: Use SOMENTE informa√ß√µes REAIS da an√°lise fornecida. Seja espec√≠fico e t√©cnico.
"""

    def _create_code_structure_report_prompt(self, section: Dict, structure_info: Dict[str, Any], final_url: str) -> str:
        """Cria prompt para relat√≥rio estrutural detalhado"""
        
        return f"""
Voc√™ √© um arquiteto de software especialista. Crie um RELAT√ìRIO ESTRUTURAL DETALHADO baseado EXCLUSIVAMENTE na an√°lise real da estrutura do projeto.

T√çTULO: {section['title']}

AN√ÅLISE ESTRUTURAL COMPLETA:
{structure_info.get('structure_analysis', 'An√°lise estrutural n√£o dispon√≠vel')}

AN√ÅLISE DE C√ìDIGO:
{structure_info.get('code_analysis', 'An√°lise de c√≥digo n√£o dispon√≠vel')}

DEPEND√äNCIAS:
{structure_info.get('dependencies', 'Depend√™ncias n√£o identificadas')}

INSTRU√á√ïES CR√çTICAS:
1. Use APENAS a estrutura de diret√≥rios e arquivos REAIS identificados
2. Analise a organiza√ß√£o REAL do projeto baseada na an√°lise
3. Identifique padr√µes organizacionais e conven√ß√µes REAIS
4. N√ÉO invente estruturas ou organize informa√ß√µes n√£o presentes na an√°lise

# {section['title']}

## üèóÔ∏è Estrutura Organizacional do Projeto

### Hierarquia de Diret√≥rios
[Baseado na estrutura REAL identificada:]

```
[Reproduza a estrutura REAL de diret√≥rios identificada na an√°lise]
```

### Organiza√ß√£o por Responsabilidade

#### Diret√≥rios Principais
[Para cada diret√≥rio REAL identificado:]

**üìÅ [Nome do Diret√≥rio Real]**
- **Prop√≥sito:** [Baseado nos arquivos encontrados]
- **Arquivos:** [Arquivos REAIS encontrados]
- **Linguagens:** [Linguagens REAIS detectadas]
- **Responsabilidade:** [Baseada na an√°lise dos arquivos]

#### Padr√µes de Organiza√ß√£o
[Baseados na estrutura REAL:]
- **Conven√ß√µes de nomenclatura:** [Padr√µes REAIS identificados]
- **Separa√ß√£o de responsabilidades:** [Como est√° organizado]
- **Modulariza√ß√£o:** [Estrutura modular identificada]

### An√°lise de Arquivos por Categoria

#### Arquivos de Configura√ß√£o
[APENAS os identificados na an√°lise:]
- `[arquivo.config]`: [Prop√≥sito baseado na an√°lise]
- `[requirements.txt]`: [Depend√™ncias identificadas]

#### Arquivos Principais
[APENAS os identificados como importantes na an√°lise:]
- `[main.py]`: [Fun√ß√£o no projeto baseada na an√°lise]
- `[app.js]`: [Responsabilidade identificada]

#### Arquivos de Teste
[APENAS se identificados na an√°lise:]
- Localiza√ß√£o: [Onde est√£o os testes]
- Cobertura: [Baseada nos arquivos encontrados]

### Depend√™ncias e Integra√ß√µes

#### Depend√™ncias Externas
[APENAS as identificadas nos arquivos de depend√™ncia:]
- **[Framework1]**: [Vers√£o e uso identificado]
- **[Biblioteca1]**: [Prop√≥sito no projeto]

#### Depend√™ncias Internas
[Baseadas nos imports REAIS identificados:]
- **M√≥dulos internos:** [M√≥dulos REAIS que se importam]
- **Acoplamento:** [N√≠vel de depend√™ncia entre m√≥dulos]

### M√©tricas Estruturais

#### Distribui√ß√£o de C√≥digo
[Baseada na an√°lise REAL:]
- **Total de arquivos:** [N√∫mero REAL]
- **Arquivos por linguagem:** [Distribui√ß√£o REAL]
- **Tamanho m√©dio dos arquivos:** [Calculado da an√°lise]

#### Complexidade Estrutural
[Baseada na an√°lise REAL:]
- **Profundidade de diret√≥rios:** [N√≠veis REAIS]
- **Arquivos por diret√≥rio:** [M√©dia REAL]
- **Interdepend√™ncias:** [Baseadas nos imports]

### Padr√µes Arquiteturais Identificados

#### Padr√µes de Organiza√ß√£o
[APENAS os identificados na estrutura REAL:]
- **[Padr√£o1]**: [Onde √© aplicado no projeto]
- **[Padr√£o2]**: [Como est√° implementado]

#### Conven√ß√µes do Projeto
[Baseadas na an√°lise REAL:]
- **Nomenclatura:** [Padr√µes REAIS de nomes]
- **Estrutura:** [Conven√ß√µes REAIS de organiza√ß√£o]
- **Separa√ß√£o:** [Como responsabilidades est√£o divididas]

### Recomenda√ß√µes Estruturais

#### Pontos Fortes
[Baseados na estrutura analisada:]
- [Aspecto positivo espec√≠fico identificado]
- [Boa pr√°tica estrutural encontrada]

#### Oportunidades de Melhoria
[APENAS se identificadas na an√°lise:]
- [Problema estrutural espec√≠fico]
- [Sugest√£o de reorganiza√ß√£o espec√≠fica]

## üìã Resumo Executivo da Estrutura

### Caracter√≠sticas Principais
- **Tipo de projeto:** [Identificado pela estrutura]
- **Padr√£o arquitetural:** [Principal padr√£o identificado]
- **N√≠vel de organiza√ß√£o:** [Baseado na an√°lise]

### Pontos de Aten√ß√£o
[APENAS os identificados na an√°lise real]

IMPORTANTE: Use SOMENTE dados REAIS da an√°lise estrutural fornecida.
"""

    def _create_technical_implementation_prompt(self, section: Dict, structure_info: Dict[str, Any], final_url: str) -> str:
        """Cria prompt para guia t√©cnico de implementa√ß√£o"""
        
        return f"""
Voc√™ √© um especialista em implementa√ß√£o de software. Crie um GUIA T√âCNICO DE IMPLEMENTA√á√ÉO baseado EXCLUSIVAMENTE na an√°lise real do projeto.

T√çTULO: {section['title']}

AN√ÅLISE COMPLETA:
{structure_info.get('code_analysis', 'An√°lise de c√≥digo n√£o dispon√≠vel')}

ESTRUTURA:
{structure_info.get('structure_analysis', 'Estrutura n√£o analisada')}

DEPEND√äNCIAS:
{structure_info.get('dependencies', 'Depend√™ncias n√£o identificadas')}

INSTRU√á√ïES CR√çTICAS:
1. Base-se APENAS nas tecnologias, padr√µes e implementa√ß√µes REAIS identificadas
2. Documente APENAS os padr√µes e pr√°ticas REAIS encontradas no c√≥digo
3. Use exemplos REAIS das fun√ß√µes e classes identificadas na an√°lise
4. N√ÉO invente implementa√ß√µes ou padr√µes n√£o presentes no c√≥digo analisado

# {section['title']}

## üõ†Ô∏è Guia de Implementa√ß√£o T√©cnica

### Stack Tecnol√≥gico Identificado
[Baseado nas depend√™ncias e arquivos REAIS:]

#### Tecnologias Principais
- **Linguagem Principal:** [Linguagem REAL mais usada]
- **Framework:** [Framework REAL identificado nas depend√™ncias]
- **Bibliotecas:** [Bibliotecas REAIS encontradas]

#### Ferramentas de Desenvolvimento
[APENAS se identificadas nos arquivos de config:]
- **Gerenciamento de depend√™ncias:** [Tool REAL identificado]
- **Testes:** [Framework de teste se encontrado]
- **Build:** [Sistema de build se identificado]

### Padr√µes de Implementa√ß√£o Identificados

#### Padr√µes de C√≥digo
[Baseados no c√≥digo REAL analisado:]

**Exemplo de Implementa√ß√£o Real:**
```[linguagem]
// Baseado em fun√ß√£o/classe REAL identificada na an√°lise
[Trecho de c√≥digo real ou estrutura identificada]
```

#### Conven√ß√µes de Nomenclatura
[Baseadas nos nomes REAIS identificados:]
- **Vari√°veis:** [Padr√£o REAL identificado]
- **Fun√ß√µes:** [Conven√ß√£o REAL encontrada]
- **Classes:** [Padr√£o REAL de nomenclatura]

### Arquitetura de Implementa√ß√£o

#### Estrutura de M√≥dulos
[Baseada na organiza√ß√£o REAL:]
- **[M√≥dulo Real 1]:** [Responsabilidade identificada]
  - Implementa√ß√£o: [Como est√° implementado]
  - Depend√™ncias: [Depend√™ncias REAIS]
  
- **[M√≥dulo Real 2]:** [Fun√ß√£o no sistema]
  - Padr√µes aplicados: [Padr√µes REAIS identificados]
  - Interfaces: [Interfaces REAIS identificadas]

#### Fluxo de Dados
[Baseado nas fun√ß√µes e imports REAIS:]
1. **Entrada:** [Como dados entram no sistema - baseado na an√°lise]
2. **Processamento:** [Fun√ß√µes REAIS de processamento identificadas]
3. **Sa√≠da:** [Como dados saem - baseado no c√≥digo analisado]

### Implementa√ß√µes Espec√≠ficas

#### Gerenciamento de Estado
[APENAS se identificado no c√≥digo:]
- **Padr√£o utilizado:** [Padr√£o REAL identificado]
- **Implementa√ß√£o:** [Como est√° implementado no c√≥digo]

#### Tratamento de Erros
[Baseado no c√≥digo REAL analisado:]
- **Estrat√©gia:** [Como erros s√£o tratados no c√≥digo]
- **Implementa√ß√£o:** [Exemplos REAIS encontrados]

#### Configura√ß√£o
[Baseada nos arquivos de config REAIS:]
- **M√©todo:** [Como configura√ß√£o √© gerenciada]
- **Arquivos:** [Arquivos de config REAIS identificados]

### Padr√µes de Qualidade Implementados

#### Pr√°ticas de C√≥digo
[Identificadas na an√°lise REAL:]
- **Documenta√ß√£o:** [N√≠vel de documenta√ß√£o encontrado]
- **Testes:** [Cobertura de testes se identificada]
- **Valida√ß√£o:** [Valida√ß√µes implementadas no c√≥digo]

#### Performance
[Baseada na an√°lise do c√≥digo:]
- **Otimiza√ß√µes:** [Otimiza√ß√µes REAIS identificadas]
- **Estruturas de dados:** [Estruturas REAIS utilizadas]

### Guia de Extens√£o

#### Como Adicionar Funcionalidades
[Baseado nos padr√µes REAIS identificados:]
1. **Seguir padr√£o:** [Padr√£o REAL identificado no projeto]
2. **Estrutura:** [Como novas funcionalidades devem se integrar]
3. **Depend√™ncias:** [Como gerenciar novas depend√™ncias]

#### Pontos de Extens√£o Identificados
[Baseados na arquitetura REAL:]
- **[Ponto de extens√£o 1]:** [Onde e como estender]
- **[Ponto de extens√£o 2]:** [Padr√£o para seguir]

### Configura√ß√£o de Ambiente

#### Depend√™ncias
[Baseadas nos arquivos REAIS de depend√™ncia:]
```bash
# Comandos baseados nos arquivos de depend√™ncia identificados
[Comandos REAIS de instala√ß√£o baseados nos arquivos encontrados]
```

#### Vari√°veis de Ambiente
[APENAS se identificadas no c√≥digo:]
- `[VAR_REAL]`: [Prop√≥sito baseado no c√≥digo]
- `[CONFIG_REAL]`: [Uso identificado na an√°lise]

### Debugging e Troubleshooting

#### Logs
[Baseados no sistema de log identificado:]
- **Sistema:** [Sistema de log REAL identificado]
- **N√≠veis:** [N√≠veis de log encontrados no c√≥digo]

#### Monitoramento
[APENAS se implementado no c√≥digo:]
- **M√©tricas:** [M√©tricas REAIS implementadas]
- **Health checks:** [Se implementados no c√≥digo]

## üìã Checklist de Implementa√ß√£o

### Pr√©-requisitos
[Baseados nas depend√™ncias REAIS:]
- [ ] [Requisito 1 baseado na an√°lise]
- [ ] [Requisito 2 identificado]

### Implementa√ß√£o
[Baseada nos padr√µes REAIS:]
- [ ] [Passo 1 baseado na estrutura real]
- [ ] [Passo 2 seguindo padr√µes identificados]

### Valida√ß√£o
[Baseada nas pr√°ticas REAIS encontradas:]
- [ ] [Valida√ß√£o 1 baseada no c√≥digo]
- [ ] [Teste 1 baseado na estrutura]

IMPORTANTE: Use SOMENTE padr√µes e implementa√ß√µes REAIS identificadas na an√°lise.
"""

    def _create_general_prompt(self, section: Dict, state: DocumentationState, final_url: str) -> str:
        """Cria prompt gen√©rico"""
        return f"""
Crie documenta√ß√£o para: {section['title']}

Descri√ß√£o: {section.get('description', 'Documenta√ß√£o geral')}

Reposit√≥rio: {final_url}

Crie documenta√ß√£o √∫til e informativa em formato Markdown.
"""
    
    def _create_fallback_content(self, section: Dict, state: DocumentationState) -> str:
        """Cria conte√∫do de fallback C4"""
        title = section.get('title', 'Documenta√ß√£o')
        repo_url = state.get("repo_url", "")
        
        return f"""# {title}

## üèóÔ∏è Documenta√ß√£o Arquitetural C4

Esta se√ß√£o documenta {title.lower()} seguindo o modelo de arquitetura C4.

## üöÄ Informa√ß√µes do Projeto

- **Projeto:** {repo_url}
- **Gerado em:** {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}
- **Sistema:** Skyone DocAgent v3.0
- **Modelo:** Arquitetura C4

## üìù Sobre o Modelo C4

O modelo C4 (Context, Container, Component, Code) fornece uma abordagem estruturada 
para visualizar a arquitetura de software em quatro n√≠veis hier√°rquicos.

## üîç An√°lise Necess√°ria

Para uma documenta√ß√£o completa desta se√ß√£o, √© necess√°ria uma an√°lise mais 
detalhada do c√≥digo-fonte do projeto.

---
*Gerado pelo Skyone DocAgent v3.0 ‚Ä¢ Arquitetura C4*
"""
    
    def _get_section_filename(self, title: str, index: int, anonymous: bool) -> str:
        """Gera nome do arquivo para se√ß√£o C4"""
        suffix = "_anonimo" if anonymous else ""
        
        title_lower = title.lower()
        if "context" in title_lower:
            return f"01_C4_Context_Diagram{suffix}.md"
        elif "container" in title_lower:
            return f"02_C4_Container_Diagram{suffix}.md"
        elif "component" in title_lower:
            return f"03_C4_Component_Diagram{suffix}.md"
        elif "c4" in title_lower and "code" in title_lower:
            return f"04_C4_Code_Analysis{suffix}.md"
        elif "detailed" in title_lower and "code" in title_lower:
            return f"05_Detailed_Code_Analysis{suffix}.md"
        elif "structure" in title_lower and "report" in title_lower:
            return f"06_Code_Structure_Report{suffix}.md"
        elif "technical" in title_lower and "implementation" in title_lower:
            return f"07_Technical_Implementation_Guide{suffix}.md"
        elif "mermaid" in title_lower or "flowchart" in title_lower:
            return f"08_Mermaid_Flowcharts{suffix}.md"
        elif "vis√£o" in title_lower or "geral" in title_lower:
            return f"01_visao_geral{suffix}.md"
        elif "instala√ß√£o" in title_lower or "guia" in title_lower:
            return f"02_guia_instalacao{suffix}.md"
        elif "t√©cnico" in title_lower or "relat√≥rio" in title_lower:
            return f"03_relatorio_tecnico{suffix}.md"
        else:
            safe_title = re.sub(r'[^\w\s-]', '', title)
            safe_title = re.sub(r'[-\s]+', '_', safe_title)
            return f"{index:02d}_{safe_title.lower()}{suffix}.md"

# =============================================================================
# CONSTRUTOR DO GRAFO LANGGRAPH
# =============================================================================

class DocAgentLangGraph:
    """Sistema principal de documenta√ß√£o baseado em LangGraph"""
    
    def __init__(self):
        self.llm_manager = LLMManager()
        self.agents = DocumentationAgents(self.llm_manager)
        self.graph = None
        self.app = None
        self.mermaid_generator = None
        self._build_graph()
        logger.info("DocAgent LangGraph inicializado")
    
    def _build_graph(self):
        """Constr√≥i o grafo LangGraph"""
        try:
            if not LANGGRAPH_AVAILABLE:
                logger.error("LangGraph n√£o dispon√≠vel")
                return
            
            # Criar grafo
            workflow = StateGraph(DocumentationState)
            
            # Adicionar n√≥s
            workflow.add_node("clone_repository", self.agents.clone_repository_node)
            workflow.add_node("analyze_structure", self.agents.analyze_structure_node)
            workflow.add_node("generate_plan", self.agents.generate_documentation_plan_node)
            workflow.add_node("generate_docs", self.agents.generate_documentation_node)
            
            # Definir fluxo
            workflow.set_entry_point("clone_repository")
            workflow.add_edge("clone_repository", "analyze_structure")
            workflow.add_edge("analyze_structure", "generate_plan")
            workflow.add_edge("generate_plan", "generate_docs")
            workflow.add_edge("generate_docs", END)
            
            # Compilar com mem√≥ria
            memory = MemorySaver()
            self.app = workflow.compile(checkpointer=memory)
            
            # Inicializar gerador Mermaid com o workflow
            self.mermaid_generator = MermaidGenerator(self.app)
            
            logger.info("Grafo LangGraph constru√≠do com sucesso")
            
        except Exception as e:
            logger.error(f"Erro ao construir grafo: {e}")
    
    async def execute_documentation_flow(self, request: AnalysisRequest) -> Dict[str, Any]:
        """Executa o fluxo completo de documenta√ß√£o"""
        try:
            if not self.app:
                raise Exception("Grafo LangGraph n√£o inicializado")
            
            logger.info(f"Iniciando fluxo de documenta√ß√£o para: {request.repo_url}")
            
            # Configurar modelo LLM
            model_config = ModelConfig(
                provider=request.model_provider,
                model_name=request.model_name,
                api_key=os.environ.get("OPENAI_API_KEY") if request.model_provider == "openai" else None
            )
            
            if not self.llm_manager.configure_model(model_config):
                raise Exception("Falha na configura√ß√£o do modelo LLM")
            
            # Estado inicial
            initial_state = DocumentationState(
                repo_url=request.repo_url,
                model_provider=request.model_provider,
                model_name=request.model_name,
                anonymous=request.anonymous,
                max_files=request.max_files,
                deep_analysis=request.deep_analysis,
                repo_path=None,
                current_phase="init",
                progress=0,
                logs=["üöÄ Iniciando an√°lise LangGraph"],
                file_structure=None,
                code_analysis=None,
                architecture_analysis=None,
                documentation_plan=None,
                generated_docs=[],
                metadata={
                    "start_time": datetime.now().isoformat(),
                    "system": "DocAgent LangGraph v3.0"
                },
                error_count=0
            )
            
            # Configura√ß√£o do thread
            config = RunnableConfig(
                thread_id=f"doc_session_{int(time.time())}",
                recursion_limit=50
            )
            
            # Executar fluxo
            final_state = await self.app.ainvoke(initial_state, config=config)
            
            # Preparar resultado
            result = {
                "status": "success" if final_state["error_count"] == 0 else "partial_success",
                "message": f"Documenta√ß√£o gerada: {len(final_state['generated_docs'])} arquivos",
                "generated_docs": final_state["generated_docs"],
                "metadata": {
                    **final_state["metadata"],
                    "end_time": datetime.now().isoformat(),
                    "total_errors": final_state["error_count"],
                    "final_phase": final_state["current_phase"],
                    "model_used": f"{request.model_provider}/{request.model_name}"
                },
                "logs": final_state["logs"]
            }
            
            logger.info(f"Fluxo conclu√≠do: {result['status']}")
            return result
            
        except Exception as e:
            logger.error(f"Erro no fluxo de documenta√ß√£o: {e}")
            return {
                "status": "error",
                "message": f"Erro cr√≠tico: {str(e)}",
                "generated_docs": [],
                "metadata": {
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                },
                "logs": [f"‚ùå Erro cr√≠tico: {str(e)}"]
            }

# =============================================================================
# API WEB COM FASTAPI
# =============================================================================

if not WEB_AVAILABLE:
    logger.error("FastAPI n√£o dispon√≠vel")
    exit(1)

# Configurar aplica√ß√£o FastAPI
if CONFIG_AVAILABLE:
    app = FastAPI(
        title=config.SYSTEM_NAME,
        version=config.VERSION,
        description=config.DESCRIPTION,
        debug=config.DEBUG
    )
    
    # Configurar CORS baseado nas configura√ß√µes
    if config.ENABLE_CORS:
        app.add_middleware(
            CORSMiddleware,
            allow_origins=config.ALLOWED_ORIGINS,
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )
else:
    app = FastAPI(
        title="DocAgent LangGraph",
        version="3.0",
        description="Sistema de Documenta√ß√£o Autom√°tica com LangGraph, OpenAI e Ollama"
    )
    
    # CORS padr√£o
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

# Configurar diret√≥rios
if CONFIG_AVAILABLE:
    config.create_directories()
    static_dir = config.STATIC_DIR
    templates_dir = config.TEMPLATES_DIR
    docs_dir = config.DOCS_DIR
    workdir = config.WORKDIR
else:
    static_dir = Path("static")
    templates_dir = Path("templates")
    docs_dir = Path("docs")
    workdir = Path("workdir")
    
    for directory in [static_dir, templates_dir, docs_dir, workdir]:
        directory.mkdir(exist_ok=True)

try:
    app.mount("/static", StaticFiles(directory=str(static_dir)), name="static")
    templates = Jinja2Templates(directory=str(templates_dir))
except Exception as e:
    logger.warning(f"Erro ao configurar arquivos est√°ticos: {e}")

# Estado global da aplica√ß√£o
app_state = {
    "doc_agent": DocAgentLangGraph(),
    "github_fetcher": GitHubRepositoryFetcher(),
    "current_analysis": None,
    "analysis_status": AnalysisStatus(
        status="idle",
        phase="Aguardando",
        progress=0,
        message="Sistema LangGraph pronto"
    ),
    "user_sessions": {}
}

# =============================================================================
# ROTAS DA API
# =============================================================================

@app.get("/", response_class=HTMLResponse)
async def home(request: Request):
    """P√°gina principal"""
    try:
        return templates.TemplateResponse("index.html", {"request": request})
    except Exception as e:
        logger.error(f"Erro ao carregar template: {e}")
        return HTMLResponse(content="<h1>DocAgent LangGraph</h1><p>Erro ao carregar interface</p>")

@app.post("/api/search")
async def search_repositories(search_request: SearchRequest):
    """Busca reposit√≥rios"""
    try:
        logger.info(f"Buscando reposit√≥rios para: {search_request.usuario}")
        
        repositories = app_state["github_fetcher"].search_repositories(
            search_request.usuario,
            search_request.incluir_forks
        )
        
        return {
            "success": True,
            "repositories": [asdict(repo) for repo in repositories],
            "count": len(repositories),
            "user": search_request.usuario
        }
    except Exception as e:
        logger.error(f"Erro na busca: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/analyze")
async def start_analysis(analysis_request: AnalysisRequest, background_tasks: BackgroundTasks):
    """Inicia an√°lise com LangGraph"""
    try:
        logger.info(f"Iniciando an√°lise LangGraph: {analysis_request.repo_url}")
        
        # Reset status
        app_state["analysis_status"] = AnalysisStatus(
            status="starting",
            phase="Iniciando LangGraph",
            progress=0,
            message="Preparando sistema LangGraph...",
            logs=["üöÄ Sistema LangGraph iniciado"]
        )
        
        # Iniciar em background
        background_tasks.add_task(run_langgraph_analysis, analysis_request)
        
        return {
            "success": True,
            "message": "An√°lise LangGraph iniciada",
            "analysis_id": f"langgraph_{int(time.time())}",
            "model": f"{analysis_request.model_provider}/{analysis_request.model_name}"
        }
    except Exception as e:
        logger.error(f"Erro ao iniciar an√°lise: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/status")
async def get_analysis_status():
    """Obt√©m status da an√°lise"""
    try:
        return app_state["analysis_status"]
    except Exception as e:
        logger.error(f"Erro ao obter status: {e}")
        return AnalysisStatus(
            status="error",
            phase="Erro",
            progress=0,
            message=f"Erro no sistema: {str(e)}"
        )

@app.get("/api/results")
async def get_analysis_results():
    """Obt√©m resultados da an√°lise"""
    try:
        if app_state["current_analysis"]:
            return app_state["current_analysis"]
        else:
            raise HTTPException(status_code=404, detail="Nenhuma an√°lise dispon√≠vel")
    except Exception as e:
        logger.error(f"Erro ao obter resultados: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/models")
async def list_models():
    """Lista modelos dispon√≠veis"""
    try:
        available = app_state["doc_agent"].llm_manager.list_available_models()
        return {
            "success": True,
            "available": available,
            "providers": ["openai", "ollama"]
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/api/download/{filename}")
async def download_file(filename: str):
    """Download de arquivo gerado"""
    try:
        if ".." in filename or "/" in filename:
            raise HTTPException(status_code=400, detail="Nome de arquivo inv√°lido")
        
        file_path = Path("docs") / filename
        
        if file_path.exists() and file_path.is_file():
            return FileResponse(file_path, filename=filename)
        else:
            raise HTTPException(status_code=404, detail="Arquivo n√£o encontrado")
            
    except Exception as e:
        logger.error(f"Erro no download: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/download-all-zip")
async def download_all_docs():
    """Download de todos os documentos em ZIP"""
    try:
        docs_dir = Path("docs")
        if not docs_dir.exists():
            raise HTTPException(status_code=404, detail="Nenhum documento encontrado")
        
        doc_files = list(docs_dir.glob("*.md")) + list(docs_dir.glob("*.json")) + list(docs_dir.glob("*.png"))
        
        if not doc_files:
            raise HTTPException(status_code=404, detail="Nenhum documento dispon√≠vel")
        
        # Criar ZIP
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        zip_filename = f"skyone_docagent_{timestamp}.zip"
        zip_path = docs_dir / zip_filename
        
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for doc_file in doc_files:
                zipf.write(doc_file, doc_file.name)
        
        return FileResponse(
            zip_path,
            filename=zip_filename,
            media_type="application/zip"
        )
        
    except Exception as e:
        logger.error(f"Erro ao criar ZIP: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/generate-mermaid-chart")
async def generate_mermaid_chart():
    """Gera diagrama Mermaid do workflow como imagem SVG"""
    try:
        # Gerar diagrama do workflow Skyone DocAgent
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        chart_filename = f"skyone_workflow_chart_{timestamp}.html"
        chart_path = Path("docs") / chart_filename
        
        # HTML com Mermaid incorporado para visualiza√ß√£o como imagem
        chart_content = f"""<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Skyone DocAgent - Workflow Chart</title>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>
    <style>
        body {{
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #1a365d 0%, #4a90e2 100%);
            font-family: 'Arial', sans-serif;
            color: white;
        }}
        .container {{
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 15px;
            padding: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }}
        .header {{
            text-align: center;
            margin-bottom: 30px;
            color: #1a365d;
        }}
        .mermaid {{
            text-align: center;
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            border: 2px solid #1a365d;
        }}
        .footer {{
            text-align: center;
            margin-top: 20px;
            color: #666;
            font-size: 14px;
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ü§ñ Skyone DocAgent - Workflow Chart</h1>
            <p>Fluxo completo de documenta√ß√£o C4 + An√°lise Detalhada</p>
            <p><strong>Gerado em:</strong> {datetime.now().strftime('%d/%m/%Y √†s %H:%M:%S')}</p>
        </div>
        
        <div class="mermaid">
flowchart TD
    A[üöÄ In√≠cio] --> B[üß† Configurar Modelo IA]
    B --> C[üìÅ Selecionar Diret√≥rio Local]
    C --> D[üîç Analisar Estrutura]
    D --> E[üìã Gerar Plano C4]
    
    E --> F[üåê C4 Context Diagram]
    F --> G[üì¶ C4 Container Diagram]
    G --> H[üß© C4 Component Diagram]
    H --> I[üíª C4 Code Analysis]
    
    I --> J[üî¨ Detailed Code Analysis]
    J --> K[üìä Structure Report]
    K --> L[üõ†Ô∏è Implementation Guide]
    L --> M[üîÑ Mermaid Flowcharts]
    
    M --> N[‚úÖ Documenta√ß√£o Completa]
    N --> O[üì• Download ZIP]
    
    subgraph "Fase 1: Prepara√ß√£o"
        A
        B
        C
        D
        E
    end
    
    subgraph "Fase 2: Arquitetura C4"
        F
        G
        H
        I
    end
    
    subgraph "Fase 3: An√°lise Detalhada"
        J
        K
        L
        M
    end
    
    subgraph "Fase 4: Finaliza√ß√£o"
        N
        O
    end
    
    style A fill:#1a365d,stroke:#fff,stroke-width:3px,color:#fff
    style O fill:#4a90e2,stroke:#fff,stroke-width:3px,color:#fff
    style F fill:#e1f5fe,stroke:#1a365d,stroke-width:2px
    style G fill:#e1f5fe,stroke:#1a365d,stroke-width:2px
    style H fill:#e1f5fe,stroke:#1a365d,stroke-width:2px
    style I fill:#e1f5fe,stroke:#1a365d,stroke-width:2px
    style J fill:#e8f5e8,stroke:#4a90e2,stroke-width:2px
    style K fill:#e8f5e8,stroke:#4a90e2,stroke-width:2px
    style L fill:#e8f5e8,stroke:#4a90e2,stroke-width:2px
    style M fill:#e8f5e8,stroke:#4a90e2,stroke-width:2px
        </div>
        
        <div class="footer">
            <p><strong>Skyone DocAgent v3.0</strong> ‚Ä¢ Documenta√ß√£o Autom√°tica com IA</p>
            <p>C4 Architecture + An√°lise Detalhada ‚Ä¢ 8 Documentos T√©cnicos</p>
            <p><em>Para salvar como imagem: Clique com bot√£o direito ‚Üí "Salvar imagem como..."</em></p>
        </div>
    </div>
    
    <script>
        mermaid.initialize({{
            startOnLoad: true,
            theme: 'default',
            themeVariables: {{
                primaryColor: '#1a365d',
                primaryTextColor: '#fff',
                primaryBorderColor: '#4a90e2',
                lineColor: '#2d5a87'
            }}
        }});
    </script>
</body>
</html>"""
        
        # Salvar arquivo HTML
        with open(chart_path, 'w', encoding='utf-8') as f:
            f.write(chart_content)
        
        logger.info(f"Chart HTML gerado: {chart_filename}")
        
        return FileResponse(
            chart_path,
            filename=chart_filename,
            media_type="text/html"
        )
        
    except Exception as e:
        logger.error(f"Erro ao gerar chart: {e}")
        raise HTTPException(status_code=500, detail=str(e))

class ModelSelectionRequest(BaseModel):
    """Requisi√ß√£o para configurar modelo"""
    provider: str  # "openai" ou "ollama"
    model_name: str
    api_key: Optional[str] = None
    base_url: Optional[str] = None

@app.post("/api/configure-model")
async def configure_model(model_request: ModelSelectionRequest):
    """Configura modelo LLM (OpenAI ou Ollama)"""
    try:
        logger.info(f"Configurando modelo: {model_request.provider}/{model_request.model_name}")
        
        # Validar provider
        if model_request.provider not in ["openai", "ollama"]:
            raise HTTPException(status_code=400, detail="Provider deve ser 'openai' ou 'ollama'")
        
        # Configurar modelo no DocAgent
        doc_agent = app_state["doc_agent"]
        config = ModelConfig(
            provider=model_request.provider,
            model_name=model_request.model_name,
            api_key=model_request.api_key,
            base_url=model_request.base_url
        )
        
        # Se for OpenAI e n√£o tiver API key na requisi√ß√£o, tentar pegar do ambiente
        if model_request.provider == "openai" and not model_request.api_key:
            config.api_key = os.environ.get("OPENAI_API_KEY")
            if not config.api_key:
                raise HTTPException(
                    status_code=400, 
                    detail="API Key OpenAI necess√°ria. Configure OPENAI_API_KEY ou forne√ßa na requisi√ß√£o."
                )
        
        # Configurar no LLM manager
        success = doc_agent.llm_manager.configure_model(config)
        
        if success:
            return {
                "success": True,
                "message": f"Modelo configurado: {model_request.provider}/{model_request.model_name}",
                "provider": model_request.provider,
                "model": model_request.model_name
            }
        else:
            raise HTTPException(status_code=500, detail="Falha ao configurar modelo")
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro ao configurar modelo: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/models/available")
async def get_available_models():
    """Lista todos os modelos dispon√≠veis"""
    try:
        doc_agent = app_state["doc_agent"]
        available = doc_agent.llm_manager.list_available_models()
        
        # Obter modelos Ollama detalhados
        ollama_models_detailed = doc_agent.llm_manager.get_ollama_models_detailed()
        
        # Verificar se OpenAI est√° configurada
        openai_configured = bool(os.environ.get("OPENAI_API_KEY"))
        
        # Verificar status do Ollama
        ollama_status = "unknown"
        try:
            result = subprocess.run(["ollama", "list"], capture_output=True, text=True, timeout=5)
            ollama_status = "running" if result.returncode == 0 else "stopped"
        except:
            ollama_status = "not_installed"
        
        return {
            "success": True,
            "models": available,
            "ollama_detailed": ollama_models_detailed,
            "status": {
                "openai_configured": openai_configured,
                "ollama_status": ollama_status
            },
            "recommended": {
                "openai": "gpt-4o",
                "ollama": ollama_models_detailed[0]["name"] if ollama_models_detailed else "qwen2.5:7b"
            }
        }
    except Exception as e:
        logger.error(f"Erro ao listar modelos: {e}")
        return {"success": False, "error": str(e)}

@app.post("/api/test-model")
async def test_model_connection(model_request: ModelSelectionRequest):
    """Testa conex√£o com modelo LLM"""
    try:
        logger.info(f"Testando modelo: {model_request.provider}/{model_request.model_name}")
        
        # Criar configura√ß√£o tempor√°ria
        config = ModelConfig(
            provider=model_request.provider,
            model_name=model_request.model_name,
            api_key=model_request.api_key,
            base_url=model_request.base_url
        )
        
        # Testar configura√ß√£o
        temp_manager = LLMManager()
        success = temp_manager.configure_model(config)
        
        if not success:
            raise Exception("Falha na configura√ß√£o do modelo")
        
        # Teste simples de gera√ß√£o
        test_llm = temp_manager.get_llm()
        test_message = HumanMessage(content="Responda apenas 'OK' se voc√™ est√° funcionando.")
        
        # Timeout para o teste
        import asyncio
        try:
            result = await asyncio.wait_for(
                test_llm.ainvoke([test_message]),
                timeout=30.0
            )
            
            response_text = result.content if hasattr(result, 'content') else str(result)
            
            return {
                "success": True,
                "message": f"Modelo {model_request.provider}/{model_request.model_name} testado com sucesso",
                "test_response": response_text[:100],
                "provider": model_request.provider,
                "model": model_request.model_name
            }
            
        except asyncio.TimeoutError:
            raise Exception("Timeout na resposta do modelo (30s)")
            
    except Exception as e:
        logger.error(f"Erro no teste do modelo: {e}")
        return {
            "success": False,
            "error": str(e),
            "provider": model_request.provider,
            "model": model_request.model_name
        }

@app.get("/health")
async def health_check():
    """Verifica√ß√£o de sa√∫de"""
    try:
        checks = {
            "langgraph_available": LANGGRAPH_AVAILABLE,
            "doc_agent_ready": app_state["doc_agent"] is not None,
            "github_fetcher_ready": app_state["github_fetcher"] is not None,
            "docs_directory": Path("docs").exists(),
            "workdir_exists": Path("workdir").exists()
        }
        
        # Verificar status do Ollama
        ollama_status = "unknown"
        try:
            result = subprocess.run(["ollama", "list"], capture_output=True, text=True, timeout=5)
            ollama_status = "running" if result.returncode == 0 else "stopped"
        except:
            ollama_status = "not_installed"
        
        # Verificar OpenAI
        openai_configured = bool(os.environ.get("OPENAI_API_KEY"))
        
        all_healthy = all(checks.values())
        
        return {
            "status": "healthy" if all_healthy else "degraded",
            "checks": checks,
            "langgraph_enabled": LANGGRAPH_AVAILABLE,
            "model_status": {
                "ollama_status": ollama_status,
                "openai_configured": openai_configured
            },
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

# =============================================================================
# FUN√á√ÉO DE AN√ÅLISE EM BACKGROUND
# =============================================================================

async def run_langgraph_analysis(analysis_request: AnalysisRequest):
    """Executa an√°lise LangGraph em background"""
    
    def update_status(phase: str, progress: int, message: str, step: str = ""):
        """Atualiza status da an√°lise"""
        current_logs = app_state["analysis_status"].logs.copy()
        if step:
            current_logs.append(f"üîÑ {step}: {message}")
        
        app_state["analysis_status"] = AnalysisStatus(
            status="running",
            phase=phase,
            progress=progress,
            message=message,
            logs=current_logs,
            current_step=step
        )
        logger.info(f"Status: {phase} ({progress}%) - {message}")
    
    try:
        logger.info(f"Background: Iniciando an√°lise LangGraph de {analysis_request.repo_url}")
        
        # Fase 1: Inicializa√ß√£o
        update_status("Inicializa√ß√£o LangGraph", 5, "Preparando sistema...", "Setup")
        
        doc_agent = app_state["doc_agent"]
        if not doc_agent or not doc_agent.app:
            raise Exception("DocAgent LangGraph n√£o inicializado")
        
        # Verificar se modelo est√° configurado
        if not doc_agent.llm_manager.current_config:
            # Configurar modelo padr√£o se n√£o estiver configurado
            default_config = ModelConfig(
                provider=analysis_request.model_provider,
                model_name=analysis_request.model_name
            )
            
            if analysis_request.model_provider == "openai":
                default_config.api_key = os.environ.get("OPENAI_API_KEY")
                if not default_config.api_key:
                    raise Exception("API Key OpenAI n√£o configurada")
            
            success = doc_agent.llm_manager.configure_model(default_config)
            if not success:
                raise Exception("Falha ao configurar modelo LLM")
        
        update_status("Configura√ß√£o", 8, f"Modelo {analysis_request.model_provider}/{analysis_request.model_name} configurado", "LLM")
        
        # Fase 2: Execu√ß√£o do fluxo
        update_status("Execu√ß√£o LangGraph", 10, "Executando fluxo de documenta√ß√£o...", "Flow")
        
        result = await doc_agent.execute_documentation_flow(analysis_request)
        
        if result["status"] in ["success", "partial_success"]:
            # Sucesso
            app_state["current_analysis"] = {
                "status": result["status"],
                "message": result["message"],
                "repository_url": analysis_request.repo_url,
                "analysis_data": result,
                "generated_docs": result["generated_docs"],
                "timestamp": datetime.now().isoformat(),
                "langgraph_enabled": True,
                "analysis_type": "LangGraph_enhanced",
                "model_used": f"{analysis_request.model_provider}/{analysis_request.model_name}"
            }
            
            app_state["analysis_status"] = AnalysisStatus(
                status="completed",
                phase="Conclu√≠do",
                progress=100,
                message=f"An√°lise LangGraph conclu√≠da! {len(result['generated_docs'])} documentos gerados.",
                logs=result["logs"] + ["üéâ An√°lise LangGraph finalizada"],
                current_step="Pronto para download"
            )
            
            logger.info(f"Background: An√°lise conclu√≠da - {len(result['generated_docs'])} arquivos")
        else:
            # Erro
            raise Exception(result.get("message", "Erro desconhecido"))
        
    except Exception as e:
        error_msg = f"Erro na an√°lise LangGraph: {str(e)}"
        logger.error(f"Background: {error_msg}")
        traceback.print_exc()
        
        app_state["analysis_status"] = AnalysisStatus(
            status="error",
            phase="Erro",
            progress=0,
            message=error_msg,
            logs=app_state["analysis_status"].logs + [f"‚ùå {error_msg}"],
            current_step="Falha"
        )

# =============================================================================
# FUN√á√ÉO PRINCIPAL
# =============================================================================

def main():
    """Fun√ß√£o principal"""
    try:
        print("üöÄ Iniciando DocAgent LangGraph v3.0")
        print("=" * 80)
        
        # Verificar depend√™ncias
        if not LANGGRAPH_AVAILABLE:
            print("‚ùå LangGraph n√£o dispon√≠vel")
            print("Execute: pip install langgraph langchain langchain-openai langchain-community")
            return 1
        
        if not WEB_AVAILABLE:
            print("‚ùå FastAPI n√£o dispon√≠vel")
            print("Execute: pip install fastapi uvicorn jinja2")
            return 1
        
        # Validar ambiente se configura√ß√£o dispon√≠vel
        if CONFIG_AVAILABLE:
            print("üîç Validando ambiente...")
            checks = config.validate_environment()
            
            for check_name, status in checks.items():
                icon = "‚úÖ" if status else "‚ö†Ô∏è"
                print(f"   {icon} {check_name}: {'OK' if status else 'N√£o dispon√≠vel'}")
            
            # Verificar se h√° problemas cr√≠ticos
            critical_checks = ["git_available", "directories_writable"]
            if not all(checks[check] for check in critical_checks if check in checks):
                print("‚ùå Verifica√ß√µes cr√≠ticas falharam")
                return 1
        else:
            # Verifica√ß√µes b√°sicas
            try:
                subprocess.run(["git", "--version"], capture_output=True, check=True)
                print("‚úÖ Git dispon√≠vel")
            except:
                print("‚ùå Git n√£o encontrado")
                return 1
            
            # Criar diret√≥rios b√°sicos
            for dir_name in ["docs", "workdir", "static", "templates", "logs"]:
                Path(dir_name).mkdir(exist_ok=True)
        
        print("\n" + "="*80)
        print("ü§ñ DocAgent LangGraph v3.0 - Sistema de Documenta√ß√£o Avan√ßada")
        print("="*80)
        print("üöÄ Funcionalidades Ativas:")
        print("   ‚úÖ LangGraph para fluxo de agentes especializados")
        print("   ‚úÖ Suporte OpenAI GPT-4 e Ollama local")
        print("   ‚úÖ An√°lise completa de reposit√≥rios GitHub")
        print("   ‚úÖ Documenta√ß√£o t√©cnica autom√°tica")
        print("   ‚úÖ Relat√≥rios an√¥nimos profissionais")
        print("   ‚úÖ Interface web moderna e responsiva")
        print("   ‚úÖ API REST completa com valida√ß√£o")
        print("   ‚úÖ Download individual e ZIP completo")
        print("   ‚úÖ Sistema de tools avan√ßadas")
        print("   ‚úÖ Checkpoints para recupera√ß√£o de estado")
        print("="*80)
        
        # Configura√ß√µes do servidor
        if CONFIG_AVAILABLE:
            host = config.HOST
            port = config.PORT
            log_level = config.LOG_LEVEL.lower()
        else:
            host = "0.0.0.0"
            port = 8001
            log_level = "info"
        
        print("üîó URLs de Acesso:")
        print(f"   üè† Interface Principal: http://localhost:{port}")
        print(f"   üìö Documenta√ß√£o API:   http://localhost:{port}/docs")
        print(f"   ‚ù§Ô∏è  Health Check:      http://localhost:{port}/health")
        print(f"   üìä Modelos Dispon√≠veis: http://localhost:{port}/api/models/available")
        print("="*80)
        print("üõ†Ô∏è Configura√ß√µes:")
        
        if os.environ.get("OPENAI_API_KEY"):
            print("   ‚úÖ OpenAI API Key configurada")
        else:
            print("   ‚ö†Ô∏è  OpenAI API Key n√£o configurada")
            print("      Configure: export OPENAI_API_KEY=sk-...")
        
        if os.environ.get("GITHUB_TOKEN"):
            print("   ‚úÖ GitHub Token configurado")
        else:
            print("   ‚ö†Ô∏è  GitHub Token n√£o configurado")
            print("      Para repos privados: export GITHUB_TOKEN=ghp_...")
        
        # Verificar Ollama
        try:
            result = subprocess.run(["ollama", "list"], capture_output=True, timeout=3)
            if result.returncode == 0:
                print("   ‚úÖ Ollama dispon√≠vel")
            else:
                print("   ‚ö†Ô∏è  Ollama n√£o est√° rodando")
                print("      Execute: ollama serve")
        except:
            print("   ‚ö†Ô∏è  Ollama n√£o instalado")
            print("      Instale em: https://ollama.ai/")
        
        print("="*80)
        print("üåü Iniciando servidor web...")
        print(f"üéØ Acesse: http://localhost:{port}")
        print("üîß Pressione Ctrl+C para parar")
        print("="*80)
        
        # Iniciar servidor
        uvicorn.run(
            app,
            host=host,
            port=port,
            log_level=log_level,
            access_log=True
        )
        
    except KeyboardInterrupt:
        print("\nüëã Encerrando DocAgent LangGraph...")
        print("   Obrigado por usar o sistema!")
        return 0
    except Exception as e:
        logger.error(f"Erro cr√≠tico: {e}")
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit(main())
