#!/usr/bin/env python3
"""
DocAgent LangGraph - Sistema de Documenta√ß√£o Autom√°tica de Reposit√≥rios
=======================================================================

Sistema avan√ßado baseado em LangGraph para an√°lise e documenta√ß√£o completa
de reposit√≥rios GitHub, com suporte para OpenAI e Ollama.

Caracter√≠sticas:
- Arquitetura baseada em LangGraph com fluxo de estados
- Agentes especializados para an√°lise e documenta√ß√£o
- Suporte para OpenAI GPT-4 e modelos Ollama locais
- Interface web moderna com autentica√ß√£o
- Relat√≥rios an√¥nimos e documenta√ß√£o t√©cnica completa
- Sistema de tools avan√ßadas para an√°lise de c√≥digo
- Arquitetura C4 Model para documenta√ß√£o arquitetural

- DocAgent Skyone v3.0 LangGraph 
"""

import os
import sys
import json
import subprocess
import tempfile
import shutil
import time
import logging
import traceback
import hashlib
import re
import fnmatch
import zipfile
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any, Union, TypedDict, Annotated
from dataclasses import dataclass, asdict
from concurrent.futures import ThreadPoolExecutor
import asyncio

# Importar configura√ß√µes
try:
    from config import config
    CONFIG_AVAILABLE = True
    print("‚úÖ Configura√ß√µes carregadas")
except ImportError:
    CONFIG_AVAILABLE = False
    print("‚ö†Ô∏è Arquivo de configura√ß√£o n√£o encontrado - usando padr√µes")

# LangGraph e LangChain imports
try:
    from langgraph.graph import StateGraph, END
    from langgraph.prebuilt import ToolNode
    from langgraph.checkpoint.memory import MemorySaver
    from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
    from langchain_core.tools import tool
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_openai import ChatOpenAI
    from langchain_community.llms import Ollama
    from langchain_core.runnables import RunnableConfig
    LANGGRAPH_AVAILABLE = True
    print("‚úÖ LangGraph e LangChain dispon√≠veis")
except ImportError as e:
    LANGGRAPH_AVAILABLE = False
    print(f"‚ùå LangGraph/LangChain n√£o dispon√≠vel: {e}")
    print("Execute: pip install langgraph langchain langchain-openai langchain-community")

# FastAPI e depend√™ncias web
try:
    from fastapi import FastAPI, Request, HTTPException, BackgroundTasks
    from fastapi.responses import HTMLResponse, JSONResponse, FileResponse
    from fastapi.staticfiles import StaticFiles
    from fastapi.templating import Jinja2Templates
    from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
    from fastapi.middleware.cors import CORSMiddleware
    import uvicorn
    WEB_AVAILABLE = True
    print("‚úÖ FastAPI dispon√≠vel")
except ImportError as e:
    WEB_AVAILABLE = False
    print(f"‚ùå FastAPI n√£o dispon√≠vel: {e}")

# Pydantic
try:
    from pydantic import BaseModel, Field, ConfigDict
    PYDANTIC_V2 = True
    print("‚úÖ Pydantic V2 detectado")
except ImportError:
    try:
        from pydantic import BaseModel, Field
        PYDANTIC_V2 = False
        print("‚ö†Ô∏è Pydantic V1 em uso")
    except ImportError as e:
        print(f"‚ùå Pydantic n√£o dispon√≠vel: {e}")
        exit(1)

# Configurar logging
if CONFIG_AVAILABLE:
    # Criar diret√≥rio de logs
    config.LOGS_DIR.mkdir(exist_ok=True)
    
    logging.basicConfig(
        level=getattr(logging, config.LOG_LEVEL),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(config.LOG_FILE),
            logging.StreamHandler(sys.stdout)
        ]
    )
else:
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

logger = logging.getLogger(__name__)

# =============================================================================
# ESTADO DO LANGGRAPH - DEFINI√á√ïES PRINCIPAIS
# =============================================================================

class DocumentationState(TypedDict):
    """Estado principal do fluxo LangGraph para documenta√ß√£o"""
    # Entrada
    repo_url: str
    model_provider: str  # "openai" ou "ollama"
    model_name: str
    anonymous: bool
    max_files: int
    deep_analysis: bool
    
    # Estado do processamento
    repo_path: Optional[str]
    current_phase: str
    progress: int
    logs: List[str]
    
    # An√°lise
    file_structure: Optional[Dict[str, Any]]
    code_analysis: Optional[Dict[str, Any]]
    architecture_analysis: Optional[Dict[str, Any]]
    
    # Documenta√ß√£o
    documentation_plan: Optional[Dict[str, Any]]
    generated_docs: List[str]
    
    # Metadata
    metadata: Dict[str, Any]
    error_count: int

# =============================================================================
# MODELOS DE DADOS
# =============================================================================

@dataclass
class RepositoryInfo:
    """Informa√ß√µes de um reposit√≥rio GitHub"""
    nome: str
    nome_completo: str
    descricao: str
    url: str
    linguagem_principal: str
    estrelas: int
    forks: int
    tamanho_kb: int
    atualizado_em: str
    topicos: List[str]
    privado: bool

@dataclass
class FileAnalysis:
    """An√°lise detalhada de um arquivo"""
    name: str
    path: str
    language: str
    size: int
    lines: int
    functions: List[str]
    classes: List[str]
    imports: List[str]
    purpose: str
    summary: str
    complexity: str

class AnalysisRequest(BaseModel):
    """Requisi√ß√£o de an√°lise"""
    repo_url: str
    model_provider: str = "ollama"  # "openai" ou "ollama"
    model_name: str = "qwen2.5:7b"
    max_files: int = 50
    deep_analysis: bool = True
    anonymous: bool = True
    local_directory: Optional[str] = None  # Para an√°lise de diret√≥rio local

class AnalysisStatus(BaseModel):
    """Status da an√°lise"""
    status: str
    phase: str
    progress: int
    message: str
    logs: List[str] = []
    current_step: str = ""

class SearchRequest(BaseModel):
    """Requisi√ß√£o de busca de reposit√≥rios"""
    usuario: str
    incluir_forks: bool = False

class ModelConfig(BaseModel):
    """Configura√ß√£o de modelos"""
    provider: str  # "openai" ou "ollama"
    model_name: str
    api_key: Optional[str] = None
    base_url: Optional[str] = None
    temperature: float = 0.1
    max_tokens: int = 8192

# =============================================================================
# SISTEMA DE ANONIMIZA√á√ÉO
# =============================================================================

class AnonymizationSystem:
    """Sistema para anonimizar informa√ß√µes pessoais"""
    
    def __init__(self):
        self.user_mapping = {}
        self.repo_mapping = {}
        self.counter = 1
        print("üîí Sistema de anonimiza√ß√£o inicializado")
    
    def anonymize_repo_url(self, url: str) -> str:
        """Anonimiza URL do reposit√≥rio"""
        try:
            match = re.search(r'github\.com/([^/]+)/([^/]+)', url)
            if match:
                user, repo = match.groups()
                
                if user not in self.user_mapping:
                    self.user_mapping[user] = f"usuario_anonimo_{self.counter}"
                    self.counter += 1
                
                if repo not in self.repo_mapping:
                    self.repo_mapping[repo] = f"projeto_anonimo_{len(self.repo_mapping) + 1}"
                
                anon_user = self.user_mapping[user]
                anon_repo = self.repo_mapping[repo]
                
                return f"https://github.com/{anon_user}/{anon_repo}"
            
            return "https://github.com/usuario_anonimo/projeto_anonimo"
            
        except Exception as e:
            logger.warning(f"Erro na anonimiza√ß√£o: {e}")
            return "https://github.com/usuario_anonimo/projeto_anonimo"

# =============================================================================
# SISTEMA DE BUSCA GITHUB
# =============================================================================

class GitHubRepositoryFetcher:
    """Sistema para buscar reposit√≥rios do GitHub"""
    
    def __init__(self):
        self.session_cache = {}
        self.rate_limit_info = {}
        self.last_request_time = 0
        self.min_request_interval = 1.0
        print("üîç Sistema de busca GitHub inicializado")
    
    def _rate_limit_wait(self):
        """Implementa rate limiting b√°sico"""
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        
        if time_since_last < self.min_request_interval:
            wait_time = self.min_request_interval - time_since_last
            time.sleep(wait_time)
        
        self.last_request_time = time.time()
    
    def search_repositories(self, user_or_org: str, include_forks: bool = False) -> List[RepositoryInfo]:
        """Busca reposit√≥rios de um usu√°rio ou organiza√ß√£o"""
        try:
            clean_user = self._extract_user_from_input(user_or_org)
            logger.info(f"Buscando reposit√≥rios de: {clean_user}")
            
            if not self._verify_user_exists(clean_user):
                logger.error(f"Usu√°rio/organiza√ß√£o n√£o encontrado: {clean_user}")
                return []
            
            repositories = []
            page = 1
            
            while len(repositories) < 50 and page <= 5:
                repos_api_url = f"https://api.github.com/users/{clean_user}/repos?per_page=30&sort=updated&page={page}"
                
                try:
                    self._rate_limit_wait()
                    repos_data = self._make_github_request(repos_api_url)
                    
                    if not repos_data:
                        break
                    
                    for repo_data in repos_data:
                        if not include_forks and repo_data.get('fork', False):
                            continue
                        
                        if repo_data.get('private', False) and not os.environ.get('GITHUB_TOKEN'):
                            continue
                        
                        repo_info = self._process_repository_data(repo_data)
                        if repo_info:
                            repositories.append(repo_info)
                    
                    if len(repos_data) < 30:
                        break
                    
                    page += 1
                    
                except Exception as e:
                    logger.warning(f"Erro na p√°gina {page}: {e}")
                    break
            
            logger.info(f"Encontrados {len(repositories)} reposit√≥rios")
            return sorted(repositories, key=lambda x: x.estrelas, reverse=True)
            
        except Exception as e:
            logger.error(f"Erro ao buscar reposit√≥rios: {e}")
            return []
    
    def _extract_user_from_input(self, input_str: str) -> str:
        """Extrai nome de usu√°rio de diferentes formatos"""
        input_str = input_str.strip()
        
        if 'github.com' in input_str:
            match = re.search(r'github\.com/([^/]+)', input_str)
            if match:
                return match.group(1)
        
        return re.sub(r'[^a-zA-Z0-9\-_]', '', input_str)
    
    def _verify_user_exists(self, user: str) -> bool:
        """Verifica se usu√°rio existe"""
        try:
            import urllib.request
            url = f"https://api.github.com/users/{user}"
            self._rate_limit_wait()
            response = self._make_github_request(url)
            return response is not None
        except Exception as e:
            logger.warning(f"Erro ao verificar usu√°rio: {e}")
            return False
    
    def _make_github_request(self, url: str) -> Optional[Dict]:
        """Faz requisi√ß√£o para API do GitHub"""
        try:
            import urllib.request
            import urllib.error
            
            request = urllib.request.Request(url)
            request.add_header('User-Agent', 'Mozilla/5.0 (compatible; DocAgent-LangGraph/3.0)')
            request.add_header('Accept', 'application/vnd.github.v3+json')
            
            github_token = os.environ.get('GITHUB_TOKEN')
            if github_token:
                request.add_header('Authorization', f'token {github_token}')
            
            with urllib.request.urlopen(request, timeout=30) as response:
                if response.getcode() == 200:
                    return json.loads(response.read().decode('utf-8'))
                else:
                    logger.warning(f"Resposta HTTP {response.getcode()}")
                    return None
                    
        except urllib.error.HTTPError as e:
            if e.code == 404:
                logger.error(f"Recurso n√£o encontrado (404): {url}")
            elif e.code == 403:
                logger.error("403: Rate limit ou permiss√£o insuficiente")
            elif e.code == 401:
                logger.error("401: Token inv√°lido ou expirado")
            else:
                logger.error(f"Erro HTTP {e.code}: {e.reason}")
            return None
        except Exception as e:
            logger.error(f"Erro na requisi√ß√£o: {e}")
            return None
    
    def _process_repository_data(self, repo_data: Dict) -> Optional[RepositoryInfo]:
        """Processa dados do reposit√≥rio"""
        try:
            return RepositoryInfo(
                nome=repo_data.get('name', ''),
                nome_completo=repo_data.get('full_name', ''),
                descricao=(repo_data.get('description') or 'Sem descri√ß√£o')[:200],
                url=repo_data.get('html_url', ''),
                linguagem_principal=repo_data.get('language') or 'Desconhecida',
                estrelas=repo_data.get('stargazers_count', 0),
                forks=repo_data.get('forks_count', 0),
                tamanho_kb=repo_data.get('size', 0),
                atualizado_em=repo_data.get('updated_at', ''),
                topicos=repo_data.get('topics', []),
                privado=repo_data.get('private', False)
            )
        except Exception as e:
            logger.warning(f"Erro ao processar reposit√≥rio: {e}")
            return None

# =============================================================================
# SISTEMA DE TOOLS PARA AN√ÅLISE DE REPOSIT√ìRIO
# =============================================================================

class RepositoryAnalysisTools:
    """Tools especializadas para an√°lise de reposit√≥rio"""
    
    def __init__(self, repo_path: Union[str, Path]):
        self.repo_path = Path(repo_path)
        self.file_cache = {}
        self.analysis_cache = {}
        logger.info(f"Inicializando tools de an√°lise para: {self.repo_path}")
    
    def get_file_structure(self) -> Dict[str, Any]:
        """Analisa estrutura de arquivos do reposit√≥rio"""
        try:
            structure = {
                "total_files": 0,
                "code_files": 0,
                "languages": {},
                "directories": [],
                "important_files": [],
                "config_files": []
            }
            
            code_extensions = {
                '.py': 'Python', '.js': 'JavaScript', '.ts': 'TypeScript',
                '.java': 'Java', '.cpp': 'C++', '.c': 'C', '.go': 'Go',
                '.rs': 'Rust', '.php': 'PHP', '.rb': 'Ruby', '.swift': 'Swift'
            }
            
            for root, dirs, files in os.walk(self.repo_path):
                # Filtrar diret√≥rios irrelevantes
                dirs[:] = [d for d in dirs if not d.startswith('.') 
                          and d not in ['node_modules', '__pycache__', 'target', 'build', 'dist']]
                
                # Adicionar diret√≥rios importantes
                for dir_name in dirs:
                    if dir_name in ['src', 'lib', 'app', 'components', 'services', 'models']:
                        structure["directories"].append(str(Path(root) / dir_name))
                
                for file in files:
                    if file.startswith('.'):
                        continue
                    
                    structure["total_files"] += 1
                    file_path = Path(root) / file
                    ext = file_path.suffix.lower()
                    
                    # Arquivos de c√≥digo
                    if ext in code_extensions:
                        structure["code_files"] += 1
                        lang = code_extensions[ext]
                        structure["languages"][lang] = structure["languages"].get(lang, 0) + 1
                    
                    # Arquivos importantes
                    if (file.lower() in ['readme.md', 'package.json', 'requirements.txt', 'dockerfile'] or
                        'main' in file.lower() or 'index' in file.lower() or 'app' in file.lower()):
                        structure["important_files"].append(str(file_path.relative_to(self.repo_path)))
                    
                    # Arquivos de configura√ß√£o
                    if ext in ['.json', '.yml', '.yaml', '.toml', '.ini', '.cfg']:
                        structure["config_files"].append(str(file_path.relative_to(self.repo_path)))
            
            return structure
            
        except Exception as e:
            logger.error(f"Erro na an√°lise de estrutura: {e}")
            return {"error": str(e)}
    
    def analyze_code_files(self, max_files: int = 50) -> List[FileAnalysis]:
        """Analisa arquivos de c√≥digo em detalhes"""
        try:
            analyses = []
            
            # Padr√µes de arquivos importantes (expandido)
            important_patterns = [
                'main.py', 'app.py', 'index.js', 'server.py', 'api.py',
                'models.py', 'views.py', 'controllers.py', 'routes.py',
                'utils.py', 'helpers.js', 'config.py', 'settings.py',
                'service.py', 'handler.py', 'manager.py', 'client.py',
                'database.py', 'db.py', 'auth.py', 'middleware.py',
                'component.js', 'module.py', 'processor.py', 'worker.py',
                'scheduler.py', 'task.py', 'job.py', 'queue.py'
            ]
            
            for root, dirs, files in os.walk(self.repo_path):
                dirs[:] = [d for d in dirs if not d.startswith('.')]
                
                for file in files:
                    if len(analyses) >= max_files:
                        break
                    
                    file_path = Path(root) / file
                    
                    # Priorizar arquivos importantes
                    is_important = any(pattern in file.lower() for pattern in important_patterns)
                    is_code = file_path.suffix.lower() in ['.py', '.js', '.ts', '.java', '.go', '.rs']
                    
                    if not (is_important or is_code):
                        continue
                    
                    try:
                        if file_path.stat().st_size > 500 * 1024:  # Skip files > 500KB
                            continue
                        
                        content = file_path.read_text(encoding='utf-8', errors='ignore')
                        language = self._get_language(file_path.suffix.lower())
                        
                        analysis = self._analyze_file_content(file_path, content, language)
                        analyses.append(analysis)
                        
                    except Exception as e:
                        logger.warning(f"Erro ao analisar {file}: {e}")
                        continue
                
                if len(analyses) >= max_files:
                    break
            
            logger.info(f"Analisados {len(analyses)} arquivos de c√≥digo")
            return analyses
            
        except Exception as e:
            logger.error(f"Erro na an√°lise de arquivos: {e}")
            return []
    
    def _analyze_file_content(self, file_path: Path, content: str, language: str) -> FileAnalysis:
        """Analisa conte√∫do de um arquivo"""
        try:
            lines = [line for line in content.split('\n') if line.strip()]
            
            # Extrair fun√ß√µes, classes e imports
            functions = self._extract_functions(content, language)
            classes = self._extract_classes(content, language)
            imports = self._extract_imports(content, language)
            
            # Determinar prop√≥sito
            purpose = self._determine_file_purpose(file_path, content, language)
            
            # Gerar resumo
            summary = self._generate_file_summary(file_path, content, functions, classes)
            
            # Calcular complexidade
            complexity = self._calculate_complexity(content, functions, classes)
            
            return FileAnalysis(
                name=file_path.name,
                path=str(file_path.relative_to(self.repo_path)),
                language=language,
                size=len(content.encode('utf-8')),
                lines=len(lines),
                functions=functions[:10],
                classes=classes[:10],
                imports=imports[:15],
                purpose=purpose,
                summary=summary,
                complexity=complexity
            )
            
        except Exception as e:
            logger.warning(f"Erro ao analisar arquivo {file_path}: {e}")
            return FileAnalysis(
                name=file_path.name,
                path=str(file_path),
                language=language,
                size=0,
                lines=0,
                functions=[],
                classes=[],
                imports=[],
                purpose="Arquivo de c√≥digo",
                summary=f"Arquivo {language}",
                complexity="Baixa"
            )
    
    def _get_language(self, ext: str) -> str:
        """Identifica linguagem pela extens√£o"""
        language_map = {
            '.py': 'Python', '.js': 'JavaScript', '.ts': 'TypeScript',
            '.java': 'Java', '.cpp': 'C++', '.c': 'C', '.go': 'Go',
            '.rs': 'Rust', '.php': 'PHP', '.rb': 'Ruby', '.swift': 'Swift',
            '.html': 'HTML', '.css': 'CSS', '.sql': 'SQL', '.sh': 'Shell'
        }
        return language_map.get(ext, 'Unknown')
    
    def _extract_functions(self, content: str, language: str) -> List[str]:
        """Extrai fun√ß√µes do c√≥digo com mais detalhes"""
        functions = []
        try:
            if language == 'Python':
                # Capturar fun√ß√µes normais e async
                pattern = r'(?:async\s+)?def\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\('
                # Tamb√©m capturar m√©todos de classe
                class_method_pattern = r'^\s+(?:async\s+)?def\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\('
                
                matches = re.findall(pattern, content, re.MULTILINE)
                class_matches = re.findall(class_method_pattern, content, re.MULTILINE)
                functions.extend(matches)
                functions.extend([f"method_{m}" for m in class_matches])
                
            elif language in ['JavaScript', 'TypeScript']:
                # Fun√ß√µes normais, arrow functions, m√©todos
                patterns = [
                    r'function\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\(',
                    r'const\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*=\s*\(',
                    r'([a-zA-Z_][a-zA-Z0-9_]*)\s*:\s*function\s*\(',
                    r'([a-zA-Z_][a-zA-Z0-9_]*)\s*\([^)]*\)\s*=>'
                ]
                for pattern in patterns:
                    matches = re.findall(pattern, content, re.MULTILINE)
                    functions.extend(matches)
                    
            elif language == 'Java':
                pattern = r'(?:public|private|protected)?\s*(?:static)?\s*\w+\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\('
                matches = re.findall(pattern, content, re.MULTILINE)
                functions.extend(matches)
            else:
                return []
            
            functions = list(set(functions)) if functions else []
        except Exception:
            pass
        
        return functions[:20]  # Limitar a 20 fun√ß√µes mais importantes
    
    def _extract_classes(self, content: str, language: str) -> List[str]:
        """Extrai classes do c√≥digo"""
        classes = []
        try:
            if language in ['Python', 'Java', 'JavaScript', 'TypeScript']:
                pattern = r'class\s+([a-zA-Z_][a-zA-Z0-9_]*)'
                matches = re.findall(pattern, content, re.MULTILINE)
                classes = list(set(matches)) if matches else []
        except Exception:
            pass
        
        return classes
    
    def _extract_imports(self, content: str, language: str) -> List[str]:
        """Extrai imports do c√≥digo"""
        imports = []
        try:
            if language == 'Python':
                pattern = r'(?:from\s+[\w.]+\s+)?import\s+([\w\s,.*]+)'
            elif language in ['JavaScript', 'TypeScript']:
                pattern = r'import\s+.*?from\s+[\'"]([^\'"]+)[\'"]'
            elif language == 'Java':
                pattern = r'import\s+([\w.]+)'
            else:
                return []
            
            matches = re.findall(pattern, content, re.MULTILINE)
            for match in matches:
                if isinstance(match, str):
                    import_name = match.strip().split(',')[0].strip()
                    if import_name and import_name not in imports:
                        imports.append(import_name)
        except Exception:
            pass
        
        return imports
    
    def _determine_file_purpose(self, file_path: Path, content: str, language: str) -> str:
        """Determina o prop√≥sito do arquivo"""
        filename = file_path.name.lower()
        
        if 'test' in filename:
            return "Arquivo de testes"
        elif filename in ['main.py', 'app.py', 'index.js']:
            return "Ponto de entrada da aplica√ß√£o"
        elif filename in ['config.py', 'settings.py']:
            return "Arquivo de configura√ß√£o"
        elif 'api' in filename or 'controller' in filename:
            return "Controlador de API"
        elif 'model' in filename:
            return "Modelo de dados"
        elif 'view' in filename or 'component' in filename:
            return "Componente de interface"
        elif filename.endswith('.md'):
            return "Documenta√ß√£o"
        else:
            return f"Arquivo {language} do projeto"
    
    def _generate_file_summary(self, file_path: Path, content: str, functions: List[str], classes: List[str]) -> str:
        """Gera resumo do arquivo"""
        lines_count = len([l for l in content.split('\n') if l.strip()])
        summary_parts = [f"Arquivo com {lines_count} linhas"]
        
        if classes:
            summary_parts.append(f"{len(classes)} classe(s)")
        if functions:
            summary_parts.append(f"{len(functions)} fun√ß√£o(√µes)")
        
        return ", ".join(summary_parts)
    
    def _calculate_complexity(self, content: str, functions: List[str], classes: List[str]) -> str:
        """Calcula complexidade do arquivo"""
        lines = len([l for l in content.split('\n') if l.strip()])
        complexity_score = 0
        
        if lines > 200:
            complexity_score += 2
        elif lines > 50:
            complexity_score += 1
        
        complexity_score += len(functions) + len(classes)
        
        control_structures = len(re.findall(r'\b(if|for|while|try|catch)\b', content))
        if control_structures > 20:
            complexity_score += 2
        elif control_structures > 10:
            complexity_score += 1
        
        if complexity_score >= 5:
            return "Alta"
        elif complexity_score >= 3:
            return "M√©dia"
        else:
            return "Baixa"

# =============================================================================
# TOOLS LANGGRAPH PARA AN√ÅLISE
# =============================================================================

@tool
def analyze_repository_structure(repo_path: str) -> str:
    """Analisa a estrutura completa do reposit√≥rio"""
    try:
        tools = RepositoryAnalysisTools(repo_path)
        structure = tools.get_file_structure()
        
        if "error" in structure:
            return f"Erro na an√°lise: {structure['error']}"
        
        result = f"""## üìÅ Estrutura do Reposit√≥rio

### üìä Estat√≠sticas Gerais:
- **Total de arquivos:** {structure['total_files']:,}
- **Arquivos de c√≥digo:** {structure['code_files']:,}
- **Linguagens detectadas:** {len(structure['languages'])}

### üíª Distribui√ß√£o por Linguagem:
"""
        for lang, count in sorted(structure['languages'].items(), key=lambda x: x[1], reverse=True):
            percentage = (count / structure['code_files']) * 100 if structure['code_files'] > 0 else 0
            result += f"- **{lang}:** {count} arquivos ({percentage:.1f}%)\n"
        
        result += "\n### üìÅ Diret√≥rios Importantes:\n"
        for directory in structure['directories'][:10]:
            result += f"- {directory}\n"
        
        result += "\n### üéØ Arquivos Importantes:\n"
        for file in structure['important_files'][:15]:
            result += f"- {file}\n"
        
        return result
        
    except Exception as e:
        return f"Erro na an√°lise de estrutura: {str(e)}"

@tool
def analyze_code_files(repo_path: str, max_files: int = 20) -> str:
    """Analisa arquivos de c√≥digo em detalhes"""
    try:
        tools = RepositoryAnalysisTools(repo_path)
        analyses = tools.analyze_code_files(max_files)
        
        if not analyses:
            return "Nenhum arquivo de c√≥digo encontrado para an√°lise"
        
        result = f"## üî¨ An√°lise Detalhada de Arquivos ({len(analyses)} arquivos)\n\n"
        
        for i, analysis in enumerate(analyses[:15], 1):
            result += f"### {i}. {analysis.name} ({analysis.language})\n"
            result += f"**Localiza√ß√£o:** `{analysis.path}`\n"
            result += f"**Tamanho:** {analysis.size:,} bytes | **Linhas:** {analysis.lines:,} | **Complexidade:** {analysis.complexity}\n"
            result += f"**Prop√≥sito:** {analysis.purpose}\n"
            result += f"**Resumo:** {analysis.summary}\n"
            
            if analysis.functions:
                result += f"**Fun√ß√µes:** {', '.join(analysis.functions[:5])}"
                if len(analysis.functions) > 5:
                    result += f" e mais {len(analysis.functions) - 5}"
                result += "\n"
            
            if analysis.classes:
                result += f"**Classes:** {', '.join(analysis.classes[:3])}"
                if len(analysis.classes) > 3:
                    result += f" e mais {len(analysis.classes) - 3}"
                result += "\n"
            
            if analysis.imports:
                result += f"**Principais imports:** {', '.join(analysis.imports[:5])}\n"
            
            result += "\n---\n\n"
        
        return result
        
    except Exception as e:
        return f"Erro na an√°lise de arquivos: {str(e)}"

@tool
def read_file_content(repo_path: str, file_path: str) -> str:
    """L√™ conte√∫do de um arquivo espec√≠fico"""
    try:
        full_path = Path(repo_path) / file_path
        
        if not full_path.exists():
            return f"Arquivo n√£o encontrado: {file_path}"
        
        if full_path.stat().st_size > 100 * 1024:  # 100KB limit
            return f"Arquivo muito grande: {file_path}"
        
        content = full_path.read_text(encoding='utf-8', errors='ignore')
        
        return f"""## üìÑ Arquivo: {file_path}

**Tamanho:** {full_path.stat().st_size:,} bytes
**Linhas:** {len(content.split(chr(10)))}

### Conte√∫do:
```{full_path.suffix[1:] if full_path.suffix else 'text'}
{content[:2000]}{'...' if len(content) > 2000 else ''}
```
"""
        
    except Exception as e:
        return f"Erro ao ler arquivo {file_path}: {str(e)}"

@tool
def find_dependencies(repo_path: str) -> str:
    """Encontra e analisa arquivos de depend√™ncias"""
    try:
        dependency_files = {
            'package.json': 'Node.js',
            'requirements.txt': 'Python',
            'Pipfile': 'Python (Pipenv)',
            'pyproject.toml': 'Python (Poetry)',
            'pom.xml': 'Java (Maven)',
            'build.gradle': 'Java (Gradle)',
            'Cargo.toml': 'Rust',
            'go.mod': 'Go',
            'composer.json': 'PHP'
        }
        
        found_deps = []
        repo_path = Path(repo_path)
        
        for dep_file, tech in dependency_files.items():
            file_path = repo_path / dep_file
            if file_path.exists():
                try:
                    content = file_path.read_text(encoding='utf-8', errors='ignore')
                    size = file_path.stat().st_size
                    
                    found_deps.append({
                        'file': dep_file,
                        'technology': tech,
                        'size': size,
                        'content_preview': content[:500]
                    })
                except Exception as e:
                    logger.warning(f"Erro ao ler {dep_file}: {e}")
        
        if not found_deps:
            return "Nenhum arquivo de depend√™ncias encontrado"
        
        result = "## üì¶ Arquivos de Depend√™ncias Encontrados\n\n"
        
        for dep in found_deps:
            result += f"### {dep['file']} ({dep['technology']})\n"
            result += f"**Tamanho:** {dep['size']:,} bytes\n\n"
            
            if dep['file'] == 'package.json':
                try:
                    pkg_data = json.loads(dep['content_preview'])
                    if 'dependencies' in pkg_data:
                        result += "**Depend√™ncias principais:**\n"
                        for pkg, version in list(pkg_data['dependencies'].items())[:10]:
                            result += f"- {pkg}: {version}\n"
                except:
                    pass
            elif dep['file'] == 'requirements.txt':
                lines = dep['content_preview'].split('\n')[:15]
                result += "**Depend√™ncias:**\n"
                for line in lines:
                    if line.strip() and not line.startswith('#'):
                        result += f"- {line.strip()}\n"
            
            result += "\n---\n\n"
        
        return result
        
    except Exception as e:
        return f"Erro na an√°lise de depend√™ncias: {str(e)}"

# =============================================================================
# SISTEMA DE MODELOS LLM
# =============================================================================

class LLMManager:
    """Gerenciador de modelos LLM (OpenAI e Ollama)"""
    
    def __init__(self):
        self.current_config = None
        self.available_models = {
            "openai": ["gpt-4o", "gpt-4o-mini", "gpt-3.5-turbo"],
            "ollama": []
        }
        self._check_ollama_models()
        logger.info("LLM Manager inicializado")
    
    def _check_ollama_models(self):
        """Verifica modelos Ollama dispon√≠veis"""
        try:
            result = subprocess.run(["ollama", "list"], capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                models = []
                for line in result.stdout.strip().split('\n')[1:]:
                    if line.strip():
                        parts = line.split()
                        if parts:
                            model_name = parts[0]
                            # Adicionar informa√ß√µes extras se dispon√≠veis
                            size_info = parts[1] if len(parts) > 1 else ""
                            models.append({
                                "name": model_name,
                                "size": size_info,
                                "display_name": f"{model_name} ({size_info})" if size_info else model_name
                            })
                self.available_models["ollama"] = models
                logger.info(f"Modelos Ollama encontrados: {[m['name'] for m in models]}")
            else:
                logger.warning("Ollama n√£o est√° rodando")
                self.available_models["ollama"] = []
        except Exception as e:
            logger.warning(f"Erro ao verificar Ollama: {e}")
            self.available_models["ollama"] = []
    
    def get_ollama_models_detailed(self):
        """Retorna modelos Ollama com detalhes"""
        self._check_ollama_models()
        return self.available_models["ollama"]
    
    def configure_model(self, config: ModelConfig):
        """Configura modelo LLM"""
        try:
            self.current_config = config
            
            if config.provider == "openai":
                if not config.api_key:
                    config.api_key = os.environ.get("OPENAI_API_KEY")
                
                if not config.api_key:
                    raise ValueError("OPENAI_API_KEY n√£o configurada")
                
                self.llm = ChatOpenAI(
                    model=config.model_name,
                    temperature=config.temperature,
                    max_tokens=config.max_tokens,
                    api_key=config.api_key
                )
                
            elif config.provider == "ollama":
                self.llm = Ollama(
                    model=config.model_name,
                    temperature=config.temperature,
                    base_url=config.base_url or "http://localhost:11434"
                )
            
            else:
                raise ValueError(f"Provider n√£o suportado: {config.provider}")
            
            logger.info(f"Modelo configurado: {config.provider}/{config.model_name}")
            return True
            
        except Exception as e:
            logger.error(f"Erro ao configurar modelo: {e}")
            return False
    
    def get_llm(self):
        """Retorna inst√¢ncia do LLM configurado"""
        if not hasattr(self, 'llm'):
            # Configura√ß√£o padr√£o
            default_config = ModelConfig(
                provider="ollama",
                model_name="qwen2.5:7b"
            )
            self.configure_model(default_config)
        
        return self.llm
    
    def list_available_models(self) -> Dict[str, List[str]]:
        """Lista modelos dispon√≠veis"""
        self._check_ollama_models()  # Atualizar lista Ollama
        return self.available_models.copy()

# =============================================================================
# N√ìS DO LANGGRAPH - AGENTES ESPECIALIZADOS
# =============================================================================

class DocumentationAgents:
    """Agentes especializados para documenta√ß√£o usando LangGraph"""
    
    def __init__(self, llm_manager: LLMManager):
        self.llm_manager = llm_manager
        self.anonymizer = AnonymizationSystem()
        logger.info("Agentes de documenta√ß√£o inicializados")
    
    async def clone_repository_node(self, state: DocumentationState) -> DocumentationState:
        """N√≥ para clonar reposit√≥rio ou usar diret√≥rio local"""
        try:
            repo_url = state["repo_url"]
            logger.info(f"Processando: {repo_url}")
            
            # Verificar se √© um diret√≥rio local
            if repo_url.startswith("file://"):
                local_path = repo_url.replace("file://", "")
                logger.info(f"Usando diret√≥rio local: {local_path}")
                
                if not Path(local_path).exists():
                    state["logs"].append(f"‚ùå Diret√≥rio n√£o encontrado: {local_path}")
                    state["error_count"] += 1
                    return state
                
                if not Path(local_path).is_dir():
                    state["logs"].append(f"‚ùå Caminho n√£o √© um diret√≥rio: {local_path}")
                    state["error_count"] += 1
                    return state
                
                state["repo_path"] = local_path
                state["current_phase"] = "local_ready"
                state["progress"] = 20
                state["logs"].append("‚úÖ Diret√≥rio local configurado")
                logger.info(f"Diret√≥rio local pronto: {local_path}")
                return state
            
            # Validar URL GitHub
            if not self._validate_github_url(repo_url):
                state["logs"].append("‚ùå URL inv√°lida")
                state["error_count"] += 1
                return state
            
            # Preparar diret√≥rio para clone
            repo_name = repo_url.split("/")[-1].replace(".git", "")
            workdir = Path("workdir").resolve()
            workdir.mkdir(exist_ok=True)
            repo_path = workdir / repo_name
            
            # Remover se existir
            if repo_path.exists():
                shutil.rmtree(repo_path, ignore_errors=True)
            
            # Clone
            cmd = ["git", "clone", "--depth", "1", repo_url, str(repo_path)]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0 and repo_path.exists():
                state["repo_path"] = str(repo_path)
                state["current_phase"] = "cloned"
                state["progress"] = 20
                state["logs"].append("‚úÖ Reposit√≥rio clonado com sucesso")
                logger.info(f"Clone conclu√≠do: {repo_path}")
            else:
                state["logs"].append(f"‚ùå Falha no clone: {result.stderr}")
                state["error_count"] += 1
            
            return state
            
        except Exception as e:
            logger.error(f"Erro no processamento: {e}")
            state["logs"].append(f"‚ùå Erro no processamento: {str(e)}")
            state["error_count"] += 1
            return state
    
    async def analyze_structure_node(self, state: DocumentationState) -> DocumentationState:
        """N√≥ para an√°lise de estrutura"""
        try:
            repo_path = state.get("repo_path")
            if not repo_path:
                state["logs"].append("‚ùå Caminho do reposit√≥rio n√£o encontrado")
                state["error_count"] += 1
                return state
            
            logger.info("Analisando estrutura do reposit√≥rio")
            
            # Usar tool de an√°lise
            structure_result = analyze_repository_structure.invoke({"repo_path": repo_path})
            
            # Analisar arquivos de c√≥digo
            code_result = analyze_code_files.invoke({
                "repo_path": repo_path, 
                "max_files": state.get("max_files", 20)
            })
            
            # Encontrar depend√™ncias
            deps_result = find_dependencies.invoke({"repo_path": repo_path})
            
            state["file_structure"] = {
                "structure_analysis": structure_result,
                "code_analysis": code_result,
                "dependencies": deps_result
            }
            
            state["current_phase"] = "analyzed"
            state["progress"] = 40
            state["logs"].append("‚úÖ Estrutura analisada")
            
            return state
            
        except Exception as e:
            logger.error(f"Erro na an√°lise de estrutura: {e}")
            state["logs"].append(f"‚ùå Erro na an√°lise: {str(e)}")
            state["error_count"] += 1
            return state
    
    async def generate_documentation_plan_node(self, state: DocumentationState) -> DocumentationState:
        """N√≥ para gerar plano de documenta√ß√£o"""
        try:
            logger.info("Gerando plano de documenta√ß√£o")
            
            llm = self.llm_manager.get_llm()
            
            # Preparar contexto da an√°lise
            structure_info = state.get("file_structure", {})
            
            # Prompt para planejamento com C4
            planning_prompt = ChatPromptTemplate.from_template("""
Voc√™ √© um especialista em documenta√ß√£o t√©cnica e arquitetura C4. Baseado na an√°lise do reposit√≥rio abaixo, 
crie um plano detalhado para documenta√ß√£o completa com arquitetura C4 em formato JSON.

AN√ÅLISE DO REPOSIT√ìRIO:
{structure_analysis}

{code_analysis}

{dependencies}

Crie um plano JSON com exatamente 4 se√ß√µes seguindo o modelo C4:
1. "C4 Context Diagram" - vis√£o geral do sistema e intera√ß√µes externas
2. "C4 Container Diagram" - cont√™ineres e tecnologias principais
3. "C4 Component Diagram" - componentes internos e suas responsabilidades
4. "C4 Code Analysis" - an√°lise detalhada do c√≥digo e estrutura

Formato JSON obrigat√≥rio:
{{
  "overview": "Documenta√ß√£o arquitetural C4 do projeto Skyone",
  "sections": [
    {{
      "title": "C4 Context Diagram",
      "description": "Vis√£o contextual do sistema e suas intera√ß√µes externas",
      "content_type": "c4_context"
    }},
    {{
      "title": "C4 Container Diagram", 
      "description": "Cont√™ineres, tecnologias e comunica√ß√£o entre componentes",
      "content_type": "c4_container"
    }},
    {{
      "title": "C4 Component Diagram",
      "description": "Componentes internos, interfaces e responsabilidades",
      "content_type": "c4_component"
    }},
    {{
      "title": "C4 Code Analysis",
      "description": "An√°lise detalhada do c√≥digo, classes e implementa√ß√£o",
      "content_type": "c4_code"
    }}
  ]
}}

Responda APENAS com o JSON v√°lido.
""")
            
            # Executar planejamento
            chain = planning_prompt | llm
            
            planning_result = await chain.ainvoke({
                "structure_analysis": structure_info.get("structure_analysis", ""),
                "code_analysis": structure_info.get("code_analysis", ""),
                "dependencies": structure_info.get("dependencies", "")
            })
            
            # Extrair JSON do resultado
            try:
                if hasattr(planning_result, 'content'):
                    plan_text = planning_result.content
                else:
                    plan_text = str(planning_result)
                
                # Extrair JSON
                json_match = re.search(r'\{.*\}', plan_text, re.DOTALL)
                if json_match:
                    plan_data = json.loads(json_match.group())
                    state["documentation_plan"] = plan_data
                    state["logs"].append("‚úÖ Plano de documenta√ß√£o criado")
                else:
                    raise ValueError("JSON n√£o encontrado na resposta")
                    
            except Exception as e:
                logger.warning(f"Erro ao extrair plano JSON: {e}")
                # Plano padr√£o C4 com fluxogramas
                state["documentation_plan"] = {
                    "overview": "Documenta√ß√£o arquitetural C4 do projeto Skyone",
                    "sections": [
                        {"title": "C4 Context Diagram", "description": "Vis√£o contextual do sistema", "content_type": "c4_context"},
                        {"title": "C4 Container Diagram", "description": "Cont√™ineres e tecnologias", "content_type": "c4_container"},
                        {"title": "C4 Component Diagram", "description": "Componentes internos", "content_type": "c4_component"},
                        {"title": "C4 Code Analysis", "description": "An√°lise detalhada do c√≥digo", "content_type": "c4_code"},
                        {"title": "Mermaid Flowcharts", "description": "Fluxogramas detalhados dos componentes", "content_type": "mermaid_flowcharts"}
                    ]
                }
                state["logs"].append("‚ö†Ô∏è Usando plano padr√£o")
            
            state["current_phase"] = "planned"
            state["progress"] = 60
            
            return state
            
        except Exception as e:
            logger.error(f"Erro no planejamento: {e}")
            state["logs"].append(f"‚ùå Erro no planejamento: {str(e)}")
            state["error_count"] += 1
            return state
    
    async def generate_documentation_node(self, state: DocumentationState) -> DocumentationState:
        """N√≥ para gerar documenta√ß√£o"""
        try:
            logger.info("Gerando documenta√ß√£o")
            
            plan = state.get("documentation_plan", {})
            sections = plan.get("sections", [])
            
            if not sections:
                state["logs"].append("‚ùå Plano de documenta√ß√£o n√£o encontrado")
                state["error_count"] += 1
                return state
            
            llm = self.llm_manager.get_llm()
            docs_dir = Path("docs")
            docs_dir.mkdir(exist_ok=True)
            
            generated_files = []
            
            for i, section in enumerate(sections):
                try:
                    logger.info(f"Gerando se√ß√£o: {section['title']}")
                    
                    # Prompt espec√≠fico por tipo de se√ß√£o
                    doc_content = await self._generate_section_content(
                        llm, section, state, i + 1
                    )
                    
                    # Salvar arquivo
                    filename = self._get_section_filename(section['title'], i, state.get("anonymous", True))
                    file_path = docs_dir / filename
                    
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(doc_content)
                    
                    generated_files.append(filename)
                    state["logs"].append(f"‚úÖ Se√ß√£o criada: {section['title']}")
                    
                except Exception as e:
                    logger.error(f"Erro na se√ß√£o {section['title']}: {e}")
                    state["logs"].append(f"‚ùå Erro na se√ß√£o {section['title']}: {str(e)}")
            
            state["generated_docs"] = generated_files
            state["current_phase"] = "completed"
            state["progress"] = 100
            state["logs"].append(f"üéâ Documenta√ß√£o completa: {len(generated_files)} arquivos")
            
            return state
            
        except Exception as e:
            logger.error(f"Erro na gera√ß√£o de documenta√ß√£o: {e}")
            state["logs"].append(f"‚ùå Erro na documenta√ß√£o: {str(e)}")
            state["error_count"] += 1
            return state
    
    def _validate_github_url(self, url: str) -> bool:
        """Valida URL do GitHub"""
        pattern = r"^https://github\.com/[\w\-\.]+/[\w\-\.]+/?$"
        return bool(re.match(pattern, url.strip()))
    
    async def _generate_section_content(self, llm, section: Dict, state: DocumentationState, section_num: int) -> str:
        """Gera conte√∫do de uma se√ß√£o espec√≠fica"""
        try:
            content_type = section.get("content_type", "general")
            repo_url = state["repo_url"]
            anonymous = state.get("anonymous", True)
            
            # Anonimizar URL se necess√°rio
            final_url = self.anonymizer.anonymize_repo_url(repo_url) if anonymous else repo_url
            
            if content_type == "c4_context":
                prompt = self._create_c4_context_prompt(section, state, final_url)
            elif content_type == "c4_container":
                prompt = self._create_c4_container_prompt(section, state, final_url)
            elif content_type == "c4_component":
                prompt = self._create_c4_component_prompt(section, state, final_url)
            elif content_type == "c4_code":
                prompt = self._create_c4_code_prompt(section, state, final_url)
            elif content_type == "mermaid_flowcharts":
                prompt = self._create_mermaid_flowcharts_prompt(section, state, final_url)
            elif content_type == "overview":
                prompt = self._create_overview_prompt(section, state, final_url)
            elif content_type == "installation":
                prompt = self._create_installation_prompt(section, state, final_url)
            elif content_type == "technical":
                prompt = self._create_technical_prompt(section, state, final_url)
            else:
                prompt = self._create_general_prompt(section, state, final_url)
            
            # Gerar conte√∫do
            result = await llm.ainvoke([HumanMessage(content=prompt)])
            
            if hasattr(result, 'content'):
                return result.content
            else:
                return str(result)
                
        except Exception as e:
            logger.error(f"Erro ao gerar se√ß√£o {section.get('title', 'unknown')}: {e}")
            return self._create_fallback_content(section, state)
    
    def _create_overview_prompt(self, section: Dict, state: DocumentationState, final_url: str) -> str:
        """Cria prompt para vis√£o geral"""
        structure_info = state.get("file_structure", {})
        
        return f"""
Crie uma documenta√ß√£o completa de VIS√ÉO GERAL DO PROJETO baseada na an√°lise real:

T√çTULO: {section['title']}
REPOSIT√ìRIO: {final_url}

AN√ÅLISE ESTRUTURAL:
{structure_info.get('structure_analysis', 'An√°lise n√£o dispon√≠vel')}

AN√ÅLISE DE C√ìDIGO:
{structure_info.get('code_analysis', 'An√°lise de c√≥digo n√£o dispon√≠vel')}

DEPEND√äNCIAS:
{structure_info.get('dependencies', 'Depend√™ncias n√£o identificadas')}

Crie documenta√ß√£o em Markdown com:
# {section['title']}

## üéØ Prop√≥sito do Projeto
[Baseado na an√°lise real dos arquivos]

## üõ†Ô∏è Stack Tecnol√≥gico
[Tecnologias identificadas na an√°lise]

## üèóÔ∏è Arquitetura
[Estrutura e padr√µes identificados]

## üìä Estat√≠sticas
[Dados quantitativos da an√°lise]

Use APENAS informa√ß√µes da an√°lise real fornecida.
"""
    
    def _create_installation_prompt(self, section: Dict, state: DocumentationState, final_url: str) -> str:
        """Cria prompt para instala√ß√£o"""
        structure_info = state.get("file_structure", {})
        
        return f"""
Crie um GUIA DE INSTALA√á√ÉO baseado na an√°lise das depend√™ncias:

T√çTULO: {section['title']}

DEPEND√äNCIAS ENCONTRADAS:
{structure_info.get('dependencies', 'Nenhuma depend√™ncia identificada')}

ESTRUTURA DO PROJETO:
{structure_info.get('structure_analysis', 'Estrutura n√£o analisada')}

Crie documenta√ß√£o em Markdown com:
# {section['title']}

## üìã Pr√©-requisitos
[Baseado nas tecnologias identificadas]

## üöÄ Instala√ß√£o
[Passos baseados nos arquivos de depend√™ncia encontrados]

## ‚öôÔ∏è Configura√ß√£o
[Configura√ß√µes necess√°rias]

## ‚ñ∂Ô∏è Execu√ß√£o
[Como executar o projeto]

Use APENAS informa√ß√µes das depend√™ncias e estrutura analisadas.
"""
    
    def _create_technical_prompt(self, section: Dict, state: DocumentationState, final_url: str) -> str:
        """Cria prompt para relat√≥rio t√©cnico"""
        structure_info = state.get("file_structure", {})
        
        return f"""
Crie um RELAT√ìRIO T√âCNICO DETALHADO baseado na an√°lise de c√≥digo:

T√çTULO: {section['title']}

AN√ÅLISE DE ARQUIVOS:
{structure_info.get('code_analysis', 'An√°lise de c√≥digo n√£o dispon√≠vel')}

ESTRUTURA:
{structure_info.get('structure_analysis', 'Estrutura n√£o analisada')}

Crie documenta√ß√£o t√©cnica em Markdown com:
# {section['title']}

## üìÅ Estrutura do Projeto
[Organiza√ß√£o identificada]

## üîß Arquivos Principais
[Para cada arquivo analisado:]
### [Nome do Arquivo]
- **Prop√≥sito:** [identificado na an√°lise]
- **Linguagem:** [detectada]
- **Fun√ß√µes:** [listadas na an√°lise]
- **Classes:** [encontradas]
- **Complexidade:** [calculada]

## üèóÔ∏è Arquitetura
[Padr√µes identificados]

Use APENAS dados da an√°lise real dos arquivos.
"""
    
    def _create_c4_context_prompt(self, section: Dict, state: DocumentationState, final_url: str) -> str:
        """Cria prompt para C4 Context Diagram"""
        structure_info = state.get("file_structure", {})
        
        return f"""
Crie uma documenta√ß√£o C4 CONTEXT DIAGRAM baseada na an√°lise real:

T√çTULO: {section['title']}
PROJETO: {final_url}

AN√ÅLISE ESTRUTURAL:
{structure_info.get('structure_analysis', 'An√°lise n√£o dispon√≠vel')}

DEPEND√äNCIAS:
{structure_info.get('dependencies', 'Depend√™ncias n√£o identificadas')}

Crie documenta√ß√£o em Markdown seguindo o modelo C4 Context:

# {section['title']}

## üéØ Vis√£o Contextual do Sistema

### Sistema Principal
[Nome e prop√≥sito do sistema baseado na an√°lise]

### Usu√°rios e Atores
[Identifique os tipos de usu√°rios que interagem com o sistema]

### Sistemas Externos
[Sistemas, APIs e servi√ßos externos identificados nas depend√™ncias]

### Intera√ß√µes Principais
[Como o sistema se comunica com o mundo externo]

## üìä Diagrama de Contexto C4

```mermaid
C4Context
    title Diagrama de Contexto - [Nome do Sistema]
    
    Person(user, "Usu√°rio", "Descri√ß√£o do usu√°rio principal")
    System(system, "[Nome do Sistema]", "Descri√ß√£o do sistema")
    System_Ext(external, "Sistema Externo", "Descri√ß√£o")
    
    Rel(user, system, "Usa")
    Rel(system, external, "Consome API")
```

## üîó Integra√ß√µes Identificadas
[Liste as integra√ß√µes encontradas na an√°lise]

Use APENAS informa√ß√µes da an√°lise real fornecida.
"""

    def _create_c4_container_prompt(self, section: Dict, state: DocumentationState, final_url: str) -> str:
        """Cria prompt para C4 Container Diagram"""
        structure_info = state.get("file_structure", {})
        
        return f"""
Voc√™ √© um especialista em arquitetura C4. Crie uma documenta√ß√£o C4 CONTAINER DIAGRAM baseada EXCLUSIVAMENTE na an√°lise real:

T√çTULO: {section['title']}

AN√ÅLISE DE C√ìDIGO:
{structure_info.get('code_analysis', 'An√°lise de c√≥digo n√£o dispon√≠vel')}

DEPEND√äNCIAS E TECNOLOGIAS REAIS:
{structure_info.get('dependencies', 'Depend√™ncias n√£o identificadas')}

ESTRUTURA REAL:
{structure_info.get('structure_analysis', 'Estrutura n√£o analisada')}

INSTRU√á√ïES CR√çTICAS:
1. Identifique APENAS tecnologias REAIS encontradas nas depend√™ncias
2. Use APENAS linguagens de programa√ß√£o REAIS detectadas na an√°lise
3. Identifique cont√™ineres REAIS baseados na estrutura de diret√≥rios
4. N√ÉO invente bancos de dados ou APIs se n√£o foram identificados
5. Base-se APENAS nos arquivos e tecnologias encontrados

# {section['title']}

## üèóÔ∏è Arquitetura de Cont√™ineres Reais

### Cont√™ineres Identificados na An√°lise
[Baseado na estrutura de diret√≥rios REAL: frontend/, backend/, api/, etc.]

### Stack Tecnol√≥gico Real
[APENAS as tecnologias REAIS das depend√™ncias:]
- **Linguagens:** [Linguagens REAIS detectadas]
- **Frameworks:** [Frameworks REAIS dos arquivos de depend√™ncia]
- **Bibliotecas:** [Bibliotecas REAIS identificadas]

### Comunica√ß√£o e Protocolos
[Baseado nos imports e configura√ß√µes REAIS encontrados]

## üì¶ Diagrama de Cont√™ineres C4 (Dados Reais)

```mermaid
C4Container
    title Diagrama de Cont√™ineres - [Nome Real do Projeto]
    
    Person(user, "Usu√°rio", "Usu√°rio do sistema")
    
    Container_Boundary(system, "[Nome Real do Sistema]") {{
        [Para cada cont√™iner REAL identificado na estrutura:]
        [Exemplo: Container(app_real, "NomeAplicacaoReal", "TecnologiaReal", "Fun√ß√£o real")]
        [APENAS se houver banco de dados identificado: ContainerDb(db_real, "BancoDadosReal", "TipoReal", "Fun√ß√£o real")]
    }}
    
    [APENAS se houver APIs externas REAIS nas depend√™ncias:]
    [System_Ext(api_real, "NomeAPIReal", "Fun√ß√£o real")]
    
    [Relacionamentos REAIS baseados na an√°lise:]
    [Rel(user, app_real, "Interage", "ProtocoloReal")]
    [Rel(app_real, db_real, "Acessa", "ProtocoloReal") - APENAS se DB foi identificado]
```

## üîß Detalhes T√©cnicos dos Cont√™ineres Reais
[Para cada cont√™iner REAL identificado:]

### [Nome Real do Cont√™iner]
- **Tecnologia:** [Tecnologia REAL detectada]
- **Localiza√ß√£o:** [Diret√≥rio REAL na estrutura]
- **Responsabilidades:** [Baseadas nos arquivos REAIS encontrados]
- **Depend√™ncias:** [Depend√™ncias REAIS identificadas]
- **Configura√ß√£o:** [Arquivos de config REAIS encontrados]

## üåê Integra√ß√µes Externas Reais
[APENAS se identificadas nas depend√™ncias ou imports:]

IMPORTANTE: Use SOMENTE dados REAIS da an√°lise. N√ÉO invente cont√™ineres, bancos de dados ou APIs.
"""

    def _create_c4_component_prompt(self, section: Dict, state: DocumentationState, final_url: str) -> str:
        """Cria prompt para C4 Component Diagram"""
        structure_info = state.get("file_structure", {})
        
        return f"""
Voc√™ √© um especialista em arquitetura de software e documenta√ß√£o C4. Crie uma documenta√ß√£o C4 COMPONENT DIAGRAM baseada EXCLUSIVAMENTE na an√°lise detalhada real fornecida.

T√çTULO: {section['title']}

AN√ÅLISE DETALHADA DE ARQUIVOS:
{structure_info.get('code_analysis', 'An√°lise de c√≥digo n√£o dispon√≠vel')}

ESTRUTURA DO PROJETO:
{structure_info.get('structure_analysis', 'Estrutura n√£o analisada')}

DEPEND√äNCIAS IDENTIFICADAS:
{structure_info.get('dependencies', 'Depend√™ncias n√£o identificadas')}

INSTRU√á√ïES CR√çTICAS:
1. Use APENAS os arquivos, classes, fun√ß√µes e componentes REAIS identificados na an√°lise
2. N√ÉO invente ou use componentes gen√©ricos como "Controller", "Service", "Repository"
3. Use os NOMES REAIS dos arquivos e classes encontrados na an√°lise
4. Base as responsabilidades nas FUN√á√ïES REAIS identificadas
5. Use as TECNOLOGIAS REAIS encontradas nas depend√™ncias

Crie documenta√ß√£o em Markdown seguindo o modelo C4 Component:

# {section['title']}

## üß© Componentes Reais Identificados

### Arquivos e M√≥dulos Principais
[Liste APENAS os arquivos reais da an√°lise com suas fun√ß√µes espec√≠ficas]

### Classes e Interfaces Reais
[Liste APENAS as classes reais encontradas na an√°lise de c√≥digo]

### Fun√ß√µes e M√©todos Principais
[Liste APENAS as fun√ß√µes reais identificadas na an√°lise]

## üîó Diagrama de Componentes C4 (Baseado na An√°lise Real)

```mermaid
C4Component
    title Diagrama de Componentes - [Nome Real do Sistema]
    
    Container_Boundary(main_container, "[Nome Real da Aplica√ß√£o]") {{
        [Para cada arquivo/classe REAL da an√°lise, crie um Component com nome, tecnologia e prop√≥sito REAIS]
        [Exemplo: Component(arquivo_real, "NomeArquivoReal.py", "Python", "Fun√ß√£o real identificada")]
    }}
    
    [Adicione sistemas externos REAIS encontrados nas depend√™ncias]
    [Adicione bancos de dados REAIS se identificados]
    
    [Crie relacionamentos REAIS baseados nos imports e depend√™ncias da an√°lise]
```

## üìã Detalhes dos Componentes Reais
[Para cada arquivo/classe REAL da an√°lise:]

### [Nome Real do Arquivo/Classe]
- **Localiza√ß√£o:** [Caminho real do arquivo]
- **Linguagem:** [Linguagem real detectada]
- **Prop√≥sito:** [Prop√≥sito real identificado na an√°lise]
- **Fun√ß√µes Principais:** [Fun√ß√µes reais listadas]
- **Depend√™ncias:** [Imports reais identificados]
- **Complexidade:** [Complexidade real calculada]

## üîÑ Fluxo de Dados Real
[Baseado nos imports e depend√™ncias REAIS, descreva como os dados fluem entre os componentes REAIS]

## üèóÔ∏è Padr√µes Arquiteturais Identificados
[Identifique padr√µes REAIS baseados na estrutura e organiza√ß√£o dos arquivos analisados]

IMPORTANTE: Use SOMENTE informa√ß√µes REAIS da an√°lise fornecida. N√ÉO invente componentes gen√©ricos.
"""

    def _create_c4_code_prompt(self, section: Dict, state: DocumentationState, final_url: str) -> str:
        """Cria prompt para C4 Code Analysis"""
        structure_info = state.get("file_structure", {})
        
        return f"""
Crie uma documenta√ß√£o C4 CODE ANALYSIS baseada na an√°lise detalhada do c√≥digo:

T√çTULO: {section['title']}

AN√ÅLISE COMPLETA DOS ARQUIVOS:
{structure_info.get('code_analysis', 'An√°lise de c√≥digo n√£o dispon√≠vel')}

ESTRUTURA DETALHADA:
{structure_info.get('structure_analysis', 'Estrutura n√£o analisada')}

Crie documenta√ß√£o em Markdown seguindo o modelo C4 Code:

# {section['title']}

## üíª An√°lise Detalhada do C√≥digo

### Estrutura de Classes e Fun√ß√µes
[Baseado na an√°lise real dos arquivos]

### Padr√µes de C√≥digo Identificados
[Padr√µes arquiteturais encontrados na an√°lise]

### Depend√™ncias Internas
[Como as classes e m√≥dulos se relacionam]

## üèóÔ∏è Estrutura de C√≥digo

### Arquivos Principais Analisados
[Para cada arquivo analisado:]

#### [Nome do Arquivo]
- **Linguagem:** [Detectada na an√°lise]
- **Prop√≥sito:** [Identificado na an√°lise]
- **Classes:** [Listadas na an√°lise]
- **Fun√ß√µes:** [Listadas na an√°lise]
- **Complexidade:** [Calculada na an√°lise]
- **Imports:** [Depend√™ncias identificadas]

## üîç M√©tricas de C√≥digo
[Estat√≠sticas extra√≠das da an√°lise]

## üèõÔ∏è Arquitetura do C√≥digo
[Padr√µes arquiteturais identificados]

## üìà Qualidade e Complexidade
[Avalia√ß√£o baseada na an√°lise realizada]

## üîó Diagrama de Classes (se aplic√°vel)

```mermaid
classDiagram
    [Baseado nas classes identificadas na an√°lise]
```

Use APENAS dados reais da an√°lise dos arquivos fornecida.
"""

    def _create_mermaid_flowcharts_prompt(self, section: Dict, state: DocumentationState, final_url: str) -> str:
        """Cria prompt para fluxogramas Mermaid detalhados"""
        structure_info = state.get("file_structure", {})
        
        return f"""
Voc√™ √© um especialista em fluxogramas e diagramas Mermaid. Crie fluxogramas detalhados baseados EXCLUSIVAMENTE na an√°lise real do c√≥digo.

T√çTULO: {section['title']}

AN√ÅLISE COMPLETA DOS ARQUIVOS:
{structure_info.get('code_analysis', 'An√°lise de c√≥digo n√£o dispon√≠vel')}

ESTRUTURA DETALHADA:
{structure_info.get('structure_analysis', 'Estrutura n√£o analisada')}

DEPEND√äNCIAS IDENTIFICADAS:
{structure_info.get('dependencies', 'Depend√™ncias n√£o identificadas')}

INSTRU√á√ïES CR√çTICAS:
1. Use APENAS arquivos, fun√ß√µes e fluxos REAIS identificados na an√°lise
2. Crie fluxogramas para os processos REAIS encontrados no c√≥digo
3. Use nomes REAIS das fun√ß√µes e classes
4. Base os fluxos nas chamadas de fun√ß√£o REAIS identificadas
5. N√ÉO invente processos gen√©ricos

# {section['title']}

## üîÑ Fluxogramas dos Componentes Reais

### Fluxograma Principal do Sistema
[Baseado no arquivo principal identificado na an√°lise]

```mermaid
flowchart TD
    [Para cada fun√ß√£o/processo REAL identificado, crie um n√≥]
    [Exemplo: A[FuncaoRealPrincipal] --> B[FuncaoRealSecundaria]]
    [Use nomes REAIS das fun√ß√µes da an√°lise]
    
    [Conecte baseado nas chamadas de fun√ß√£o REAIS identificadas]
    [Adicione decis√µes baseadas em condicionais REAIS do c√≥digo]
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
```

### Fluxograma de Processamento de Dados
[APENAS se identificado processamento de dados na an√°lise]

```mermaid
flowchart LR
    [Baseado nos fluxos REAIS de dados identificados]
    [Use fun√ß√µes REAIS que manipulam dados]
    
    subgraph "M√≥dulo Real"
        [FuncaoRealEntrada] --> [FuncaoRealProcessamento]
        [FuncaoRealProcessamento] --> [FuncaoRealSaida]
    end
```

### Fluxograma de Intera√ß√£o entre M√≥dulos
[Baseado nos imports REAIS identificados]

```mermaid
flowchart TB
    [Para cada arquivo/m√≥dulo REAL:]
    
    subgraph "[NomeModuloReal1]"
        [FuncaoReal1]
        [FuncaoReal2]
    end
    
    subgraph "[NomeModuloReal2]"
        [FuncaoReal3]
        [FuncaoReal4]
    end
    
    [Conecte baseado nos imports REAIS]
    [FuncaoReal1] --> [FuncaoReal3]
    [FuncaoReal2] --> [FuncaoReal4]
```

### Fluxograma de Tratamento de Erros
[APENAS se identificado tratamento de erro na an√°lise]

```mermaid
flowchart TD
    [Baseado em try/catch ou tratamento de erro REAL encontrado]
```

### Fluxograma de Configura√ß√£o e Inicializa√ß√£o
[APENAS se identificados arquivos de config na an√°lise]

```mermaid
flowchart TD
    [Baseado nos arquivos de configura√ß√£o REAIS encontrados]
    [Use fun√ß√µes REAIS de inicializa√ß√£o identificadas]
```

## üìã Descri√ß√£o dos Fluxogramas

### [Nome do Fluxograma Real]
- **Baseado em:** [Arquivo/fun√ß√£o REAL da an√°lise]
- **Entrada:** [Par√¢metros REAIS identificados]
- **Processamento:** [L√≥gica REAL encontrada no c√≥digo]
- **Sa√≠da:** [Retorno REAL da fun√ß√£o]
- **Depend√™ncias:** [Chamadas REAIS para outras fun√ß√µes]

## üîß Detalhes de Implementa√ß√£o
[Para cada fluxo REAL identificado:]

### Processo: [Nome Real do Processo]
- **Arquivo:** [Localiza√ß√£o REAL]
- **Fun√ß√£o Principal:** [Nome REAL da fun√ß√£o]
- **Complexidade:** [Complexidade REAL calculada]
- **Chamadas:** [Fun√ß√µes REAIS que chama]

IMPORTANTE: Crie APENAS fluxogramas baseados em c√≥digo REAL analisado. N√ÉO invente processos gen√©ricos.
"""

    def _create_general_prompt(self, section: Dict, state: DocumentationState, final_url: str) -> str:
        """Cria prompt gen√©rico"""
        return f"""
Crie documenta√ß√£o para: {section['title']}

Descri√ß√£o: {section.get('description', 'Documenta√ß√£o geral')}

Reposit√≥rio: {final_url}

Crie documenta√ß√£o √∫til e informativa em formato Markdown.
"""
    
    def _create_fallback_content(self, section: Dict, state: DocumentationState) -> str:
        """Cria conte√∫do de fallback C4"""
        title = section.get('title', 'Documenta√ß√£o')
        repo_url = state.get("repo_url", "")
        
        return f"""# {title}

## üèóÔ∏è Documenta√ß√£o Arquitetural C4

Esta se√ß√£o documenta {title.lower()} seguindo o modelo de arquitetura C4.

## üöÄ Informa√ß√µes do Projeto

- **Projeto:** {repo_url}
- **Gerado em:** {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}
- **Sistema:** Skyone DocAgent v3.0
- **Modelo:** Arquitetura C4

## üìù Sobre o Modelo C4

O modelo C4 (Context, Container, Component, Code) fornece uma abordagem estruturada 
para visualizar a arquitetura de software em quatro n√≠veis hier√°rquicos.

## üîç An√°lise Necess√°ria

Para uma documenta√ß√£o completa desta se√ß√£o, √© necess√°ria uma an√°lise mais 
detalhada do c√≥digo-fonte do projeto.

---
*Gerado pelo Skyone DocAgent v3.0 ‚Ä¢ Arquitetura C4*
"""
    
    def _get_section_filename(self, title: str, index: int, anonymous: bool) -> str:
        """Gera nome do arquivo para se√ß√£o C4"""
        suffix = "_anonimo" if anonymous else ""
        
        title_lower = title.lower()
        if "context" in title_lower:
            return f"01_C4_Context_Diagram{suffix}.md"
        elif "container" in title_lower:
            return f"02_C4_Container_Diagram{suffix}.md"
        elif "component" in title_lower:
            return f"03_C4_Component_Diagram{suffix}.md"
        elif "code" in title_lower:
            return f"04_C4_Code_Analysis{suffix}.md"
        elif "mermaid" in title_lower or "flowchart" in title_lower:
            return f"05_Mermaid_Flowcharts{suffix}.md"
        elif "vis√£o" in title_lower or "geral" in title_lower:
            return f"01_visao_geral{suffix}.md"
        elif "instala√ß√£o" in title_lower or "guia" in title_lower:
            return f"02_guia_instalacao{suffix}.md"
        elif "t√©cnico" in title_lower or "relat√≥rio" in title_lower:
            return f"03_relatorio_tecnico{suffix}.md"
        else:
            safe_title = re.sub(r'[^\w\s-]', '', title)
            safe_title = re.sub(r'[-\s]+', '_', safe_title)
            return f"{index:02d}_{safe_title.lower()}{suffix}.md"

# =============================================================================
# CONSTRUTOR DO GRAFO LANGGRAPH
# =============================================================================

class DocAgentLangGraph:
    """Sistema principal de documenta√ß√£o baseado em LangGraph"""
    
    def __init__(self):
        self.llm_manager = LLMManager()
        self.agents = DocumentationAgents(self.llm_manager)
        self.graph = None
        self.app = None
        self._build_graph()
        logger.info("DocAgent LangGraph inicializado")
    
    def _build_graph(self):
        """Constr√≥i o grafo LangGraph"""
        try:
            if not LANGGRAPH_AVAILABLE:
                logger.error("LangGraph n√£o dispon√≠vel")
                return
            
            # Criar grafo
            workflow = StateGraph(DocumentationState)
            
            # Adicionar n√≥s
            workflow.add_node("clone_repository", self.agents.clone_repository_node)
            workflow.add_node("analyze_structure", self.agents.analyze_structure_node)
            workflow.add_node("generate_plan", self.agents.generate_documentation_plan_node)
            workflow.add_node("generate_docs", self.agents.generate_documentation_node)
            
            # Definir fluxo
            workflow.set_entry_point("clone_repository")
            workflow.add_edge("clone_repository", "analyze_structure")
            workflow.add_edge("analyze_structure", "generate_plan")
            workflow.add_edge("generate_plan", "generate_docs")
            workflow.add_edge("generate_docs", END)
            
            # Compilar com mem√≥ria
            memory = MemorySaver()
            self.app = workflow.compile(checkpointer=memory)
            
            logger.info("Grafo LangGraph constru√≠do com sucesso")
            
        except Exception as e:
            logger.error(f"Erro ao construir grafo: {e}")
    
    async def execute_documentation_flow(self, request: AnalysisRequest) -> Dict[str, Any]:
        """Executa o fluxo completo de documenta√ß√£o"""
        try:
            if not self.app:
                raise Exception("Grafo LangGraph n√£o inicializado")
            
            logger.info(f"Iniciando fluxo de documenta√ß√£o para: {request.repo_url}")
            
            # Configurar modelo LLM
            model_config = ModelConfig(
                provider=request.model_provider,
                model_name=request.model_name,
                api_key=os.environ.get("OPENAI_API_KEY") if request.model_provider == "openai" else None
            )
            
            if not self.llm_manager.configure_model(model_config):
                raise Exception("Falha na configura√ß√£o do modelo LLM")
            
            # Estado inicial
            initial_state = DocumentationState(
                repo_url=request.repo_url,
                model_provider=request.model_provider,
                model_name=request.model_name,
                anonymous=request.anonymous,
                max_files=request.max_files,
                deep_analysis=request.deep_analysis,
                repo_path=None,
                current_phase="init",
                progress=0,
                logs=["üöÄ Iniciando an√°lise LangGraph"],
                file_structure=None,
                code_analysis=None,
                architecture_analysis=None,
                documentation_plan=None,
                generated_docs=[],
                metadata={
                    "start_time": datetime.now().isoformat(),
                    "system": "DocAgent LangGraph v3.0"
                },
                error_count=0
            )
            
            # Configura√ß√£o do thread
            config = RunnableConfig(
                thread_id=f"doc_session_{int(time.time())}",
                recursion_limit=50
            )
            
            # Executar fluxo
            final_state = await self.app.ainvoke(initial_state, config=config)
            
            # Preparar resultado
            result = {
                "status": "success" if final_state["error_count"] == 0 else "partial_success",
                "message": f"Documenta√ß√£o gerada: {len(final_state['generated_docs'])} arquivos",
                "generated_docs": final_state["generated_docs"],
                "metadata": {
                    **final_state["metadata"],
                    "end_time": datetime.now().isoformat(),
                    "total_errors": final_state["error_count"],
                    "final_phase": final_state["current_phase"],
                    "model_used": f"{request.model_provider}/{request.model_name}"
                },
                "logs": final_state["logs"]
            }
            
            logger.info(f"Fluxo conclu√≠do: {result['status']}")
            return result
            
        except Exception as e:
            logger.error(f"Erro no fluxo de documenta√ß√£o: {e}")
            return {
                "status": "error",
                "message": f"Erro cr√≠tico: {str(e)}",
                "generated_docs": [],
                "metadata": {
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                },
                "logs": [f"‚ùå Erro cr√≠tico: {str(e)}"]
            }

# =============================================================================
# API WEB COM FASTAPI
# =============================================================================

if not WEB_AVAILABLE:
    logger.error("FastAPI n√£o dispon√≠vel")
    exit(1)

# Configurar aplica√ß√£o FastAPI
if CONFIG_AVAILABLE:
    app = FastAPI(
        title=config.SYSTEM_NAME,
        version=config.VERSION,
        description=config.DESCRIPTION,
        debug=config.DEBUG
    )
    
    # Configurar CORS baseado nas configura√ß√µes
    if config.ENABLE_CORS:
        app.add_middleware(
            CORSMiddleware,
            allow_origins=config.ALLOWED_ORIGINS,
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )
else:
    app = FastAPI(
        title="DocAgent LangGraph",
        version="3.0",
        description="Sistema de Documenta√ß√£o Autom√°tica com LangGraph, OpenAI e Ollama"
    )
    
    # CORS padr√£o
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

# Configurar diret√≥rios
if CONFIG_AVAILABLE:
    config.create_directories()
    static_dir = config.STATIC_DIR
    templates_dir = config.TEMPLATES_DIR
    docs_dir = config.DOCS_DIR
    workdir = config.WORKDIR
else:
    static_dir = Path("static")
    templates_dir = Path("templates")
    docs_dir = Path("docs")
    workdir = Path("workdir")
    
    for directory in [static_dir, templates_dir, docs_dir, workdir]:
        directory.mkdir(exist_ok=True)

try:
    app.mount("/static", StaticFiles(directory=str(static_dir)), name="static")
    templates = Jinja2Templates(directory=str(templates_dir))
except Exception as e:
    logger.warning(f"Erro ao configurar arquivos est√°ticos: {e}")

# Estado global da aplica√ß√£o
app_state = {
    "doc_agent": DocAgentLangGraph(),
    "github_fetcher": GitHubRepositoryFetcher(),
    "current_analysis": None,
    "analysis_status": AnalysisStatus(
        status="idle",
        phase="Aguardando",
        progress=0,
        message="Sistema LangGraph pronto"
    ),
    "user_sessions": {}
}

# =============================================================================
# ROTAS DA API
# =============================================================================

@app.get("/", response_class=HTMLResponse)
async def home(request: Request):
    """P√°gina principal"""
    try:
        return templates.TemplateResponse("index.html", {"request": request})
    except Exception as e:
        logger.error(f"Erro ao carregar template: {e}")
        return HTMLResponse(content="<h1>DocAgent LangGraph</h1><p>Erro ao carregar interface</p>")

@app.post("/api/search")
async def search_repositories(search_request: SearchRequest):
    """Busca reposit√≥rios"""
    try:
        logger.info(f"Buscando reposit√≥rios para: {search_request.usuario}")
        
        repositories = app_state["github_fetcher"].search_repositories(
            search_request.usuario,
            search_request.incluir_forks
        )
        
        return {
            "success": True,
            "repositories": [asdict(repo) for repo in repositories],
            "count": len(repositories),
            "user": search_request.usuario
        }
    except Exception as e:
        logger.error(f"Erro na busca: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/analyze")
async def start_analysis(analysis_request: AnalysisRequest, background_tasks: BackgroundTasks):
    """Inicia an√°lise com LangGraph"""
    try:
        logger.info(f"Iniciando an√°lise LangGraph: {analysis_request.repo_url}")
        
        # Reset status
        app_state["analysis_status"] = AnalysisStatus(
            status="starting",
            phase="Iniciando LangGraph",
            progress=0,
            message="Preparando sistema LangGraph...",
            logs=["üöÄ Sistema LangGraph iniciado"]
        )
        
        # Iniciar em background
        background_tasks.add_task(run_langgraph_analysis, analysis_request)
        
        return {
            "success": True,
            "message": "An√°lise LangGraph iniciada",
            "analysis_id": f"langgraph_{int(time.time())}",
            "model": f"{analysis_request.model_provider}/{analysis_request.model_name}"
        }
    except Exception as e:
        logger.error(f"Erro ao iniciar an√°lise: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/status")
async def get_analysis_status():
    """Obt√©m status da an√°lise"""
    try:
        return app_state["analysis_status"]
    except Exception as e:
        logger.error(f"Erro ao obter status: {e}")
        return AnalysisStatus(
            status="error",
            phase="Erro",
            progress=0,
            message=f"Erro no sistema: {str(e)}"
        )

@app.get("/api/results")
async def get_analysis_results():
    """Obt√©m resultados da an√°lise"""
    try:
        if app_state["current_analysis"]:
            return app_state["current_analysis"]
        else:
            raise HTTPException(status_code=404, detail="Nenhuma an√°lise dispon√≠vel")
    except Exception as e:
        logger.error(f"Erro ao obter resultados: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/models")
async def list_models():
    """Lista modelos dispon√≠veis"""
    try:
        available = app_state["doc_agent"].llm_manager.list_available_models()
        return {
            "success": True,
            "available": available,
            "providers": ["openai", "ollama"]
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/api/download/{filename}")
async def download_file(filename: str):
    """Download de arquivo gerado"""
    try:
        if ".." in filename or "/" in filename:
            raise HTTPException(status_code=400, detail="Nome de arquivo inv√°lido")
        
        file_path = Path("docs") / filename
        
        if file_path.exists() and file_path.is_file():
            return FileResponse(file_path, filename=filename)
        else:
            raise HTTPException(status_code=404, detail="Arquivo n√£o encontrado")
            
    except Exception as e:
        logger.error(f"Erro no download: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/download-all-zip")
async def download_all_docs():
    """Download de todos os documentos em ZIP"""
    try:
        docs_dir = Path("docs")
        if not docs_dir.exists():
            raise HTTPException(status_code=404, detail="Nenhum documento encontrado")
        
        doc_files = list(docs_dir.glob("*.md")) + list(docs_dir.glob("*.json"))
        
        if not doc_files:
            raise HTTPException(status_code=404, detail="Nenhum documento dispon√≠vel")
        
        # Criar ZIP
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        zip_filename = f"docagent_langgraph_{timestamp}.zip"
        zip_path = docs_dir / zip_filename
        
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for doc_file in doc_files:
                zipf.write(doc_file, doc_file.name)
        
        return FileResponse(
            zip_path,
            filename=zip_filename,
            media_type="application/zip"
        )
        
    except Exception as e:
        logger.error(f"Erro ao criar ZIP: {e}")
        raise HTTPException(status_code=500, detail=str(e))

class ModelSelectionRequest(BaseModel):
    """Requisi√ß√£o para configurar modelo"""
    provider: str  # "openai" ou "ollama"
    model_name: str
    api_key: Optional[str] = None
    base_url: Optional[str] = None

@app.post("/api/configure-model")
async def configure_model(model_request: ModelSelectionRequest):
    """Configura modelo LLM (OpenAI ou Ollama)"""
    try:
        logger.info(f"Configurando modelo: {model_request.provider}/{model_request.model_name}")
        
        # Validar provider
        if model_request.provider not in ["openai", "ollama"]:
            raise HTTPException(status_code=400, detail="Provider deve ser 'openai' ou 'ollama'")
        
        # Configurar modelo no DocAgent
        doc_agent = app_state["doc_agent"]
        config = ModelConfig(
            provider=model_request.provider,
            model_name=model_request.model_name,
            api_key=model_request.api_key,
            base_url=model_request.base_url
        )
        
        # Se for OpenAI e n√£o tiver API key na requisi√ß√£o, tentar pegar do ambiente
        if model_request.provider == "openai" and not model_request.api_key:
            config.api_key = os.environ.get("OPENAI_API_KEY")
            if not config.api_key:
                raise HTTPException(
                    status_code=400, 
                    detail="API Key OpenAI necess√°ria. Configure OPENAI_API_KEY ou forne√ßa na requisi√ß√£o."
                )
        
        # Configurar no LLM manager
        success = doc_agent.llm_manager.configure_model(config)
        
        if success:
            return {
                "success": True,
                "message": f"Modelo configurado: {model_request.provider}/{model_request.model_name}",
                "provider": model_request.provider,
                "model": model_request.model_name
            }
        else:
            raise HTTPException(status_code=500, detail="Falha ao configurar modelo")
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro ao configurar modelo: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/models/available")
async def get_available_models():
    """Lista todos os modelos dispon√≠veis"""
    try:
        doc_agent = app_state["doc_agent"]
        available = doc_agent.llm_manager.list_available_models()
        
        # Obter modelos Ollama detalhados
        ollama_models_detailed = doc_agent.llm_manager.get_ollama_models_detailed()
        
        # Verificar se OpenAI est√° configurada
        openai_configured = bool(os.environ.get("OPENAI_API_KEY"))
        
        # Verificar status do Ollama
        ollama_status = "unknown"
        try:
            result = subprocess.run(["ollama", "list"], capture_output=True, text=True, timeout=5)
            ollama_status = "running" if result.returncode == 0 else "stopped"
        except:
            ollama_status = "not_installed"
        
        return {
            "success": True,
            "models": available,
            "ollama_detailed": ollama_models_detailed,
            "status": {
                "openai_configured": openai_configured,
                "ollama_status": ollama_status
            },
            "recommended": {
                "openai": "gpt-4o",
                "ollama": ollama_models_detailed[0]["name"] if ollama_models_detailed else "qwen2.5:7b"
            }
        }
    except Exception as e:
        logger.error(f"Erro ao listar modelos: {e}")
        return {"success": False, "error": str(e)}

@app.post("/api/test-model")
async def test_model_connection(model_request: ModelSelectionRequest):
    """Testa conex√£o com modelo LLM"""
    try:
        logger.info(f"Testando modelo: {model_request.provider}/{model_request.model_name}")
        
        # Criar configura√ß√£o tempor√°ria
        config = ModelConfig(
            provider=model_request.provider,
            model_name=model_request.model_name,
            api_key=model_request.api_key,
            base_url=model_request.base_url
        )
        
        # Testar configura√ß√£o
        temp_manager = LLMManager()
        success = temp_manager.configure_model(config)
        
        if not success:
            raise Exception("Falha na configura√ß√£o do modelo")
        
        # Teste simples de gera√ß√£o
        test_llm = temp_manager.get_llm()
        test_message = HumanMessage(content="Responda apenas 'OK' se voc√™ est√° funcionando.")
        
        # Timeout para o teste
        import asyncio
        try:
            result = await asyncio.wait_for(
                test_llm.ainvoke([test_message]),
                timeout=30.0
            )
            
            response_text = result.content if hasattr(result, 'content') else str(result)
            
            return {
                "success": True,
                "message": f"Modelo {model_request.provider}/{model_request.model_name} testado com sucesso",
                "test_response": response_text[:100],
                "provider": model_request.provider,
                "model": model_request.model_name
            }
            
        except asyncio.TimeoutError:
            raise Exception("Timeout na resposta do modelo (30s)")
            
    except Exception as e:
        logger.error(f"Erro no teste do modelo: {e}")
        return {
            "success": False,
            "error": str(e),
            "provider": model_request.provider,
            "model": model_request.model_name
        }

@app.get("/health")
async def health_check():
    """Verifica√ß√£o de sa√∫de"""
    try:
        checks = {
            "langgraph_available": LANGGRAPH_AVAILABLE,
            "doc_agent_ready": app_state["doc_agent"] is not None,
            "github_fetcher_ready": app_state["github_fetcher"] is not None,
            "docs_directory": Path("docs").exists(),
            "workdir_exists": Path("workdir").exists()
        }
        
        # Verificar status do Ollama
        ollama_status = "unknown"
        try:
            result = subprocess.run(["ollama", "list"], capture_output=True, text=True, timeout=5)
            ollama_status = "running" if result.returncode == 0 else "stopped"
        except:
            ollama_status = "not_installed"
        
        # Verificar OpenAI
        openai_configured = bool(os.environ.get("OPENAI_API_KEY"))
        
        all_healthy = all(checks.values())
        
        return {
            "status": "healthy" if all_healthy else "degraded",
            "checks": checks,
            "langgraph_enabled": LANGGRAPH_AVAILABLE,
            "model_status": {
                "ollama_status": ollama_status,
                "openai_configured": openai_configured
            },
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

# =============================================================================
# FUN√á√ÉO DE AN√ÅLISE EM BACKGROUND
# =============================================================================

async def run_langgraph_analysis(analysis_request: AnalysisRequest):
    """Executa an√°lise LangGraph em background"""
    
    def update_status(phase: str, progress: int, message: str, step: str = ""):
        """Atualiza status da an√°lise"""
        current_logs = app_state["analysis_status"].logs.copy()
        if step:
            current_logs.append(f"üîÑ {step}: {message}")
        
        app_state["analysis_status"] = AnalysisStatus(
            status="running",
            phase=phase,
            progress=progress,
            message=message,
            logs=current_logs,
            current_step=step
        )
        logger.info(f"Status: {phase} ({progress}%) - {message}")
    
    try:
        logger.info(f"Background: Iniciando an√°lise LangGraph de {analysis_request.repo_url}")
        
        # Fase 1: Inicializa√ß√£o
        update_status("Inicializa√ß√£o LangGraph", 5, "Preparando sistema...", "Setup")
        
        doc_agent = app_state["doc_agent"]
        if not doc_agent or not doc_agent.app:
            raise Exception("DocAgent LangGraph n√£o inicializado")
        
        # Verificar se modelo est√° configurado
        if not doc_agent.llm_manager.current_config:
            # Configurar modelo padr√£o se n√£o estiver configurado
            default_config = ModelConfig(
                provider=analysis_request.model_provider,
                model_name=analysis_request.model_name
            )
            
            if analysis_request.model_provider == "openai":
                default_config.api_key = os.environ.get("OPENAI_API_KEY")
                if not default_config.api_key:
                    raise Exception("API Key OpenAI n√£o configurada")
            
            success = doc_agent.llm_manager.configure_model(default_config)
            if not success:
                raise Exception("Falha ao configurar modelo LLM")
        
        update_status("Configura√ß√£o", 8, f"Modelo {analysis_request.model_provider}/{analysis_request.model_name} configurado", "LLM")
        
        # Fase 2: Execu√ß√£o do fluxo
        update_status("Execu√ß√£o LangGraph", 10, "Executando fluxo de documenta√ß√£o...", "Flow")
        
        result = await doc_agent.execute_documentation_flow(analysis_request)
        
        if result["status"] in ["success", "partial_success"]:
            # Sucesso
            app_state["current_analysis"] = {
                "status": result["status"],
                "message": result["message"],
                "repository_url": analysis_request.repo_url,
                "analysis_data": result,
                "generated_docs": result["generated_docs"],
                "timestamp": datetime.now().isoformat(),
                "langgraph_enabled": True,
                "analysis_type": "LangGraph_enhanced",
                "model_used": f"{analysis_request.model_provider}/{analysis_request.model_name}"
            }
            
            app_state["analysis_status"] = AnalysisStatus(
                status="completed",
                phase="Conclu√≠do",
                progress=100,
                message=f"An√°lise LangGraph conclu√≠da! {len(result['generated_docs'])} documentos gerados.",
                logs=result["logs"] + ["üéâ An√°lise LangGraph finalizada"],
                current_step="Pronto para download"
            )
            
            logger.info(f"Background: An√°lise conclu√≠da - {len(result['generated_docs'])} arquivos")
        else:
            # Erro
            raise Exception(result.get("message", "Erro desconhecido"))
        
    except Exception as e:
        error_msg = f"Erro na an√°lise LangGraph: {str(e)}"
        logger.error(f"Background: {error_msg}")
        traceback.print_exc()
        
        app_state["analysis_status"] = AnalysisStatus(
            status="error",
            phase="Erro",
            progress=0,
            message=error_msg,
            logs=app_state["analysis_status"].logs + [f"‚ùå {error_msg}"],
            current_step="Falha"
        )

# =============================================================================
# FUN√á√ÉO PRINCIPAL
# =============================================================================

def main():
    """Fun√ß√£o principal"""
    try:
        print("üöÄ Iniciando DocAgent LangGraph v3.0")
        print("=" * 80)
        
        # Verificar depend√™ncias
        if not LANGGRAPH_AVAILABLE:
            print("‚ùå LangGraph n√£o dispon√≠vel")
            print("Execute: pip install langgraph langchain langchain-openai langchain-community")
            return 1
        
        if not WEB_AVAILABLE:
            print("‚ùå FastAPI n√£o dispon√≠vel")
            print("Execute: pip install fastapi uvicorn jinja2")
            return 1
        
        # Validar ambiente se configura√ß√£o dispon√≠vel
        if CONFIG_AVAILABLE:
            print("üîç Validando ambiente...")
            checks = config.validate_environment()
            
            for check_name, status in checks.items():
                icon = "‚úÖ" if status else "‚ö†Ô∏è"
                print(f"   {icon} {check_name}: {'OK' if status else 'N√£o dispon√≠vel'}")
            
            # Verificar se h√° problemas cr√≠ticos
            critical_checks = ["git_available", "directories_writable"]
            if not all(checks[check] for check in critical_checks if check in checks):
                print("‚ùå Verifica√ß√µes cr√≠ticas falharam")
                return 1
        else:
            # Verifica√ß√µes b√°sicas
            try:
                subprocess.run(["git", "--version"], capture_output=True, check=True)
                print("‚úÖ Git dispon√≠vel")
            except:
                print("‚ùå Git n√£o encontrado")
                return 1
            
            # Criar diret√≥rios b√°sicos
            for dir_name in ["docs", "workdir", "static", "templates", "logs"]:
                Path(dir_name).mkdir(exist_ok=True)
        
        print("\n" + "="*80)
        print("ü§ñ DocAgent LangGraph v3.0 - Sistema de Documenta√ß√£o Avan√ßada")
        print("="*80)
        print("üöÄ Funcionalidades Ativas:")
        print("   ‚úÖ LangGraph para fluxo de agentes especializados")
        print("   ‚úÖ Suporte OpenAI GPT-4 e Ollama local")
        print("   ‚úÖ An√°lise completa de reposit√≥rios GitHub")
        print("   ‚úÖ Documenta√ß√£o t√©cnica autom√°tica")
        print("   ‚úÖ Relat√≥rios an√¥nimos profissionais")
        print("   ‚úÖ Interface web moderna e responsiva")
        print("   ‚úÖ API REST completa com valida√ß√£o")
        print("   ‚úÖ Download individual e ZIP completo")
        print("   ‚úÖ Sistema de tools avan√ßadas")
        print("   ‚úÖ Checkpoints para recupera√ß√£o de estado")
        print("="*80)
        
        # Configura√ß√µes do servidor
        if CONFIG_AVAILABLE:
            host = config.HOST
            port = config.PORT
            log_level = config.LOG_LEVEL.lower()
        else:
            host = "0.0.0.0"
            port = 8001
            log_level = "info"
        
        print("üîó URLs de Acesso:")
        print(f"   üè† Interface Principal: http://localhost:{port}")
        print(f"   üìö Documenta√ß√£o API:   http://localhost:{port}/docs")
        print(f"   ‚ù§Ô∏è  Health Check:      http://localhost:{port}/health")
        print(f"   üìä Modelos Dispon√≠veis: http://localhost:{port}/api/models/available")
        print("="*80)
        print("üõ†Ô∏è Configura√ß√µes:")
        
        if os.environ.get("OPENAI_API_KEY"):
            print("   ‚úÖ OpenAI API Key configurada")
        else:
            print("   ‚ö†Ô∏è  OpenAI API Key n√£o configurada")
            print("      Configure: export OPENAI_API_KEY=sk-...")
        
        if os.environ.get("GITHUB_TOKEN"):
            print("   ‚úÖ GitHub Token configurado")
        else:
            print("   ‚ö†Ô∏è  GitHub Token n√£o configurado")
            print("      Para repos privados: export GITHUB_TOKEN=ghp_...")
        
        # Verificar Ollama
        try:
            result = subprocess.run(["ollama", "list"], capture_output=True, timeout=3)
            if result.returncode == 0:
                print("   ‚úÖ Ollama dispon√≠vel")
            else:
                print("   ‚ö†Ô∏è  Ollama n√£o est√° rodando")
                print("      Execute: ollama serve")
        except:
            print("   ‚ö†Ô∏è  Ollama n√£o instalado")
            print("      Instale em: https://ollama.ai/")
        
        print("="*80)
        print("üåü Iniciando servidor web...")
        print(f"üéØ Acesse: http://localhost:{port}")
        print("üîß Pressione Ctrl+C para parar")
        print("="*80)
        
        # Iniciar servidor
        uvicorn.run(
            app,
            host=host,
            port=port,
            log_level=log_level,
            access_log=True
        )
        
    except KeyboardInterrupt:
        print("\nüëã Encerrando DocAgent LangGraph...")
        print("   Obrigado por usar o sistema!")
        return 0
    except Exception as e:
        logger.error(f"Erro cr√≠tico: {e}")
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit(main())
