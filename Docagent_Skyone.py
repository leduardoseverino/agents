#!/usr/bin/env python3
"""
DocAgent LangGraph - Sistema de Documenta√ß√£o Autom√°tica de Reposit√≥rios
=======================================================================

Sistema avan√ßado baseado em LangGraph para an√°lise e documenta√ß√£o completa
de reposit√≥rios GitHub, com suporte para OpenAI e Ollama.

Caracter√≠sticas:
- Arquitetura baseada em LangGraph com fluxo de estados
- Agentes especializados para an√°lise e documenta√ß√£o
- Suporte para OpenAI GPT-4 e modelos Ollama locais
- Interface web moderna com autentica√ß√£o
- Relat√≥rios an√¥nimos e documenta√ß√£o t√©cnica completa
- Sistema de tools avan√ßadas para an√°lise de c√≥digo
- Arquitetura C4 Model para documenta√ß√£o arquitetural

Autor: DocAgent Skyone v3.0 LangGraph
"""

import os
import sys
import json
import subprocess
import tempfile
import shutil
import time
import logging
import traceback
import hashlib
import re
import fnmatch
import zipfile
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any, Union, TypedDict, Annotated
from dataclasses import dataclass, asdict
from concurrent.futures import ThreadPoolExecutor
import asyncio

# Importar configura√ß√µes
try:
    from config import config
    CONFIG_AVAILABLE = True
    print("‚úÖ Configura√ß√µes carregadas")
except ImportError:
    CONFIG_AVAILABLE = False
    print("‚ö†Ô∏è Arquivo de configura√ß√£o n√£o encontrado - usando padr√µes")

# LangGraph e LangChain imports
try:
    from langgraph.graph import StateGraph, END
    from langgraph.prebuilt import ToolNode
    from langgraph.checkpoint.memory import MemorySaver
    from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
    from langchain_core.tools import tool
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_openai import ChatOpenAI
    from langchain_community.llms import Ollama
    from langchain_core.runnables import RunnableConfig
    LANGGRAPH_AVAILABLE = True
    print("‚úÖ LangGraph e LangChain dispon√≠veis")
except ImportError as e:
    LANGGRAPH_AVAILABLE = False
    print(f"‚ùå LangGraph/LangChain n√£o dispon√≠vel: {e}")
    print("Execute: pip install langgraph langchain langchain-openai langchain-community")

# FastAPI e depend√™ncias web
try:
    from fastapi import FastAPI, Request, HTTPException, BackgroundTasks
    from fastapi.responses import HTMLResponse, JSONResponse, FileResponse
    from fastapi.staticfiles import StaticFiles
    from fastapi.templating import Jinja2Templates
    from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
    from fastapi.middleware.cors import CORSMiddleware
    import uvicorn
    WEB_AVAILABLE = True
    print("‚úÖ FastAPI dispon√≠vel")
except ImportError as e:
    WEB_AVAILABLE = False
    print(f"‚ùå FastAPI n√£o dispon√≠vel: {e}")

# Pydantic
try:
    from pydantic import BaseModel, Field, ConfigDict
    PYDANTIC_V2 = True
    print("‚úÖ Pydantic V2 detectado")
except ImportError:
    try:
        from pydantic import BaseModel, Field
        PYDANTIC_V2 = False
        print("‚ö†Ô∏è Pydantic V1 em uso")
    except ImportError as e:
        print(f"‚ùå Pydantic n√£o dispon√≠vel: {e}")
        exit(1)

# Configurar logging
if CONFIG_AVAILABLE:
    # Criar diret√≥rio de logs
    config.LOGS_DIR.mkdir(exist_ok=True)
    
    logging.basicConfig(
        level=getattr(logging, config.LOG_LEVEL),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(config.LOG_FILE),
            logging.StreamHandler(sys.stdout)
        ]
    )
else:
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

logger = logging.getLogger(__name__)

# =============================================================================
# ESTADO DO LANGGRAPH - DEFINI√á√ïES PRINCIPAIS
# =============================================================================

class DocumentationState(TypedDict):
    """Estado principal do fluxo LangGraph para documenta√ß√£o"""
    # Entrada
    repo_url: str
    model_provider: str  # "openai" ou "ollama"
    model_name: str
    anonymous: bool
    max_files: int
    deep_analysis: bool
    
    # Estado do processamento
    repo_path: Optional[str]
    current_phase: str
    progress: int
    logs: List[str]
    
    # An√°lise
    file_structure: Optional[Dict[str, Any]]
    code_analysis: Optional[Dict[str, Any]]
    architecture_analysis: Optional[Dict[str, Any]]
    
    # Documenta√ß√£o
    documentation_plan: Optional[Dict[str, Any]]
    generated_docs: List[str]
    
    # Metadata
    metadata: Dict[str, Any]
    error_count: int

# =============================================================================
# MODELOS DE DADOS
# =============================================================================

@dataclass
class RepositoryInfo:
    """Informa√ß√µes de um reposit√≥rio GitHub"""
    nome: str
    nome_completo: str
    descricao: str
    url: str
    linguagem_principal: str
    estrelas: int
    forks: int
    tamanho_kb: int
    atualizado_em: str
    topicos: List[str]
    privado: bool

@dataclass
class FileAnalysis:
    """An√°lise detalhada de um arquivo"""
    name: str
    path: str
    language: str
    size: int
    lines: int
    functions: List[str]
    classes: List[str]
    imports: List[str]
    purpose: str
    summary: str
    complexity: str

class AnalysisRequest(BaseModel):
    """Requisi√ß√£o de an√°lise"""
    repo_url: str
    model_provider: str = "ollama"  # "openai" ou "ollama"
    model_name: str = "qwen2.5:7b"
    max_files: int = 50
    deep_analysis: bool = True
    anonymous: bool = True

class AnalysisStatus(BaseModel):
    """Status da an√°lise"""
    status: str
    phase: str
    progress: int
    message: str
    logs: List[str] = []
    current_step: str = ""

class SearchRequest(BaseModel):
    """Requisi√ß√£o de busca de reposit√≥rios"""
    usuario: str
    incluir_forks: bool = False

class ModelConfig(BaseModel):
    """Configura√ß√£o de modelos"""
    provider: str  # "openai" ou "ollama"
    model_name: str
    api_key: Optional[str] = None
    base_url: Optional[str] = None
    temperature: float = 0.1
    max_tokens: int = 8192

# =============================================================================
# SISTEMA DE ANONIMIZA√á√ÉO
# =============================================================================

class AnonymizationSystem:
    """Sistema para anonimizar informa√ß√µes pessoais"""
    
    def __init__(self):
        self.user_mapping = {}
        self.repo_mapping = {}
        self.counter = 1
        print("üîí Sistema de anonimiza√ß√£o inicializado")
    
    def anonymize_repo_url(self, url: str) -> str:
        """Anonimiza URL do reposit√≥rio"""
        try:
            match = re.search(r'github\.com/([^/]+)/([^/]+)', url)
            if match:
                user, repo = match.groups()
                
                if user not in self.user_mapping:
                    self.user_mapping[user] = f"usuario_anonimo_{self.counter}"
                    self.counter += 1
                
                if repo not in self.repo_mapping:
                    self.repo_mapping[repo] = f"projeto_anonimo_{len(self.repo_mapping) + 1}"
                
                anon_user = self.user_mapping[user]
                anon_repo = self.repo_mapping[repo]
                
                return f"https://github.com/{anon_user}/{anon_repo}"
            
            return "https://github.com/usuario_anonimo/projeto_anonimo"
            
        except Exception as e:
            logger.warning(f"Erro na anonimiza√ß√£o: {e}")
            return "https://github.com/usuario_anonimo/projeto_anonimo"

# =============================================================================
# SISTEMA DE BUSCA GITHUB
# =============================================================================

class GitHubRepositoryFetcher:
    """Sistema para buscar reposit√≥rios do GitHub"""
    
    def __init__(self):
        self.session_cache = {}
        self.rate_limit_info = {}
        self.last_request_time = 0
        self.min_request_interval = 1.0
        print("üîç Sistema de busca GitHub inicializado")
    
    def _rate_limit_wait(self):
        """Implementa rate limiting b√°sico"""
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        
        if time_since_last < self.min_request_interval:
            wait_time = self.min_request_interval - time_since_last
            time.sleep(wait_time)
        
        self.last_request_time = time.time()
    
    def search_repositories(self, user_or_org: str, include_forks: bool = False) -> List[RepositoryInfo]:
        """Busca reposit√≥rios de um usu√°rio ou organiza√ß√£o"""
        try:
            clean_user = self._extract_user_from_input(user_or_org)
            logger.info(f"Buscando reposit√≥rios de: {clean_user}")
            
            if not self._verify_user_exists(clean_user):
                logger.error(f"Usu√°rio/organiza√ß√£o n√£o encontrado: {clean_user}")
                return []
            
            repositories = []
            page = 1
            
            while len(repositories) < 50 and page <= 5:
                repos_api_url = f"https://api.github.com/users/{clean_user}/repos?per_page=30&sort=updated&page={page}"
                
                try:
                    self._rate_limit_wait()
                    repos_data = self._make_github_request(repos_api_url)
                    
                    if not repos_data:
                        break
                    
                    for repo_data in repos_data:
                        if not include_forks and repo_data.get('fork', False):
                            continue
                        
                        if repo_data.get('private', False) and not os.environ.get('GITHUB_TOKEN'):
                            continue
                        
                        repo_info = self._process_repository_data(repo_data)
                        if repo_info:
                            repositories.append(repo_info)
                    
                    if len(repos_data) < 30:
                        break
                    
                    page += 1
                    
                except Exception as e:
                    logger.warning(f"Erro na p√°gina {page}: {e}")
                    break
            
            logger.info(f"Encontrados {len(repositories)} reposit√≥rios")
            return sorted(repositories, key=lambda x: x.estrelas, reverse=True)
            
        except Exception as e:
            logger.error(f"Erro ao buscar reposit√≥rios: {e}")
            return []
    
    def _extract_user_from_input(self, input_str: str) -> str:
        """Extrai nome de usu√°rio de diferentes formatos"""
        input_str = input_str.strip()
        
        if 'github.com' in input_str:
            match = re.search(r'github\.com/([^/]+)', input_str)
            if match:
                return match.group(1)
        
        return re.sub(r'[^a-zA-Z0-9\-_]', '', input_str)
    
    def _verify_user_exists(self, user: str) -> bool:
        """Verifica se usu√°rio existe"""
        try:
            import urllib.request
            url = f"https://api.github.com/users/{user}"
            self._rate_limit_wait()
            response = self._make_github_request(url)
            return response is not None
        except Exception as e:
            logger.warning(f"Erro ao verificar usu√°rio: {e}")
            return False
    
    def _make_github_request(self, url: str) -> Optional[Dict]:
        """Faz requisi√ß√£o para API do GitHub"""
        try:
            import urllib.request
            import urllib.error
            
            request = urllib.request.Request(url)
            request.add_header('User-Agent', 'Mozilla/5.0 (compatible; DocAgent-LangGraph/3.0)')
            request.add_header('Accept', 'application/vnd.github.v3+json')
            
            github_token = os.environ.get('GITHUB_TOKEN')
            if github_token:
                request.add_header('Authorization', f'token {github_token}')
            
            with urllib.request.urlopen(request, timeout=30) as response:
                if response.getcode() == 200:
                    return json.loads(response.read().decode('utf-8'))
                else:
                    logger.warning(f"Resposta HTTP {response.getcode()}")
                    return None
                    
        except urllib.error.HTTPError as e:
            if e.code == 404:
                logger.error(f"Recurso n√£o encontrado (404): {url}")
            elif e.code == 403:
                logger.error("403: Rate limit ou permiss√£o insuficiente")
            elif e.code == 401:
                logger.error("401: Token inv√°lido ou expirado")
            else:
                logger.error(f"Erro HTTP {e.code}: {e.reason}")
            return None
        except Exception as e:
            logger.error(f"Erro na requisi√ß√£o: {e}")
            return None
    
    def _process_repository_data(self, repo_data: Dict) -> Optional[RepositoryInfo]:
        """Processa dados do reposit√≥rio"""
        try:
            return RepositoryInfo(
                nome=repo_data.get('name', ''),
                nome_completo=repo_data.get('full_name', ''),
                descricao=(repo_data.get('description') or 'Sem descri√ß√£o')[:200],
                url=repo_data.get('html_url', ''),
                linguagem_principal=repo_data.get('language') or 'Desconhecida',
                estrelas=repo_data.get('stargazers_count', 0),
                forks=repo_data.get('forks_count', 0),
                tamanho_kb=repo_data.get('size', 0),
                atualizado_em=repo_data.get('updated_at', ''),
                topicos=repo_data.get('topics', []),
                privado=repo_data.get('private', False)
            )
        except Exception as e:
            logger.warning(f"Erro ao processar reposit√≥rio: {e}")
            return None

# =============================================================================
# SISTEMA DE TOOLS PARA AN√ÅLISE DE REPOSIT√ìRIO
# =============================================================================

class RepositoryAnalysisTools:
    """Tools especializadas para an√°lise de reposit√≥rio"""
    
    def __init__(self, repo_path: Union[str, Path]):
        self.repo_path = Path(repo_path)
        self.file_cache = {}
        self.analysis_cache = {}
        logger.info(f"Inicializando tools de an√°lise para: {self.repo_path}")
    
    def get_file_structure(self) -> Dict[str, Any]:
        """Analisa estrutura de arquivos do reposit√≥rio"""
        try:
            structure = {
                "total_files": 0,
                "code_files": 0,
                "languages": {},
                "directories": [],
                "important_files": [],
                "config_files": []
            }
            
            code_extensions = {
                '.py': 'Python', '.js': 'JavaScript', '.ts': 'TypeScript',
                '.java': 'Java', '.cpp': 'C++', '.c': 'C', '.go': 'Go',
                '.rs': 'Rust', '.php': 'PHP', '.rb': 'Ruby', '.swift': 'Swift'
            }
            
            for root, dirs, files in os.walk(self.repo_path):
                # Filtrar diret√≥rios irrelevantes
                dirs[:] = [d for d in dirs if not d.startswith('.') 
                          and d not in ['node_modules', '__pycache__', 'target', 'build', 'dist']]
                
                # Adicionar diret√≥rios importantes
                for dir_name in dirs:
                    if dir_name in ['src', 'lib', 'app', 'components', 'services', 'models']:
                        structure["directories"].append(str(Path(root) / dir_name))
                
                for file in files:
                    if file.startswith('.'):
                        continue
                    
                    structure["total_files"] += 1
                    file_path = Path(root) / file
                    ext = file_path.suffix.lower()
                    
                    # Arquivos de c√≥digo
                    if ext in code_extensions:
                        structure["code_files"] += 1
                        lang = code_extensions[ext]
                        structure["languages"][lang] = structure["languages"].get(lang, 0) + 1
                    
                    # Arquivos importantes
                    if (file.lower() in ['readme.md', 'package.json', 'requirements.txt', 'dockerfile'] or
                        'main' in file.lower() or 'index' in file.lower() or 'app' in file.lower()):
                        structure["important_files"].append(str(file_path.relative_to(self.repo_path)))
                    
                    # Arquivos de configura√ß√£o
                    if ext in ['.json', '.yml', '.yaml', '.toml', '.ini', '.cfg']:
                        structure["config_files"].append(str(file_path.relative_to(self.repo_path)))
            
            return structure
            
        except Exception as e:
            logger.error(f"Erro na an√°lise de estrutura: {e}")
            return {"error": str(e)}
    
    def analyze_code_files(self, max_files: int = 20) -> List[FileAnalysis]:
        """Analisa arquivos de c√≥digo em detalhes"""
        try:
            analyses = []
            
            # Padr√µes de arquivos importantes
            important_patterns = [
                'main.py', 'app.py', 'index.js', 'server.py', 'api.py',
                'models.py', 'views.py', 'controllers.py', 'routes.py',
                'utils.py', 'helpers.js', 'config.py', 'settings.py'
            ]
            
            for root, dirs, files in os.walk(self.repo_path):
                dirs[:] = [d for d in dirs if not d.startswith('.')]
                
                for file in files:
                    if len(analyses) >= max_files:
                        break
                    
                    file_path = Path(root) / file
                    
                    # Priorizar arquivos importantes
                    is_important = any(pattern in file.lower() for pattern in important_patterns)
                    is_code = file_path.suffix.lower() in ['.py', '.js', '.ts', '.java', '.go', '.rs']
                    
                    if not (is_important or is_code):
                        continue
                    
                    try:
                        if file_path.stat().st_size > 500 * 1024:  # Skip files > 500KB
                            continue
                        
                        content = file_path.read_text(encoding='utf-8', errors='ignore')
                        language = self._get_language(file_path.suffix.lower())
                        
                        analysis = self._analyze_file_content(file_path, content, language)
                        analyses.append(analysis)
                        
                    except Exception as e:
                        logger.warning(f"Erro ao analisar {file}: {e}")
                        continue
                
                if len(analyses) >= max_files:
                    break
            
            logger.info(f"Analisados {len(analyses)} arquivos de c√≥digo")
            return analyses
            
        except Exception as e:
            logger.error(f"Erro na an√°lise de arquivos: {e}")
            return []
    
    def _analyze_file_content(self, file_path: Path, content: str, language: str) -> FileAnalysis:
        """Analisa conte√∫do de um arquivo"""
        try:
            lines = [line for line in content.split('\n') if line.strip()]
            
            # Extrair fun√ß√µes, classes e imports
            functions = self._extract_functions(content, language)
            classes = self._extract_classes(content, language)
            imports = self._extract_imports(content, language)
            
            # Determinar prop√≥sito
            purpose = self._determine_file_purpose(file_path, content, language)
            
            # Gerar resumo
            summary = self._generate_file_summary(file_path, content, functions, classes)
            
            # Calcular complexidade
            complexity = self._calculate_complexity(content, functions, classes)
            
            return FileAnalysis(
                name=file_path.name,
                path=str(file_path.relative_to(self.repo_path)),
                language=language,
                size=len(content.encode('utf-8')),
                lines=len(lines),
                functions=functions[:10],
                classes=classes[:10],
                imports=imports[:15],
                purpose=purpose,
                summary=summary,
                complexity=complexity
            )
            
        except Exception as e:
            logger.warning(f"Erro ao analisar arquivo {file_path}: {e}")
            return FileAnalysis(
                name=file_path.name,
                path=str(file_path),
                language=language,
                size=0,
                lines=0,
                functions=[],
                classes=[],
                imports=[],
                purpose="Arquivo de c√≥digo",
                summary=f"Arquivo {language}",
                complexity="Baixa"
            )
    
    def _get_language(self, ext: str) -> str:
        """Identifica linguagem pela extens√£o"""
        language_map = {
            '.py': 'Python', '.js': 'JavaScript', '.ts': 'TypeScript',
            '.java': 'Java', '.cpp': 'C++', '.c': 'C', '.go': 'Go',
            '.rs': 'Rust', '.php': 'PHP', '.rb': 'Ruby', '.swift': 'Swift',
            '.html': 'HTML', '.css': 'CSS', '.sql': 'SQL', '.sh': 'Shell'
        }
        return language_map.get(ext, 'Unknown')
    
    def _extract_functions(self, content: str, language: str) -> List[str]:
        """Extrai fun√ß√µes do c√≥digo"""
        functions = []
        try:
            if language == 'Python':
                pattern = r'def\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\('
            elif language in ['JavaScript', 'TypeScript']:
                pattern = r'function\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\('
            elif language == 'Java':
                pattern = r'(?:public|private|protected)?\s*(?:static)?\s*\w+\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\('
            else:
                return []
            
            matches = re.findall(pattern, content, re.MULTILINE)
            functions = list(set(matches)) if matches else []
        except Exception:
            pass
        
        return functions
    
    def _extract_classes(self, content: str, language: str) -> List[str]:
        """Extrai classes do c√≥digo"""
        classes = []
        try:
            if language in ['Python', 'Java', 'JavaScript', 'TypeScript']:
                pattern = r'class\s+([a-zA-Z_][a-zA-Z0-9_]*)'
                matches = re.findall(pattern, content, re.MULTILINE)
                classes = list(set(matches)) if matches else []
        except Exception:
            pass
        
        return classes
    
    def _extract_imports(self, content: str, language: str) -> List[str]:
        """Extrai imports do c√≥digo"""
        imports = []
        try:
            if language == 'Python':
                pattern = r'(?:from\s+[\w.]+\s+)?import\s+([\w\s,.*]+)'
            elif language in ['JavaScript', 'TypeScript']:
                pattern = r'import\s+.*?from\s+[\'"]([^\'"]+)[\'"]'
            elif language == 'Java':
                pattern = r'import\s+([\w.]+)'
            else:
                return []
            
            matches = re.findall(pattern, content, re.MULTILINE)
            for match in matches:
                if isinstance(match, str):
                    import_name = match.strip().split(',')[0].strip()
                    if import_name and import_name not in imports:
                        imports.append(import_name)
        except Exception:
            pass
        
        return imports
    
    def _determine_file_purpose(self, file_path: Path, content: str, language: str) -> str:
        """Determina o prop√≥sito do arquivo"""
        filename = file_path.name.lower()
        
        if 'test' in filename:
            return "Arquivo de testes"
        elif filename in ['main.py', 'app.py', 'index.js']:
            return "Ponto de entrada da aplica√ß√£o"
        elif filename in ['config.py', 'settings.py']:
            return "Arquivo de configura√ß√£o"
        elif 'api' in filename or 'controller' in filename:
            return "Controlador de API"
        elif 'model' in filename:
            return "Modelo de dados"
        elif 'view' in filename or 'component' in filename:
            return "Componente de interface"
        elif filename.endswith('.md'):
            return "Documenta√ß√£o"
        else:
            return f"Arquivo {language} do projeto"
    
    def _generate_file_summary(self, file_path: Path, content: str, functions: List[str], classes: List[str]) -> str:
        """Gera resumo do arquivo"""
        lines_count = len([l for l in content.split('\n') if l.strip()])
        summary_parts = [f"Arquivo com {lines_count} linhas"]
        
        if classes:
            summary_parts.append(f"{len(classes)} classe(s)")
        if functions:
            summary_parts.append(f"{len(functions)} fun√ß√£o(√µes)")
        
        return ", ".join(summary_parts)
    
    def _calculate_complexity(self, content: str, functions: List[str], classes: List[str]) -> str:
        """Calcula complexidade do arquivo"""
        lines = len([l for l in content.split('\n') if l.strip()])
        complexity_score = 0
        
        if lines > 200:
            complexity_score += 2
        elif lines > 50:
            complexity_score += 1
        
        complexity_score += len(functions) + len(classes)
        
        control_structures = len(re.findall(r'\b(if|for|while|try|catch)\b', content))
        if control_structures > 20:
            complexity_score += 2
        elif control_structures > 10:
            complexity_score += 1
        
        if complexity_score >= 5:
            return "Alta"
        elif complexity_score >= 3:
            return "M√©dia"
        else:
            return "Baixa"

# =============================================================================
# TOOLS LANGGRAPH PARA AN√ÅLISE
# =============================================================================

@tool
def analyze_repository_structure(repo_path: str) -> str:
    """Analisa a estrutura completa do reposit√≥rio"""
    try:
        tools = RepositoryAnalysisTools(repo_path)
        structure = tools.get_file_structure()
        
        if "error" in structure:
            return f"Erro na an√°lise: {structure['error']}"
        
        result = f"""## üìÅ Estrutura do Reposit√≥rio

### üìä Estat√≠sticas Gerais:
- **Total de arquivos:** {structure['total_files']:,}
- **Arquivos de c√≥digo:** {structure['code_files']:,}
- **Linguagens detectadas:** {len(structure['languages'])}

### üíª Distribui√ß√£o por Linguagem:
"""
        for lang, count in sorted(structure['languages'].items(), key=lambda x: x[1], reverse=True):
            percentage = (count / structure['code_files']) * 100 if structure['code_files'] > 0 else 0
            result += f"- **{lang}:** {count} arquivos ({percentage:.1f}%)\n"
        
        result += "\n### üìÅ Diret√≥rios Importantes:\n"
        for directory in structure['directories'][:10]:
            result += f"- {directory}\n"
        
        result += "\n### üéØ Arquivos Importantes:\n"
        for file in structure['important_files'][:15]:
            result += f"- {file}\n"
        
        return result
        
    except Exception as e:
        return f"Erro na an√°lise de estrutura: {str(e)}"

@tool
def analyze_code_files(repo_path: str, max_files: int = 20) -> str:
    """Analisa arquivos de c√≥digo em detalhes"""
    try:
        tools = RepositoryAnalysisTools(repo_path)
        analyses = tools.analyze_code_files(max_files)
        
        if not analyses:
            return "Nenhum arquivo de c√≥digo encontrado para an√°lise"
        
        result = f"## üî¨ An√°lise Detalhada de Arquivos ({len(analyses)} arquivos)\n\n"
        
        for i, analysis in enumerate(analyses[:15], 1):
            result += f"### {i}. {analysis.name} ({analysis.language})\n"
            result += f"**Localiza√ß√£o:** `{analysis.path}`\n"
            result += f"**Tamanho:** {analysis.size:,} bytes | **Linhas:** {analysis.lines:,} | **Complexidade:** {analysis.complexity}\n"
            result += f"**Prop√≥sito:** {analysis.purpose}\n"
            result += f"**Resumo:** {analysis.summary}\n"
            
            if analysis.functions:
                result += f"**Fun√ß√µes:** {', '.join(analysis.functions[:5])}"
                if len(analysis.functions) > 5:
                    result += f" e mais {len(analysis.functions) - 5}"
                result += "\n"
            
            if analysis.classes:
                result += f"**Classes:** {', '.join(analysis.classes[:3])}"
                if len(analysis.classes) > 3:
                    result += f" e mais {len(analysis.classes) - 3}"
                result += "\n"
            
            if analysis.imports:
                result += f"**Principais imports:** {', '.join(analysis.imports[:5])}\n"
            
            result += "\n---\n\n"
        
        return result
        
    except Exception as e:
        return f"Erro na an√°lise de arquivos: {str(e)}"

@tool
def read_file_content(repo_path: str, file_path: str) -> str:
    """L√™ conte√∫do de um arquivo espec√≠fico"""
    try:
        full_path = Path(repo_path) / file_path
        
        if not full_path.exists():
            return f"Arquivo n√£o encontrado: {file_path}"
        
        if full_path.stat().st_size > 100 * 1024:  # 100KB limit
            return f"Arquivo muito grande: {file_path}"
        
        content = full_path.read_text(encoding='utf-8', errors='ignore')
        
        return f"""## üìÑ Arquivo: {file_path}

**Tamanho:** {full_path.stat().st_size:,} bytes
**Linhas:** {len(content.split(chr(10)))}

### Conte√∫do:
```{full_path.suffix[1:] if full_path.suffix else 'text'}
{content[:2000]}{'...' if len(content) > 2000 else ''}
```
"""
        
    except Exception as e:
        return f"Erro ao ler arquivo {file_path}: {str(e)}"

@tool
def find_dependencies(repo_path: str) -> str:
    """Encontra e analisa arquivos de depend√™ncias"""
    try:
        dependency_files = {
            'package.json': 'Node.js',
            'requirements.txt': 'Python',
            'Pipfile': 'Python (Pipenv)',
            'pyproject.toml': 'Python (Poetry)',
            'pom.xml': 'Java (Maven)',
            'build.gradle': 'Java (Gradle)',
            'Cargo.toml': 'Rust',
            'go.mod': 'Go',
            'composer.json': 'PHP'
        }
        
        found_deps = []
        repo_path = Path(repo_path)
        
        for dep_file, tech in dependency_files.items():
            file_path = repo_path / dep_file
            if file_path.exists():
                try:
                    content = file_path.read_text(encoding='utf-8', errors='ignore')
                    size = file_path.stat().st_size
                    
                    found_deps.append({
                        'file': dep_file,
                        'technology': tech,
                        'size': size,
                        'content_preview': content[:500]
                    })
                except Exception as e:
                    logger.warning(f"Erro ao ler {dep_file}: {e}")
        
        if not found_deps:
            return "Nenhum arquivo de depend√™ncias encontrado"
        
        result = "## üì¶ Arquivos de Depend√™ncias Encontrados\n\n"
        
        for dep in found_deps:
            result += f"### {dep['file']} ({dep['technology']})\n"
            result += f"**Tamanho:** {dep['size']:,} bytes\n\n"
            
            if dep['file'] == 'package.json':
                try:
                    pkg_data = json.loads(dep['content_preview'])
                    if 'dependencies' in pkg_data:
                        result += "**Depend√™ncias principais:**\n"
                        for pkg, version in list(pkg_data['dependencies'].items())[:10]:
                            result += f"- {pkg}: {version}\n"
                except:
                    pass
            elif dep['file'] == 'requirements.txt':
                lines = dep['content_preview'].split('\n')[:15]
                result += "**Depend√™ncias:**\n"
                for line in lines:
                    if line.strip() and not line.startswith('#'):
                        result += f"- {line.strip()}\n"
            
            result += "\n---\n\n"
        
        return result
        
    except Exception as e:
        return f"Erro na an√°lise de depend√™ncias: {str(e)}"

# =============================================================================
# SISTEMA DE MODELOS LLM
# =============================================================================

class LLMManager:
    """Gerenciador de modelos LLM (OpenAI e Ollama)"""
    
    def __init__(self):
        self.current_config = None
        self.available_models = {
            "openai": ["gpt-4o", "gpt-4o-mini", "gpt-3.5-turbo"],
            "ollama": []
        }
        self._check_ollama_models()
        logger.info("LLM Manager inicializado")
    
    def _check_ollama_models(self):
        """Verifica modelos Ollama dispon√≠veis"""
        try:
            result = subprocess.run(["ollama", "list"], capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                models = []
                for line in result.stdout.strip().split('\n')[1:]:
                    if line.strip():
                        model_name = line.split()[0]
                        models.append(model_name)
                self.available_models["ollama"] = models
                logger.info(f"Modelos Ollama encontrados: {models}")
            else:
                logger.warning("Ollama n√£o est√° rodando")
        except Exception as e:
            logger.warning(f"Erro ao verificar Ollama: {e}")
    
    def configure_model(self, config: ModelConfig):
        """Configura modelo LLM"""
        try:
            self.current_config = config
            
            if config.provider == "openai":
                if not config.api_key:
                    config.api_key = os.environ.get("OPENAI_API_KEY")
                
                if not config.api_key:
                    raise ValueError("OPENAI_API_KEY n√£o configurada")
                
                self.llm = ChatOpenAI(
                    model=config.model_name,
                    temperature=config.temperature,
                    max_tokens=config.max_tokens,
                    api_key=config.api_key
                )
                
            elif config.provider == "ollama":
                self.llm = Ollama(
                    model=config.model_name,
                    temperature=config.temperature,
                    base_url=config.base_url or "http://localhost:11434"
                )
            
            else:
                raise ValueError(f"Provider n√£o suportado: {config.provider}")
            
            logger.info(f"Modelo configurado: {config.provider}/{config.model_name}")
            return True
            
        except Exception as e:
            logger.error(f"Erro ao configurar modelo: {e}")
            return False
    
    def get_llm(self):
        """Retorna inst√¢ncia do LLM configurado"""
        if not hasattr(self, 'llm'):
            # Configura√ß√£o padr√£o
            default_config = ModelConfig(
                provider="ollama",
                model_name="qwen2.5:7b"
            )
            self.configure_model(default_config)
        
        return self.llm
    
    def list_available_models(self) -> Dict[str, List[str]]:
        """Lista modelos dispon√≠veis"""
        self._check_ollama_models()  # Atualizar lista Ollama
        return self.available_models.copy()

# =============================================================================
# N√ìS DO LANGGRAPH - AGENTES ESPECIALIZADOS
# =============================================================================

class DocumentationAgents:
    """Agentes especializados para documenta√ß√£o usando LangGraph"""
    
    def __init__(self, llm_manager: LLMManager):
        self.llm_manager = llm_manager
        self.anonymizer = AnonymizationSystem()
        logger.info("Agentes de documenta√ß√£o inicializados")
    
    async def clone_repository_node(self, state: DocumentationState) -> DocumentationState:
        """N√≥ para clonar reposit√≥rio"""
        try:
            repo_url = state["repo_url"]
            logger.info(f"Clonando reposit√≥rio: {repo_url}")
            
            # Validar URL
            if not self._validate_github_url(repo_url):
                state["logs"].append("‚ùå URL inv√°lida")
                state["error_count"] += 1
                return state
            
            # Preparar diret√≥rio
            repo_name = repo_url.split("/")[-1].replace(".git", "")
            workdir = Path("workdir").resolve()
            workdir.mkdir(exist_ok=True)
            repo_path = workdir / repo_name
            
            # Remover se existir
            if repo_path.exists():
                shutil.rmtree(repo_path, ignore_errors=True)
            
            # Clone
            cmd = ["git", "clone", "--depth", "1", repo_url, str(repo_path)]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0 and repo_path.exists():
                state["repo_path"] = str(repo_path)
                state["current_phase"] = "cloned"
                state["progress"] = 20
                state["logs"].append("‚úÖ Reposit√≥rio clonado com sucesso")
                logger.info(f"Clone conclu√≠do: {repo_path}")
            else:
                state["logs"].append(f"‚ùå Falha no clone: {result.stderr}")
                state["error_count"] += 1
            
            return state
            
        except Exception as e:
            logger.error(f"Erro no clone: {e}")
            state["logs"].append(f"‚ùå Erro no clone: {str(e)}")
            state["error_count"] += 1
            return state
    
    async def analyze_structure_node(self, state: DocumentationState) -> DocumentationState:
        """N√≥ para an√°lise de estrutura"""
        try:
            repo_path = state.get("repo_path")
            if not repo_path:
                state["logs"].append("‚ùå Caminho do reposit√≥rio n√£o encontrado")
                state["error_count"] += 1
                return state
            
            logger.info("Analisando estrutura do reposit√≥rio")
            
            # Usar tool de an√°lise
            structure_result = analyze_repository_structure.invoke({"repo_path": repo_path})
            
            # Analisar arquivos de c√≥digo
            code_result = analyze_code_files.invoke({
                "repo_path": repo_path, 
                "max_files": state.get("max_files", 20)
            })
            
            # Encontrar depend√™ncias
            deps_result = find_dependencies.invoke({"repo_path": repo_path})
            
            state["file_structure"] = {
                "structure_analysis": structure_result,
                "code_analysis": code_result,
                "dependencies": deps_result
            }
            
            state["current_phase"] = "analyzed"
            state["progress"] = 40
            state["logs"].append("‚úÖ Estrutura analisada")
            
            return state
            
        except Exception as e:
            logger.error(f"Erro na an√°lise de estrutura: {e}")
            state["logs"].append(f"‚ùå Erro na an√°lise: {str(e)}")
            state["error_count"] += 1
            return state
    
    async def generate_documentation_plan_node(self, state: DocumentationState) -> DocumentationState:
        """N√≥ para gerar plano de documenta√ß√£o"""
        try:
            logger.info("Gerando plano de documenta√ß√£o")
            
            llm = self.llm_manager.get_llm()
            
            # Preparar contexto da an√°lise
            structure_info = state.get("file_structure", {})
            
            # Prompt para planejamento
            planning_prompt = ChatPromptTemplate.from_template("""
Voc√™ √© um especialista em documenta√ß√£o t√©cnica. Baseado na an√°lise do reposit√≥rio abaixo, 
crie um plano detalhado para documenta√ß√£o completa em formato JSON.

AN√ÅLISE DO REPOSIT√ìRIO:
{structure_analysis}

{code_analysis}

{dependencies}

Crie um plano JSON com exatamente 3 se√ß√µes:
1. "Vis√£o Geral do Projeto" - tecnologias, prop√≥sito, arquitetura
2. "Guia de Instala√ß√£o" - pr√©-requisitos, instala√ß√£o, configura√ß√£o
3. "Relat√≥rio T√©cnico" - an√°lise detalhada dos arquivos e c√≥digo

Formato JSON obrigat√≥rio:
{{
  "overview": "Descri√ß√£o geral do projeto baseada na an√°lise",
  "sections": [
    {{
      "title": "Vis√£o Geral do Projeto",
      "description": "An√°lise completa das tecnologias e arquitetura",
      "content_type": "overview"
    }},
    {{
      "title": "Guia de Instala√ß√£o e Configura√ß√£o", 
      "description": "Instru√ß√µes detalhadas baseadas nas depend√™ncias encontradas",
      "content_type": "installation"
    }},
    {{
      "title": "Relat√≥rio T√©cnico dos Arquivos",
      "description": "An√°lise t√©cnica detalhada de cada arquivo importante",
      "content_type": "technical"
    }}
  ]
}}

Responda APENAS com o JSON v√°lido.
""")
            
            # Executar planejamento
            chain = planning_prompt | llm
            
            planning_result = await chain.ainvoke({
                "structure_analysis": structure_info.get("structure_analysis", ""),
                "code_analysis": structure_info.get("code_analysis", ""),
                "dependencies": structure_info.get("dependencies", "")
            })
            
            # Extrair JSON do resultado
            try:
                if hasattr(planning_result, 'content'):
                    plan_text = planning_result.content
                else:
                    plan_text = str(planning_result)
                
                # Extrair JSON
                json_match = re.search(r'\{.*\}', plan_text, re.DOTALL)
                if json_match:
                    plan_data = json.loads(json_match.group())
                    state["documentation_plan"] = plan_data
                    state["logs"].append("‚úÖ Plano de documenta√ß√£o criado")
                else:
                    raise ValueError("JSON n√£o encontrado na resposta")
                    
            except Exception as e:
                logger.warning(f"Erro ao extrair plano JSON: {e}")
                # Plano padr√£o
                state["documentation_plan"] = {
                    "overview": "Projeto analisado automaticamente",
                    "sections": [
                        {"title": "Vis√£o Geral do Projeto", "description": "An√°lise geral", "content_type": "overview"},
                        {"title": "Guia de Instala√ß√£o", "description": "Instru√ß√µes de instala√ß√£o", "content_type": "installation"},
                        {"title": "Relat√≥rio T√©cnico", "description": "An√°lise t√©cnica", "content_type": "technical"}
                    ]
                }
                state["logs"].append("‚ö†Ô∏è Usando plano padr√£o")
            
            state["current_phase"] = "planned"
            state["progress"] = 60
            
            return state
            
        except Exception as e:
            logger.error(f"Erro no planejamento: {e}")
            state["logs"].append(f"‚ùå Erro no planejamento: {str(e)}")
            state["error_count"] += 1
            return state
    
    async def generate_documentation_node(self, state: DocumentationState) -> DocumentationState:
        """N√≥ para gerar documenta√ß√£o"""
        try:
            logger.info("Gerando documenta√ß√£o")
            
            plan = state.get("documentation_plan", {})
            sections = plan.get("sections", [])
            
            if not sections:
                state["logs"].append("‚ùå Plano de documenta√ß√£o n√£o encontrado")
                state["error_count"] += 1
                return state
            
            llm = self.llm_manager.get_llm()
            docs_dir = Path("docs")
            docs_dir.mkdir(exist_ok=True)
            
            generated_files = []
            
            for i, section in enumerate(sections):
                try:
                    logger.info(f"Gerando se√ß√£o: {section['title']}")
                    
                    # Prompt espec√≠fico por tipo de se√ß√£o
                    doc_content = await self._generate_section_content(
                        llm, section, state, i + 1
                    )
                    
                    # Salvar arquivo
                    filename = self._get_section_filename(section['title'], i, state.get("anonymous", True))
                    file_path = docs_dir / filename
                    
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(doc_content)
                    
                    generated_files.append(filename)
                    state["logs"].append(f"‚úÖ Se√ß√£o criada: {section['title']}")
                    
                except Exception as e:
                    logger.error(f"Erro na se√ß√£o {section['title']}: {e}")
                    state["logs"].append(f"‚ùå Erro na se√ß√£o {section['title']}: {str(e)}")
            
            state["generated_docs"] = generated_files
            state["current_phase"] = "completed"
            state["progress"] = 100
            state["logs"].append(f"üéâ Documenta√ß√£o completa: {len(generated_files)} arquivos")
            
            return state
            
        except Exception as e:
            logger.error(f"Erro na gera√ß√£o de documenta√ß√£o: {e}")
            state["logs"].append(f"‚ùå Erro na documenta√ß√£o: {str(e)}")
            state["error_count"] += 1
            return state
    
    def _validate_github_url(self, url: str) -> bool:
        """Valida URL do GitHub"""
        pattern = r"^https://github\.com/[\w\-\.]+/[\w\-\.]+/?$"
        return bool(re.match(pattern, url.strip()))
    
    async def _generate_section_content(self, llm, section: Dict, state: DocumentationState, section_num: int) -> str:
        """Gera conte√∫do de uma se√ß√£o espec√≠fica"""
        try:
            content_type = section.get("content_type", "general")
            repo_url = state["repo_url"]
            anonymous = state.get("anonymous", True)
            
            # Anonimizar URL se necess√°rio
            final_url = self.anonymizer.anonymize_repo_url(repo_url) if anonymous else repo_url
            
            if content_type == "overview":
                prompt = self._create_overview_prompt(section, state, final_url)
            elif content_type == "installation":
                prompt = self._create_installation_prompt(section, state, final_url)
            elif content_type == "technical":
                prompt = self._create_technical_prompt(section, state, final_url)
            else:
                prompt = self._create_general_prompt(section, state, final_url)
            
            # Gerar conte√∫do
            result = await llm.ainvoke([HumanMessage(content=prompt)])
            
            if hasattr(result, 'content'):
                return result.content
            else:
                return str(result)
                
        except Exception as e:
            logger.error(f"Erro ao gerar se√ß√£o {section.get('title', 'unknown')}: {e}")
            return self._create_fallback_content(section, state)
    
    def _create_overview_prompt(self, section: Dict, state: DocumentationState, final_url: str) -> str:
        """Cria prompt para vis√£o geral"""
        structure_info = state.get("file_structure", {})
        
        return f"""
Crie uma documenta√ß√£o completa de VIS√ÉO GERAL DO PROJETO baseada na an√°lise real:

T√çTULO: {section['title']}
REPOSIT√ìRIO: {final_url}

AN√ÅLISE ESTRUTURAL:
{structure_info.get('structure_analysis', 'An√°lise n√£o dispon√≠vel')}

AN√ÅLISE DE C√ìDIGO:
{structure_info.get('code_analysis', 'An√°lise de c√≥digo n√£o dispon√≠vel')}

DEPEND√äNCIAS:
{structure_info.get('dependencies', 'Depend√™ncias n√£o identificadas')}

Crie documenta√ß√£o em Markdown com:
# {section['title']}

## üéØ Prop√≥sito do Projeto
[Baseado na an√°lise real dos arquivos]

## üõ†Ô∏è Stack Tecnol√≥gico
[Tecnologias identificadas na an√°lise]

## üèóÔ∏è Arquitetura
[Estrutura e padr√µes identificados]

## üìä Estat√≠sticas
[Dados quantitativos da an√°lise]

Use APENAS informa√ß√µes da an√°lise real fornecida.
"""
    
    def _create_installation_prompt(self, section: Dict, state: DocumentationState, final_url: str) -> str:
        """Cria prompt para instala√ß√£o"""
        structure_info = state.get("file_structure", {})
        
        return f"""
Crie um GUIA DE INSTALA√á√ÉO baseado na an√°lise das depend√™ncias:

T√çTULO: {section['title']}

DEPEND√äNCIAS ENCONTRADAS:
{structure_info.get('dependencies', 'Nenhuma depend√™ncia identificada')}

ESTRUTURA DO PROJETO:
{structure_info.get('structure_analysis', 'Estrutura n√£o analisada')}

Crie documenta√ß√£o em Markdown com:
# {section['title']}

## üìã Pr√©-requisitos
[Baseado nas tecnologias identificadas]

## üöÄ Instala√ß√£o
[Passos baseados nos arquivos de depend√™ncia encontrados]

## ‚öôÔ∏è Configura√ß√£o
[Configura√ß√µes necess√°rias]

## ‚ñ∂Ô∏è Execu√ß√£o
[Como executar o projeto]

Use APENAS informa√ß√µes das depend√™ncias e estrutura analisadas.
"""
    
    def _create_technical_prompt(self, section: Dict, state: DocumentationState, final_url: str) -> str:
        """Cria prompt para relat√≥rio t√©cnico"""
        structure_info = state.get("file_structure", {})
        
        return f"""
Crie um RELAT√ìRIO T√âCNICO DETALHADO baseado na an√°lise de c√≥digo:

T√çTULO: {section['title']}

AN√ÅLISE DE ARQUIVOS:
{structure_info.get('code_analysis', 'An√°lise de c√≥digo n√£o dispon√≠vel')}

ESTRUTURA:
{structure_info.get('structure_analysis', 'Estrutura n√£o analisada')}

Crie documenta√ß√£o t√©cnica em Markdown com:
# {section['title']}

## üìÅ Estrutura do Projeto
[Organiza√ß√£o identificada]

## üîß Arquivos Principais
[Para cada arquivo analisado:]
### [Nome do Arquivo]
- **Prop√≥sito:** [identificado na an√°lise]
- **Linguagem:** [detectada]
- **Fun√ß√µes:** [listadas na an√°lise]
- **Classes:** [encontradas]
- **Complexidade:** [calculada]

## üèóÔ∏è Arquitetura
[Padr√µes identificados]

Use APENAS dados da an√°lise real dos arquivos.
"""
    
    def _create_general_prompt(self, section: Dict, state: DocumentationState, final_url: str) -> str:
        """Cria prompt gen√©rico"""
        return f"""
Crie documenta√ß√£o para: {section['title']}

Descri√ß√£o: {section.get('description', 'Documenta√ß√£o geral')}

Reposit√≥rio: {final_url}

Crie documenta√ß√£o √∫til e informativa em formato Markdown.
"""
    
    def _create_fallback_content(self, section: Dict, state: DocumentationState) -> str:
        """Cria conte√∫do de fallback"""
        title = section.get('title', 'Documenta√ß√£o')
        repo_url = state.get("repo_url", "")
        
        return f"""# {title}

## üìã Vis√£o Geral

Esta se√ß√£o documenta {title.lower()} do projeto.

## üöÄ Informa√ß√µes

- **Reposit√≥rio:** {repo_url}
- **Gerado em:** {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}
- **Sistema:** DocAgent LangGraph v3.0

## üìù Observa√ß√µes

Esta documenta√ß√£o foi gerada automaticamente pelo DocAgent LangGraph.
Para informa√ß√µes mais detalhadas, consulte o c√≥digo-fonte do projeto.

---
*Gerado pelo DocAgent LangGraph v3.0*
"""
    
    def _get_section_filename(self, title: str, index: int, anonymous: bool) -> str:
        """Gera nome do arquivo para se√ß√£o"""
        suffix = "_anonimo" if anonymous else ""
        
        title_lower = title.lower()
        if "vis√£o" in title_lower or "geral" in title_lower:
            return f"01_visao_geral{suffix}.md"
        elif "instala√ß√£o" in title_lower or "guia" in title_lower:
            return f"02_guia_instalacao{suffix}.md"
        elif "t√©cnico" in title_lower or "relat√≥rio" in title_lower:
            return f"03_relatorio_tecnico{suffix}.md"
        else:
            safe_title = re.sub(r'[^\w\s-]', '', title)
            safe_title = re.sub(r'[-\s]+', '_', safe_title)
            return f"{index:02d}_{safe_title.lower()}{suffix}.md"

# =============================================================================
# CONSTRUTOR DO GRAFO LANGGRAPH
# =============================================================================

class DocAgentLangGraph:
    """Sistema principal de documenta√ß√£o baseado em LangGraph"""
    
    def __init__(self):
        self.llm_manager = LLMManager()
        self.agents = DocumentationAgents(self.llm_manager)
        self.graph = None
        self.app = None
        self._build_graph()
        logger.info("DocAgent LangGraph inicializado")
    
    def _build_graph(self):
        """Constr√≥i o grafo LangGraph"""
        try:
            if not LANGGRAPH_AVAILABLE:
                logger.error("LangGraph n√£o dispon√≠vel")
                return
            
            # Criar grafo
            workflow = StateGraph(DocumentationState)
            
            # Adicionar n√≥s
            workflow.add_node("clone_repository", self.agents.clone_repository_node)
            workflow.add_node("analyze_structure", self.agents.analyze_structure_node)
            workflow.add_node("generate_plan", self.agents.generate_documentation_plan_node)
            workflow.add_node("generate_docs", self.agents.generate_documentation_node)
            
            # Definir fluxo
            workflow.set_entry_point("clone_repository")
            workflow.add_edge("clone_repository", "analyze_structure")
            workflow.add_edge("analyze_structure", "generate_plan")
            workflow.add_edge("generate_plan", "generate_docs")
            workflow.add_edge("generate_docs", END)
            
            # Compilar com mem√≥ria
            memory = MemorySaver()
            self.app = workflow.compile(checkpointer=memory)
            
            logger.info("Grafo LangGraph constru√≠do com sucesso")
            
        except Exception as e:
            logger.error(f"Erro ao construir grafo: {e}")
    
    async def execute_documentation_flow(self, request: AnalysisRequest) -> Dict[str, Any]:
        """Executa o fluxo completo de documenta√ß√£o"""
        try:
            if not self.app:
                raise Exception("Grafo LangGraph n√£o inicializado")
            
            logger.info(f"Iniciando fluxo de documenta√ß√£o para: {request.repo_url}")
            
            # Configurar modelo LLM
            model_config = ModelConfig(
                provider=request.model_provider,
                model_name=request.model_name,
                api_key=os.environ.get("OPENAI_API_KEY") if request.model_provider == "openai" else None
            )
            
            if not self.llm_manager.configure_model(model_config):
                raise Exception("Falha na configura√ß√£o do modelo LLM")
            
            # Estado inicial
            initial_state = DocumentationState(
                repo_url=request.repo_url,
                model_provider=request.model_provider,
                model_name=request.model_name,
                anonymous=request.anonymous,
                max_files=request.max_files,
                deep_analysis=request.deep_analysis,
                repo_path=None,
                current_phase="init",
                progress=0,
                logs=["üöÄ Iniciando an√°lise LangGraph"],
                file_structure=None,
                code_analysis=None,
                architecture_analysis=None,
                documentation_plan=None,
                generated_docs=[],
                metadata={
                    "start_time": datetime.now().isoformat(),
                    "system": "DocAgent LangGraph v3.0"
                },
                error_count=0
            )
            
            # Configura√ß√£o do thread
            config = RunnableConfig(
                thread_id=f"doc_session_{int(time.time())}",
                recursion_limit=50
            )
            
            # Executar fluxo
            final_state = await self.app.ainvoke(initial_state, config=config)
            
            # Preparar resultado
            result = {
                "status": "success" if final_state["error_count"] == 0 else "partial_success",
                "message": f"Documenta√ß√£o gerada: {len(final_state['generated_docs'])} arquivos",
                "generated_docs": final_state["generated_docs"],
                "metadata": {
                    **final_state["metadata"],
                    "end_time": datetime.now().isoformat(),
                    "total_errors": final_state["error_count"],
                    "final_phase": final_state["current_phase"],
                    "model_used": f"{request.model_provider}/{request.model_name}"
                },
                "logs": final_state["logs"]
            }
            
            logger.info(f"Fluxo conclu√≠do: {result['status']}")
            return result
            
        except Exception as e:
            logger.error(f"Erro no fluxo de documenta√ß√£o: {e}")
            return {
                "status": "error",
                "message": f"Erro cr√≠tico: {str(e)}",
                "generated_docs": [],
                "metadata": {
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                },
                "logs": [f"‚ùå Erro cr√≠tico: {str(e)}"]
            }

# =============================================================================
# API WEB COM FASTAPI
# =============================================================================

if not WEB_AVAILABLE:
    logger.error("FastAPI n√£o dispon√≠vel")
    exit(1)

# Configurar aplica√ß√£o FastAPI
if CONFIG_AVAILABLE:
    app = FastAPI(
        title=config.SYSTEM_NAME,
        version=config.VERSION,
        description=config.DESCRIPTION,
        debug=config.DEBUG
    )
    
    # Configurar CORS baseado nas configura√ß√µes
    if config.ENABLE_CORS:
        app.add_middleware(
            CORSMiddleware,
            allow_origins=config.ALLOWED_ORIGINS,
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )
else:
    app = FastAPI(
        title="DocAgent LangGraph",
        version="3.0",
        description="Sistema de Documenta√ß√£o Autom√°tica com LangGraph, OpenAI e Ollama"
    )
    
    # CORS padr√£o
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

# Configurar diret√≥rios
if CONFIG_AVAILABLE:
    config.create_directories()
    static_dir = config.STATIC_DIR
    templates_dir = config.TEMPLATES_DIR
    docs_dir = config.DOCS_DIR
    workdir = config.WORKDIR
else:
    static_dir = Path("static")
    templates_dir = Path("templates")
    docs_dir = Path("docs")
    workdir = Path("workdir")
    
    for directory in [static_dir, templates_dir, docs_dir, workdir]:
        directory.mkdir(exist_ok=True)

try:
    app.mount("/static", StaticFiles(directory=str(static_dir)), name="static")
    templates = Jinja2Templates(directory=str(templates_dir))
except Exception as e:
    logger.warning(f"Erro ao configurar arquivos est√°ticos: {e}")

# Estado global da aplica√ß√£o
app_state = {
    "doc_agent": DocAgentLangGraph(),
    "github_fetcher": GitHubRepositoryFetcher(),
    "current_analysis": None,
    "analysis_status": AnalysisStatus(
        status="idle",
        phase="Aguardando",
        progress=0,
        message="Sistema LangGraph pronto"
    ),
    "user_sessions": {}
}

# =============================================================================
# ROTAS DA API
# =============================================================================

@app.get("/", response_class=HTMLResponse)
async def home(request: Request):
    """P√°gina principal"""
    try:
        return templates.TemplateResponse("index.html", {"request": request})
    except Exception as e:
        logger.error(f"Erro ao carregar template: {e}")
        return HTMLResponse(content="<h1>DocAgent LangGraph</h1><p>Erro ao carregar interface</p>")

@app.post("/api/search")
async def search_repositories(search_request: SearchRequest):
    """Busca reposit√≥rios"""
    try:
        logger.info(f"Buscando reposit√≥rios para: {search_request.usuario}")
        
        repositories = app_state["github_fetcher"].search_repositories(
            search_request.usuario,
            search_request.incluir_forks
        )
        
        return {
            "success": True,
            "repositories": [asdict(repo) for repo in repositories],
            "count": len(repositories),
            "user": search_request.usuario
        }
    except Exception as e:
        logger.error(f"Erro na busca: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/analyze")
async def start_analysis(analysis_request: AnalysisRequest, background_tasks: BackgroundTasks):
    """Inicia an√°lise com LangGraph"""
    try:
        logger.info(f"Iniciando an√°lise LangGraph: {analysis_request.repo_url}")
        
        # Reset status
        app_state["analysis_status"] = AnalysisStatus(
            status="starting",
            phase="Iniciando LangGraph",
            progress=0,
            message="Preparando sistema LangGraph...",
            logs=["üöÄ Sistema LangGraph iniciado"]
        )
        
        # Iniciar em background
        background_tasks.add_task(run_langgraph_analysis, analysis_request)
        
        return {
            "success": True,
            "message": "An√°lise LangGraph iniciada",
            "analysis_id": f"langgraph_{int(time.time())}",
            "model": f"{analysis_request.model_provider}/{analysis_request.model_name}"
        }
    except Exception as e:
        logger.error(f"Erro ao iniciar an√°lise: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/status")
async def get_analysis_status():
    """Obt√©m status da an√°lise"""
    try:
        return app_state["analysis_status"]
    except Exception as e:
        logger.error(f"Erro ao obter status: {e}")
        return AnalysisStatus(
            status="error",
            phase="Erro",
            progress=0,
            message=f"Erro no sistema: {str(e)}"
        )

@app.get("/api/results")
async def get_analysis_results():
    """Obt√©m resultados da an√°lise"""
    try:
        if app_state["current_analysis"]:
            return app_state["current_analysis"]
        else:
            raise HTTPException(status_code=404, detail="Nenhuma an√°lise dispon√≠vel")
    except Exception as e:
        logger.error(f"Erro ao obter resultados: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/models")
async def list_models():
    """Lista modelos dispon√≠veis"""
    try:
        available = app_state["doc_agent"].llm_manager.list_available_models()
        return {
            "success": True,
            "available": available,
            "providers": ["openai", "ollama"]
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/api/download/{filename}")
async def download_file(filename: str):
    """Download de arquivo gerado"""
    try:
        if ".." in filename or "/" in filename:
            raise HTTPException(status_code=400, detail="Nome de arquivo inv√°lido")
        
        file_path = Path("docs") / filename
        
        if file_path.exists() and file_path.is_file():
            return FileResponse(file_path, filename=filename)
        else:
            raise HTTPException(status_code=404, detail="Arquivo n√£o encontrado")
            
    except Exception as e:
        logger.error(f"Erro no download: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/download-all-zip")
async def download_all_docs():
    """Download de todos os documentos em ZIP"""
    try:
        docs_dir = Path("docs")
        if not docs_dir.exists():
            raise HTTPException(status_code=404, detail="Nenhum documento encontrado")
        
        doc_files = list(docs_dir.glob("*.md")) + list(docs_dir.glob("*.json"))
        
        if not doc_files:
            raise HTTPException(status_code=404, detail="Nenhum documento dispon√≠vel")
        
        # Criar ZIP
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        zip_filename = f"docagent_langgraph_{timestamp}.zip"
        zip_path = docs_dir / zip_filename
        
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for doc_file in doc_files:
                zipf.write(doc_file, doc_file.name)
        
        return FileResponse(
            zip_path,
            filename=zip_filename,
            media_type="application/zip"
        )
        
    except Exception as e:
        logger.error(f"Erro ao criar ZIP: {e}")
        raise HTTPException(status_code=500, detail=str(e))

class ModelSelectionRequest(BaseModel):
    """Requisi√ß√£o para configurar modelo"""
    provider: str  # "openai" ou "ollama"
    model_name: str
    api_key: Optional[str] = None
    base_url: Optional[str] = None

@app.post("/api/configure-model")
async def configure_model(model_request: ModelSelectionRequest):
    """Configura modelo LLM (OpenAI ou Ollama)"""
    try:
        logger.info(f"Configurando modelo: {model_request.provider}/{model_request.model_name}")
        
        # Validar provider
        if model_request.provider not in ["openai", "ollama"]:
            raise HTTPException(status_code=400, detail="Provider deve ser 'openai' ou 'ollama'")
        
        # Configurar modelo no DocAgent
        doc_agent = app_state["doc_agent"]
        config = ModelConfig(
            provider=model_request.provider,
            model_name=model_request.model_name,
            api_key=model_request.api_key,
            base_url=model_request.base_url
        )
        
        # Se for OpenAI e n√£o tiver API key na requisi√ß√£o, tentar pegar do ambiente
        if model_request.provider == "openai" and not model_request.api_key:
            config.api_key = os.environ.get("OPENAI_API_KEY")
            if not config.api_key:
                raise HTTPException(
                    status_code=400, 
                    detail="API Key OpenAI necess√°ria. Configure OPENAI_API_KEY ou forne√ßa na requisi√ß√£o."
                )
        
        # Configurar no LLM manager
        success = doc_agent.llm_manager.configure_model(config)
        
        if success:
            return {
                "success": True,
                "message": f"Modelo configurado: {model_request.provider}/{model_request.model_name}",
                "provider": model_request.provider,
                "model": model_request.model_name
            }
        else:
            raise HTTPException(status_code=500, detail="Falha ao configurar modelo")
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro ao configurar modelo: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/models/available")
async def get_available_models():
    """Lista todos os modelos dispon√≠veis"""
    try:
        doc_agent = app_state["doc_agent"]
        available = doc_agent.llm_manager.list_available_models()
        
        # Verificar se OpenAI est√° configurada
        openai_configured = bool(os.environ.get("OPENAI_API_KEY"))
        
        # Verificar status do Ollama
        ollama_status = "unknown"
        try:
            result = subprocess.run(["ollama", "list"], capture_output=True, text=True, timeout=5)
            ollama_status = "running" if result.returncode == 0 else "stopped"
        except:
            ollama_status = "not_installed"
        
        return {
            "success": True,
            "models": available,
            "status": {
                "openai_configured": openai_configured,
                "ollama_status": ollama_status
            },
            "recommended": {
                "openai": "gpt-4o",
                "ollama": "qwen2.5:7b"
            }
        }
    except Exception as e:
        logger.error(f"Erro ao listar modelos: {e}")
        return {"success": False, "error": str(e)}

@app.post("/api/test-model")
async def test_model_connection(model_request: ModelSelectionRequest):
    """Testa conex√£o com modelo LLM"""
    try:
        logger.info(f"Testando modelo: {model_request.provider}/{model_request.model_name}")
        
        # Criar configura√ß√£o tempor√°ria
        config = ModelConfig(
            provider=model_request.provider,
            model_name=model_request.model_name,
            api_key=model_request.api_key,
            base_url=model_request.base_url
        )
        
        # Testar configura√ß√£o
        temp_manager = LLMManager()
        success = temp_manager.configure_model(config)
        
        if not success:
            raise Exception("Falha na configura√ß√£o do modelo")
        
        # Teste simples de gera√ß√£o
        test_llm = temp_manager.get_llm()
        test_message = HumanMessage(content="Responda apenas 'OK' se voc√™ est√° funcionando.")
        
        # Timeout para o teste
        import asyncio
        try:
            result = await asyncio.wait_for(
                test_llm.ainvoke([test_message]),
                timeout=30.0
            )
            
            response_text = result.content if hasattr(result, 'content') else str(result)
            
            return {
                "success": True,
                "message": f"Modelo {model_request.provider}/{model_request.model_name} testado com sucesso",
                "test_response": response_text[:100],
                "provider": model_request.provider,
                "model": model_request.model_name
            }
            
        except asyncio.TimeoutError:
            raise Exception("Timeout na resposta do modelo (30s)")
            
    except Exception as e:
        logger.error(f"Erro no teste do modelo: {e}")
        return {
            "success": False,
            "error": str(e),
            "provider": model_request.provider,
            "model": model_request.model_name
        }

@app.get("/health")
async def health_check():
    """Verifica√ß√£o de sa√∫de"""
    try:
        checks = {
            "langgraph_available": LANGGRAPH_AVAILABLE,
            "doc_agent_ready": app_state["doc_agent"] is not None,
            "github_fetcher_ready": app_state["github_fetcher"] is not None,
            "docs_directory": Path("docs").exists(),
            "workdir_exists": Path("workdir").exists()
        }
        
        # Verificar status do Ollama
        ollama_status = "unknown"
        try:
            result = subprocess.run(["ollama", "list"], capture_output=True, text=True, timeout=5)
            ollama_status = "running" if result.returncode == 0 else "stopped"
        except:
            ollama_status = "not_installed"
        
        # Verificar OpenAI
        openai_configured = bool(os.environ.get("OPENAI_API_KEY"))
        
        all_healthy = all(checks.values())
        
        return {
            "status": "healthy" if all_healthy else "degraded",
            "checks": checks,
            "langgraph_enabled": LANGGRAPH_AVAILABLE,
            "model_status": {
                "ollama_status": ollama_status,
                "openai_configured": openai_configured
            },
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

# =============================================================================
# FUN√á√ÉO DE AN√ÅLISE EM BACKGROUND
# =============================================================================

async def run_langgraph_analysis(analysis_request: AnalysisRequest):
    """Executa an√°lise LangGraph em background"""
    
    def update_status(phase: str, progress: int, message: str, step: str = ""):
        """Atualiza status da an√°lise"""
        current_logs = app_state["analysis_status"].logs.copy()
        if step:
            current_logs.append(f"üîÑ {step}: {message}")
        
        app_state["analysis_status"] = AnalysisStatus(
            status="running",
            phase=phase,
            progress=progress,
            message=message,
            logs=current_logs,
            current_step=step
        )
        logger.info(f"Status: {phase} ({progress}%) - {message}")
    
    try:
        logger.info(f"Background: Iniciando an√°lise LangGraph de {analysis_request.repo_url}")
        
        # Fase 1: Inicializa√ß√£o
        update_status("Inicializa√ß√£o LangGraph", 5, "Preparando sistema...", "Setup")
        
        doc_agent = app_state["doc_agent"]
        if not doc_agent or not doc_agent.app:
            raise Exception("DocAgent LangGraph n√£o inicializado")
        
        # Verificar se modelo est√° configurado
        if not doc_agent.llm_manager.current_config:
            # Configurar modelo padr√£o se n√£o estiver configurado
            default_config = ModelConfig(
                provider=analysis_request.model_provider,
                model_name=analysis_request.model_name
            )
            
            if analysis_request.model_provider == "openai":
                default_config.api_key = os.environ.get("OPENAI_API_KEY")
                if not default_config.api_key:
                    raise Exception("API Key OpenAI n√£o configurada")
            
            success = doc_agent.llm_manager.configure_model(default_config)
            if not success:
                raise Exception("Falha ao configurar modelo LLM")
        
        update_status("Configura√ß√£o", 8, f"Modelo {analysis_request.model_provider}/{analysis_request.model_name} configurado", "LLM")
        
        # Fase 2: Execu√ß√£o do fluxo
        update_status("Execu√ß√£o LangGraph", 10, "Executando fluxo de documenta√ß√£o...", "Flow")
        
        result = await doc_agent.execute_documentation_flow(analysis_request)
        
        if result["status"] in ["success", "partial_success"]:
            # Sucesso
            app_state["current_analysis"] = {
                "status": result["status"],
                "message": result["message"],
                "repository_url": analysis_request.repo_url,
                "analysis_data": result,
                "generated_docs": result["generated_docs"],
                "timestamp": datetime.now().isoformat(),
                "langgraph_enabled": True,
                "analysis_type": "LangGraph_enhanced",
                "model_used": f"{analysis_request.model_provider}/{analysis_request.model_name}"
            }
            
            app_state["analysis_status"] = AnalysisStatus(
                status="completed",
                phase="Conclu√≠do",
                progress=100,
                message=f"An√°lise LangGraph conclu√≠da! {len(result['generated_docs'])} documentos gerados.",
                logs=result["logs"] + ["üéâ An√°lise LangGraph finalizada"],
                current_step="Pronto para download"
            )
            
            logger.info(f"Background: An√°lise conclu√≠da - {len(result['generated_docs'])} arquivos")
        else:
            # Erro
            raise Exception(result.get("message", "Erro desconhecido"))
        
    except Exception as e:
        error_msg = f"Erro na an√°lise LangGraph: {str(e)}"
        logger.error(f"Background: {error_msg}")
        traceback.print_exc()
        
        app_state["analysis_status"] = AnalysisStatus(
            status="error",
            phase="Erro",
            progress=0,
            message=error_msg,
            logs=app_state["analysis_status"].logs + [f"‚ùå {error_msg}"],
            current_step="Falha"
        )

# =============================================================================
# FUN√á√ÉO PRINCIPAL
# =============================================================================

def main():
    """Fun√ß√£o principal"""
    try:
        print("üöÄ Iniciando DocAgent LangGraph v3.0")
        print("=" * 80)
        
        # Verificar depend√™ncias
        if not LANGGRAPH_AVAILABLE:
            print("‚ùå LangGraph n√£o dispon√≠vel")
            print("Execute: pip install langgraph langchain langchain-openai langchain-community")
            return 1
        
        if not WEB_AVAILABLE:
            print("‚ùå FastAPI n√£o dispon√≠vel")
            print("Execute: pip install fastapi uvicorn jinja2")
            return 1
        
        # Validar ambiente se configura√ß√£o dispon√≠vel
        if CONFIG_AVAILABLE:
            print("üîç Validando ambiente...")
            checks = config.validate_environment()
            
            for check_name, status in checks.items():
                icon = "‚úÖ" if status else "‚ö†Ô∏è"
                print(f"   {icon} {check_name}: {'OK' if status else 'N√£o dispon√≠vel'}")
            
            # Verificar se h√° problemas cr√≠ticos
            critical_checks = ["git_available", "directories_writable"]
            if not all(checks[check] for check in critical_checks if check in checks):
                print("‚ùå Verifica√ß√µes cr√≠ticas falharam")
                return 1
        else:
            # Verifica√ß√µes b√°sicas
            try:
                subprocess.run(["git", "--version"], capture_output=True, check=True)
                print("‚úÖ Git dispon√≠vel")
            except:
                print("‚ùå Git n√£o encontrado")
                return 1
            
            # Criar diret√≥rios b√°sicos
            for dir_name in ["docs", "workdir", "static", "templates", "logs"]:
                Path(dir_name).mkdir(exist_ok=True)
        
        print("\n" + "="*80)
        print("ü§ñ DocAgent LangGraph v3.0 - Sistema de Documenta√ß√£o Avan√ßada")
        print("="*80)
        print("üöÄ Funcionalidades Ativas:")
        print("   ‚úÖ LangGraph para fluxo de agentes especializados")
        print("   ‚úÖ Suporte OpenAI GPT-4 e Ollama local")
        print("   ‚úÖ An√°lise completa de reposit√≥rios GitHub")
        print("   ‚úÖ Documenta√ß√£o t√©cnica autom√°tica")
        print("   ‚úÖ Relat√≥rios an√¥nimos profissionais")
        print("   ‚úÖ Interface web moderna e responsiva")
        print("   ‚úÖ API REST completa com valida√ß√£o")
        print("   ‚úÖ Download individual e ZIP completo")
        print("   ‚úÖ Sistema de tools avan√ßadas")
        print("   ‚úÖ Checkpoints para recupera√ß√£o de estado")
        print("="*80)
        
        # Configura√ß√µes do servidor
        if CONFIG_AVAILABLE:
            host = config.HOST
            port = config.PORT
            log_level = config.LOG_LEVEL.lower()
        else:
            host = "0.0.0.0"
            port = 8001
            log_level = "info"
        
        print("üîó URLs de Acesso:")
        print(f"   üè† Interface Principal: http://localhost:{port}")
        print(f"   üìö Documenta√ß√£o API:   http://localhost:{port}/docs")
        print(f"   ‚ù§Ô∏è  Health Check:      http://localhost:{port}/health")
        print(f"   üìä Modelos Dispon√≠veis: http://localhost:{port}/api/models/available")
        print("="*80)
        print("üõ†Ô∏è Configura√ß√µes:")
        
        if os.environ.get("OPENAI_API_KEY"):
            print("   ‚úÖ OpenAI API Key configurada")
        else:
            print("   ‚ö†Ô∏è  OpenAI API Key n√£o configurada")
            print("      Configure: export OPENAI_API_KEY=sk-...")
        
        if os.environ.get("GITHUB_TOKEN"):
            print("   ‚úÖ GitHub Token configurado")
        else:
            print("   ‚ö†Ô∏è  GitHub Token n√£o configurado")
            print("      Para repos privados: export GITHUB_TOKEN=ghp_...")
        
        # Verificar Ollama
        try:
            result = subprocess.run(["ollama", "list"], capture_output=True, timeout=3)
            if result.returncode == 0:
                print("   ‚úÖ Ollama dispon√≠vel")
            else:
                print("   ‚ö†Ô∏è  Ollama n√£o est√° rodando")
                print("      Execute: ollama serve")
        except:
            print("   ‚ö†Ô∏è  Ollama n√£o instalado")
            print("      Instale em: https://ollama.ai/")
        
        print("="*80)
        print("üåü Iniciando servidor web...")
        print(f"üéØ Acesse: http://localhost:{port}")
        print("üîß Pressione Ctrl+C para parar")
        print("="*80)
        
        # Iniciar servidor
        uvicorn.run(
            app,
            host=host,
            port=port,
            log_level=log_level,
            access_log=True
        )
        
    except KeyboardInterrupt:
        print("\nüëã Encerrando DocAgent LangGraph...")
        print("   Obrigado por usar o sistema!")
        return 0
    except Exception as e:
        logger.error(f"Erro cr√≠tico: {e}")
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit(main())
